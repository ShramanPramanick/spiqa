{"93": {"question": "Did the annotators agreed and how much?", "response": {"6-Figure4-1.png": ["The annotators agreed to a certain extent. The 'Average Pixels Kappa' is 0.64, which indicates a moderate level of agreement.</s>", "Yes, the annotators agreed. The inter-annotator agreement is 94.5%.</s>"]}, "referred_figures_names": ["6-Figure4-1.png"], "answer": "For event types and participant types, there was a moderate to substantial level of agreement using the Fleiss' Kappa. For coreference chain annotation, there was average agreement of 90.5%."}, "94": {"question": "Did the annotators agreed and how much?", "response": {"6-Figure4-1.png": ["The annotators agreed to a certain extent. The 'Average Pixels Kappa' is 0.64, which indicates a moderate level of agreement.</s>", "Yes, the annotators agreed. The inter-annotator agreement is 94.5%.</s>"]}, "referred_figures_names": ["6-Figure4-1.png"], "answer": "Moderate agreement of 0.64-0.68 Fleiss\u2019 Kappa over event type labels, 0.77 Fleiss\u2019 Kappa over participant labels, and good agreement of 90.5% over coreference information."}}