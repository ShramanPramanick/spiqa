{"874": {"question": "Do they perform a quantitative analysis of their model displaying knowledge distortions?", "response": {"4-Table2-1.png": ["Yes, they perform a quantitative analysis of their model displaying knowledge distortions by providing mean precision (Prec.) results on the test sets to demonstrate corpus-level results.</s>", "Yes, they perform a quantitative analysis of their model displaying knowledge distortions. They provide mean precision (Prec.) results on the test sets to demonstrate corpus-level results.</s>"], "5-Figure2-1.png": ["Yes.</s>", "Yes, they perform a quantitative analysis of their model displaying knowledge distortions. This is evident from the caption which mentions that they show the learned \u03c3(w)\u2019s for some diverse input words and display the results from the semantic parsing, syntactic parsing, and English to Mandarin translation datasets. They also provide information about the number of weights that were omitted due to rounding to the nearest tenth\u2019s place.</s>"]}, "referred_figures_names": ["4-Table2-1.png", "5-Figure2-1.png"], "answer": "Yes"}, "875": {"question": "How do they damage different neural modules?", "response": {"4-Table2-1.png": ["They damage different neural modules by randomly initializing their weights.</s>", "They damage different neural modules by randomly initializing the weights of those modules, which results in the loss of all learned information.</s>"]}, "referred_figures_names": ["4-Table2-1.png"], "answer": "Damage to neural modules is done by randomly initializing their weights, causing the loss of all learned information."}}