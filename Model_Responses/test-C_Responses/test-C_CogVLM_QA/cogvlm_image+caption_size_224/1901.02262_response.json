{"457": {"question": "What do they mean by answer styles?", "response": {"5-Table1-1.png": ["The table does not provide a detailed definition of 'answer styles'. However, based on the context, it likely refers to different types or formats of answers given in the datasets used in the experiments.</s>", "Answer styles in the context of the table likely refer to different types or formats of responses given in a question-answering system. For instance, 'ALL' might represent all possible answer styles, while 'NARROW' could indicate a more specific or limited set of answer styles.</s>"]}, "referred_figures_names": ["5-Table1-1.png"], "answer": "well-formed sentences vs concise answers"}, "458": {"question": "Is there exactly one \"answer style\" per dataset?", "response": {"5-Table1-1.png": ["Yes, there is exactly one \"answer style\" per dataset.</s>", "Yes, there is exactly one \"answer style\" per dataset as indicated by the single entry under each dataset column.</s>"]}, "referred_figures_names": ["5-Table1-1.png"], "answer": "Yes"}, "459": {"question": "What are the baselines that Masque is compared against?", "response": {"8-Table5-1.png": ["Masque is compared against the following baselines: B-1, B-4, M, and R-L.</s>", "Masque is compared against several baselines including B-1, B-4, M, R-L, and the results on the NarrativeQA validation set.</s>"], "6-Table2-1.png": ["Masque is compared against the following baselines: BIDAF, Deep Cascade QA, S-Net+CES2S, BERT+Multi-PGNet, Selector+CGC, VNET, Masque (NLG; single), Masque (NLG; ensemble), Masque (Q&A; single), and Masque (Q&A; ensemble).</s>", "Masque is compared against several baselines including BIDAF, Deep Cascade QA, S-Net+CES2S, BERT+Multi-PGNet, Selector+CGC, VNET, Masque (NLG; single), Masque (NLG; ensemble), Masque (Q&A; single), and Masque (Q&A; ensemble).</s>"]}, "referred_figures_names": ["8-Table5-1.png", "6-Table2-1.png"], "answer": "BiDAF, Deep Cascade QA, S-Net+CES2S, BERT+Multi-PGNet, Selector+CCG, VNET, DECAPROP, MHPGM+NOIC, ConZNet, RMR+A2D"}, "460": {"question": "What is the performance achieved on NarrativeQA?", "response": {"8-Table5-1.png": ["The performance achieved on NarrativeQA is 52.78 for Masque (NQA, valid) and 28.72 for Masque (NQA, test).</s>", "The performance achieved on NarrativeQA is 52.78 for the model with multi-style learning and valid data.</s>"]}, "referred_figures_names": ["8-Table5-1.png"], "answer": "Bleu-1: 54.11, Bleu-4: 30.43, METEOR: 26.13, ROUGE-L: 59.87"}, "461": {"question": "What is an \"answer style\"?", "response": {"5-Table1-1.png": ["An answer style refers to the way a question is answered, such as by providing a direct answer, an explanation, or an analogy.</s>", "An \"answer style\" refers to the way in which a question is answered. It can be a direct response, an explanation, or a combination of both.</s>"]}, "referred_figures_names": ["5-Table1-1.png"], "answer": "well-formed sentences vs concise answers"}}