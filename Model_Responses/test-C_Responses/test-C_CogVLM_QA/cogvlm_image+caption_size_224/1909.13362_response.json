{"684": {"question": "What are the datasets used for the task?", "response": {"5-TableI-1.png": ["The datasets used for the task are: English, Dutch, Indian, French, Minigui, Non-English Third-Person, and Reverse.</s>", "The datasets used for the task are 'Cebu-English', 'Dutch', 'Indian', 'French', 'Minigui', 'Sinhala-Thai', and 'Boscar'.</s>"]}, "referred_figures_names": ["5-TableI-1.png"], "answer": "Datasets used are Celex (English, Dutch), Festival (Italian), OpenLexuque (French), IIT-Guwahati (Manipuri), E-Hitz (Basque)"}, "685": {"question": "What is the accuracy of the model for the six languages tested?", "response": {"6-TableIII-1.png": ["The accuracy of the model for the six languages tested is 99.5% \u00b1 0.11 for English, 99.99% \u00b1 0.04 for Dutch, 99.99% \u00b1 0.05 for Flemish, 99.99% \u00b1 0.05 for French, 99.99% \u00b1 0.01 for German, and 100.00% \u00b1 0.01 for Spanish.</s>", "The accuracy of the model for the six languages tested is 99.5% for English, 99.4% for Dutch, 99.9% for Flemish, 99.8% for French, 99.9% for German, and 99.9% for Italian.</s>"]}, "referred_figures_names": ["6-TableIII-1.png"], "answer": "Authors report their best models have following accuracy: English CELEX (98.5%), Dutch CELEX (99.47%), Festival (99.990%), OpenLexique (100%), IIT-Guwahat (95.4%), E-Hitz (99.83%)"}, "686": {"question": "Which models achieve state-of-the-art performances?", "response": {"5-TableII-1.png": ["The models that achieve state-of-the-art performances are English CELEX, Dutch CELEX, and E-Hitz.</s>", "The models that achieve state-of-the-art performances are 'English CELEX', 'English CELEX', 'English CELEX', 'Dutch CELEX', 'Festival', 'OpenLexique', 'IIT-Gowhat', and 'E-Hitz'.</s>"]}, "referred_figures_names": ["5-TableII-1.png"], "answer": "CELEX (Dutch and English) - SVM-HMM\nFestival, E-Hitz and OpenLexique - Liang hyphenation\nIIT-Guwahat - Entropy CRF"}}