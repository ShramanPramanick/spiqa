{"951": {"question": "what are the evaluation metrics?", "response": {"15-Table5-1.png": ["The evaluation metrics are P, R, F1, P@R, and F1@R.</s>", "The evaluation metrics are P, R, F1, P@R, and F1@R.</s>"]}, "referred_figures_names": ["15-Table5-1.png"], "answer": "Precision, Recall, F1"}, "952": {"question": "which datasets were used in evaluation?", "response": {"5-Table1-1.png": ["The datasets used in evaluation are 'en MUC7', 'en Wiki2006', 'en Equiria', 'en SONAR-1', 'en Ancora 2.0', and 'en MEANTIME'.</s>", "The datasets used in evaluation are 'en MUC7', 'en Wright', 'en Wikipedia 2008', 'en SONAR-1', 'en Ancora 2.0', and 'en MEANTIME'.</s>"]}, "referred_figures_names": ["5-Table1-1.png"], "answer": "CoNLL 2003, GermEval 2014, CoNLL 2002, Egunkaria, MUC7, Wikigold, MEANTIME, SONAR-1, Ancora 2.0"}}