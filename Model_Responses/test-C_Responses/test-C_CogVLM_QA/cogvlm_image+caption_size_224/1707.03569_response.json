{"812": {"question": "By how much did they improve?", "response": {"5-Table3-1.png": ["They improved by 0.024.</s>", "They improved by 0.024, as the score for 'bilSTM+Multitask' is 0.685 compared to 'bilSTM' which has a score of 0.661.</s>"], "3-Figure1-1.png": ["They improved by 1.5%.</s>", "They improved by 1.1% as indicated in the image.</s>"]}, "referred_figures_names": ["5-Table3-1.png", "3-Figure1-1.png"], "answer": "They decrease MAE in 0.34"}, "813": {"question": "What dataset did they use?", "response": {"3-Table2-1.png": ["They used the 'Treebank' dataset.</s>", "They used the 'Treatment' dataset.</s>"]}, "referred_figures_names": ["3-Table2-1.png"], "answer": " high-quality datasets  from SemEval-2016 \u201cSentiment Analysis in Twitter\u201d task"}}