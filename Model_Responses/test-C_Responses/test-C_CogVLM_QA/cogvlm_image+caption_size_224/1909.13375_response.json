{"204": {"question": "What is difference in peformance between proposed model and state-of-the art on other question types?", "response": {"6-Table2-1.png": ["The proposed model has an EM of 76.68 and an F1 of 75.1, while the state-of-the-art model has an EM of 76.17 and an F1 of 72.8. The difference in performance is 0.51 for EM and 2.3 for F1.</s>", "The proposed model has an EM of 76.68 and an F1 of 75.1, while the state-of-the-art model has an EM of 76.17 and an F1 of 72.8. The difference in performance is 0.51 in terms of EM and 0.39 in terms of F1 for the proposed model compared to the state-of-the-art model on other question types.</s>"]}, "referred_figures_names": ["6-Table2-1.png"], "answer": "For single-span questions, the proposed LARGE-SQUAD improve performance of the MTMSNlarge baseline for 2.1 EM and 1.55 F1.\nFor number type question,  MTMSNlarge baseline  have improvement over LARGE-SQUAD for 3,11  EM and  2,98 F1. \nFor date question,  LARGE-SQUAD have improvements in 2,02 EM but MTMSNlarge have improvement of 4,39 F1."}, "205": {"question": "What is the performance of proposed model on entire DROP dataset?", "response": {"6-Table3-1.png": ["The performance of the proposed model on the entire DROP dataset is 80.25.</s>", "The performance of the proposed model on the entire DROP dataset is 80.25.</s>"]}, "referred_figures_names": ["6-Table3-1.png"], "answer": "The proposed model achieves  EM 77,63 and F1 80,73  on the test and EM  76,95 and  F1 80,25 on the dev"}}