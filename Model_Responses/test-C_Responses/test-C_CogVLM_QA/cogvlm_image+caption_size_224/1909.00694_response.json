{"2": {"question": "What are the results?", "response": {"5-Table4-1.png": ["The results are as follows: For the training dataset of 6K with only AL, the BERT model achieved an accuracy of 0.886. When the AL data was combined with CA+CO, the accuracy increased to 0.879.</s>", "The results show that when BERT is trained only with the AL data, the Accuracy (Acc) is 0.886.</s>"], "5-Table3-1.png": ["The results show the performance of various models on the ACP test set. The models include AL, AL+CA+CO, ACP, ACP+AL+CA+CO, Random, and Random+Seed. The performance is measured in terms of Accuracy (Acc), which is a percentage value. For instance, the AL model has an accuracy of 0.843, while the Random+Seed model has an accuracy of 0.503.</s>", "The results showcase the performance of various models on the ACP test set. The models include AL, AL+CA+CO, ACP, ACP+AL+CA+CO, Random, and Random+Seed. The performance is measured in terms of Accuracy (Acc), which is a metric used to evaluate the accuracy of a model in predicting outcomes. The highest accuracy is achieved by the ACP+AL+CA+CO model with an accuracy of 0.913, while the lowest is by the Random model with an accuracy of 0.500.</s>"]}, "referred_figures_names": ["5-Table4-1.png", "5-Table3-1.png"], "answer": "Using all data to train: AL -- BiGRU achieved 0.843 accuracy, AL -- BERT achieved 0.863 accuracy, AL+CA+CO -- BiGRU achieved 0.866 accuracy, AL+CA+CO -- BERT achieved 0.835, accuracy, ACP -- BiGRU achieved 0.919 accuracy, ACP -- BERT achived 0.933, accuracy, ACP+AL+CA+CO -- BiGRU achieved 0.917 accuracy, ACP+AL+CA+CO -- BERT achieved 0.913 accuracy. \nUsing a subset to train: BERT achieved 0.876 accuracy using ACP (6K), BERT achieved 0.886 accuracy using ACP (6K) + AL, BiGRU achieved 0.830 accuracy using ACP (6K), BiGRU achieved 0.879 accuracy using ACP (6K) + AL + CA + CO."}, "3": {"question": "How are relations used to propagate polarity?", "response": {"2-Figure1-1.png": ["Relations are used to propagate polarity by determining the discourse relation between the former and latter events. If the relation is 'CAUSE', the latter event's polarity is propagated to the former event. If the relation is 'CONCESSION', the former event's polarity is reversed.</s>", "Relations are used to propagate polarity by determining the discourse relation between the former and latter events. If the relation is 'CAUSE', the latter event's polarity is propagated to the former event, maintaining the same polarity. If the relation is 'CONCESSION', the latter event's polarity is reversed and propagated to the former event, resulting in a reversed polarity.</s>"]}, "referred_figures_names": ["2-Figure1-1.png"], "answer": "based on the relation between events, the suggested polarity of one event can determine the possible polarity of the other event "}, "4": {"question": "How are relations used to propagate polarity?", "response": {"2-Figure1-1.png": ["Relations are used to propagate polarity by determining the discourse relation between the former and latter events. If the relation is 'CAUSE', the latter event's polarity is propagated to the former event. If the relation is 'CONCESSION', the former event's polarity is reversed.</s>", "Relations are used to propagate polarity by determining the discourse relation between the former and latter events. If the relation is 'CAUSE', the latter event's polarity is propagated to the former event, maintaining the same polarity. If the relation is 'CONCESSION', the latter event's polarity is reversed and propagated to the former event, resulting in a reversed polarity.</s>"]}, "referred_figures_names": ["2-Figure1-1.png"], "answer": "cause relation: both events in the relation should have the same polarity; concession relation: events should have opposite polarity"}, "5": {"question": "How big is the Japanese data?", "response": {"4-Table2-1.png": ["The Japanese data consists of 1,000,000 entries.</s>", "The Japanese data consists of 1,000,000 entries.</s>"], "4-Table1-1.png": ["The Japanese data consists of 1,000,000 pairs.</s>", "The Japanese data consists of 1,000,000 pairs.</s>"]}, "referred_figures_names": ["4-Table2-1.png", "4-Table1-1.png"], "answer": "7000000 pairs of events were extracted from the Japanese Web corpus, 529850 pairs of events were extracted from the ACP corpus"}, "6": {"question": "How big is the Japanese data?", "response": {"4-Table2-1.png": ["The Japanese data consists of 1,000,000 entries.</s>", "The Japanese data consists of 1,000,000 entries.</s>"]}, "referred_figures_names": ["4-Table2-1.png"], "answer": "The ACP corpus has around 700k events split into positive and negative polarity "}, "8": {"question": "How big are improvements of supervszed learning results trained on smalled labeled data enhanced with proposed approach copared to basic approach?", "response": {"5-Table4-1.png": ["Improvements of supervised learning results trained on small labeled data enhanced with the proposed approach are compared to the basic approach.</s>", "Improvements of supervised learning results trained on small labeled data enhanced with the proposed approach are 0.009 compared to the basic approach.</s>"]}, "referred_figures_names": ["5-Table4-1.png"], "answer": "3%"}, "9": {"question": "How does their model learn using mostly raw data?", "response": {"2-Figure1-1.png": ["Their model learns using mostly raw data through a combination of supervised and unsupervised learning.</s>", "Their model learns using mostly raw data through a process called 'unsupervised learning'.</s>"]}, "referred_figures_names": ["2-Figure1-1.png"], "answer": "by exploiting discourse relations to propagate polarity from seed predicates to final sentiment polarity"}, "10": {"question": "How big is seed lexicon used for training?", "response": {"4-Table1-1.png": ["The seed lexicon used for training is 1,000,000.</s>", "The seed lexicon used for training is 1,000,000.</s>"]}, "referred_figures_names": ["4-Table1-1.png"], "answer": "30 words"}}