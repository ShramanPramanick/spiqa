{"845": {"question": "By how much does their best model outperform the state-of-the-art?", "response": {"5-Table3-1.png": ["1. 0", "0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"]}, "referred_figures_names": ["5-Table3-1.png"], "answer": "0.8% F1 better than the best state-of-the-art"}, "846": {"question": "By how much does their best model outperform the state-of-the-art?", "response": {"5-Table3-1.png": ["1. 0", "0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"]}, "referred_figures_names": ["5-Table3-1.png"], "answer": "Best proposed model achieves F1 score of 84.9 compared to best previous result of 84.1."}, "852": {"question": "How do they obtain the new context represetation?", "response": {"3-Figure1-1.png": ["1", "Convolutional Neural Network (CNN) with extended contexts"]}, "referred_figures_names": ["3-Figure1-1.png"], "answer": "They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."}}