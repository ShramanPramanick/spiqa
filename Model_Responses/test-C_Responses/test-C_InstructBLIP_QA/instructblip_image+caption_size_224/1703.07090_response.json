{"801": {"question": "how small of a dataset did they train on?", "response": {"4-Table1-1.png": ["568", ""]}, "referred_figures_names": ["4-Table1-1.png"], "answer": "23085 hours of data"}, "802": {"question": "what was their character error rate?", "response": {"6-Table3-1.png": ["0.12", "0.05"], "6-Table4-1.png": ["0.75", "7.6%"], "6-Table2-1.png": ["0.12", "0.05"]}, "referred_figures_names": ["6-Table3-1.png", "6-Table4-1.png", "6-Table2-1.png"], "answer": "2.49% for  layer-wise training, 2.63% for distillation, 6.26% for transfer learning."}, "803": {"question": "what was their character error rate?", "response": {"6-Table3-1.png": ["0.12", "0.05"], "6-Table2-1.png": ["0.12", "0.05"]}, "referred_figures_names": ["6-Table3-1.png", "6-Table2-1.png"], "answer": "Their best model achieved a 2.49% Character Error Rate."}, "804": {"question": "which lstm models did they compare with?", "response": {"6-Table3-1.png": ["2-layers", "Regular LSTM"], "6-Table2-1.png": ["8-layers sMBR model", "LSTM"]}, "referred_figures_names": ["6-Table3-1.png", "6-Table2-1.png"], "answer": "Unidirectional LSTM networks with 2, 6, 7, 8, and  9 layers."}}