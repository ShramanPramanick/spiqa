{"204": {"question": "What is difference in peformance between proposed model and state-of-the art on other question types?", "referred_figures_indices": [3], "response": "{'Image': 0, 'Rationale': 'Table 3 provides a direct comparison between the proposed model (Ours, LARGE-SQUAD) and other state-of-the-art models.'}\n\nThe answer is: The proposed model (Ours, LARGE-SQUAD) has an Exact Match (EM) score of 77.63 and an F1 score of 80.73 on the test set, and an EM score of 76.95 and an F1 score of 80.25 on the development set. This performance is better than the other models listed, which include NAQANET, NABERT", "all_figures_names": ["6-Table3-1.png", "6-Table1-1.png", "7-Table4-1.png", "6-Table2-1.png"], "referred_figures_names": ["6-Table2-1.png"], "answer": "For single-span questions, the proposed LARGE-SQUAD improve performance of the MTMSNlarge baseline for 2.1 EM and 1.55 F1.\nFor number type question,  MTMSNlarge baseline  have improvement over LARGE-SQUAD for 3,11  EM and  2,98 F1. \nFor date question,  LARGE-SQUAD have improvements in 2,02 EM but MTMSNlarge have improvement of 4,39 F1."}, "205": {"question": "What is the performance of proposed model on entire DROP dataset?", "referred_figures_indices": [1], "response": "{'Image': 1, 'Rationale': 'Image 1 presents a direct comparison of models on the DROP dataset for both the test and development (Dev) sets, which is relevant to the question about the performance of the proposed model on the entire DROP dataset.'}\n\nThe answer is: The performance of the proposed model \"Ours, LARGE-SQUAD\" on the entire DROP dataset as per the development (Dev) set is an Exact Match (EM) of 76.95 and an F1 score of 80.25.", "all_figures_names": ["6-Table2-1.png", "6-Table3-1.png", "7-Table4-1.png", "6-Table1-1.png"], "referred_figures_names": ["6-Table3-1.png"], "answer": "The proposed model achieves  EM 77,63 and F1 80,73  on the test and EM  76,95 and  F1 80,25 on the dev"}}