{"412": {"question": "Which training dataset allowed for the best generalization to benchmark sets?", "referred_figures_indices": [3], "response": "{'Image': 3, 'Rationale': 'Provides direct comparison of test accuracies for models trained with different datasets, which is needed to answer the question regarding the best generalization.'}\n\nThe answer is: The best generalization to benchmark sets was achieved by the combination of SNLI + MultiNLI training data, as indicated by the highest accuracy underlined in the results on Image 3.", "all_figures_names": ["4-Table2-1.png", "5-Table3-1.png", "3-Table1-1.png", "6-Table4-1.png", "9-Table5-1.png", "10-Table6-1.png"], "referred_figures_names": ["6-Table4-1.png"], "answer": "MultiNLI"}, "414": {"question": "Which models were compared?", "referred_figures_indices": [0], "response": "{'Image': 0, 'Rationale': 'This image contains a table listing the model architectures used in the experiments, thus directly answering the question about which models were compared.'}\n\nThe answer is: BiLSTM-max, HBMP, ESIM, KIM, ESIM + ELMo, and BERT-base.", "all_figures_names": ["5-Table3-1.png", "9-Table5-1.png", "6-Table4-1.png", "3-Table1-1.png", "4-Table2-1.png", "10-Table6-1.png"], "referred_figures_names": ["5-Table3-1.png"], "answer": "BiLSTM-max, HBMP, ESIM, KIM, ESIM + ELMo, and BERT"}}