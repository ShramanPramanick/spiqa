{"2": {"question": "What are the results?", "referred_figures_indices": [4, 2], "response": "{'Image': 4, 'Rationale': 'This image contains a performance comparison table of various models on a test set, which directly answers the question about results.'}\n\nThe answer is: The highest accuracy on the ACP test set is achieved by BERT trained on the ACP dataset, with an accuracy of 0.933. The BiGRU model trained on the ACP dataset follows closely with an accuracy of 0.919. Other training configurations result in lower accuracies, with BERT and BiGRU models trained on ACP+AL+CA+CO datasets achieving accuracies of 0.913 and", "all_figures_names": ["4-Table2-1.png", "5-Table5-1.png", "5-Table4-1.png", "2-Figure1-1.png", "5-Table3-1.png", "4-Table1-1.png"], "referred_figures_names": ["5-Table3-1.png", "5-Table4-1.png"], "answer": "Using all data to train: AL -- BiGRU achieved 0.843 accuracy, AL -- BERT achieved 0.863 accuracy, AL+CA+CO -- BiGRU achieved 0.866 accuracy, AL+CA+CO -- BERT achieved 0.835, accuracy, ACP -- BiGRU achieved 0.919 accuracy, ACP -- BERT achived 0.933, accuracy, ACP+AL+CA+CO -- BiGRU achieved 0.917 accuracy, ACP+AL+CA+CO -- BERT achieved 0.913 accuracy. \nUsing a subset to train: BERT achieved 0.876 accuracy using ACP (6K), BERT achieved 0.886 accuracy using ACP (6K) + AL, BiGRU achieved 0.830 accuracy using ACP (6K), BiGRU achieved 0.879 accuracy using ACP (6K) + AL + CA + CO."}, "3": {"question": "How are relations used to propagate polarity?", "referred_figures_indices": [3], "response": "{'Image': 3, 'Rationale': 'This image explicitly demonstrates the method of propagating polarity using relations such as CAUSE and CONCESSION between events.'}\n\nThe answer is: Polarity is propagated using relations such as CAUSE and CONCESSION, where the polarity of an event (positive or negative) is propagated to a former event based on the type of relation. For a CAUSE relation, the same polarity is propagated, while for a CONCESSION relation, the reverse polarity is propagated to the former event.", "all_figures_names": ["4-Table1-1.png", "5-Table3-1.png", "5-Table4-1.png", "2-Figure1-1.png", "5-Table5-1.png", "4-Table2-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "based on the relation between events, the suggested polarity of one event can determine the possible polarity of the other event "}, "4": {"question": "How are relations used to propagate polarity?", "referred_figures_indices": [3], "response": "{'Image': 3, 'Rationale': 'Image 3 directly demonstrates the method of using relations to propagate polarity between paired events and provides visual examples, which is directly relevant to explaining how polarity is propagated.'}\n\nThe answer is: Polarity is propagated by using discourse relations between pairs of events, such as CAUSE or CONCESSION. In the case of a CAUSE relation, the same polarity is propagated from the latter event to the former event. For CONCESSION relations, the polarity is reversed when propagating from the latter event to the former event.", "all_figures_names": ["5-Table3-1.png", "4-Table1-1.png", "5-Table4-1.png", "2-Figure1-1.png", "5-Table5-1.png", "4-Table2-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "cause relation: both events in the relation should have the same polarity; concession relation: events should have opposite polarity"}, "5": {"question": "How big is the Japanese data?", "referred_figures_indices": [5, 2], "response": "{'Image': 2, 'Rationale': 'This image provides the exact numbers for the ACP dataset size including train, dev, and test splits, which directly answers the question on dataset size.'}\n\nThe answer is: The Japanese data, referred to as the ACP dataset, consists of 299,834 positive and 300,164 negative events for the training set, 50,118 positive and 49,882 negative events for the development (dev) set, and 50,046 positive and 49,954 negative events for the test set.", "all_figures_names": ["5-Table3-1.png", "5-Table4-1.png", "4-Table2-1.png", "5-Table5-1.png", "2-Figure1-1.png", "4-Table1-1.png"], "referred_figures_names": ["4-Table1-1.png", "4-Table2-1.png"], "answer": "7000000 pairs of events were extracted from the Japanese Web corpus, 529850 pairs of events were extracted from the ACP corpus"}, "6": {"question": "How big is the Japanese data?", "referred_figures_indices": [5], "response": "{'Image': 3, 'Rationale': 'This image provides the explicit size of the datasets in terms of the number of pairs which is likely what the question refers to by \"how big.\"'}\n\nThe answer is: The size of the Japanese data referred to as AL (Automatically Labeled Pairs) is 1,000,000 pairs, CA (CAUSE Pairs) is 5,000,000 pairs, and CO (CONCESSION Pairs) is 5,000,000 pairs.", "all_figures_names": ["5-Table3-1.png", "5-Table5-1.png", "2-Figure1-1.png", "4-Table1-1.png", "5-Table4-1.png", "4-Table2-1.png"], "referred_figures_names": ["4-Table2-1.png"], "answer": "The ACP corpus has around 700k events split into positive and negative polarity "}, "8": {"question": "How big are improvements of supervszed learning results trained on smalled labeled data enhanced with proposed approach copared to basic approach?", "referred_figures_indices": [0], "response": "{'Image': 3, 'Rationale': 'Table 3 shows the performance of various models on the ACP test set, which includes results from both the basic and proposed approaches, making it relevant for comparison of improvements.'}\n\nBased on the information provided in Image 3:\n\nThe answer is: The improvements of supervised learning results trained on small labeled data (6K) using the proposed approach (+AL+CA+CO) are as follows:\n- For the BERT encoder, the accuracy improves from 0.876 (ACP 6K) to 0.879 (+AL+CA+CO).\n- For the Bi", "all_figures_names": ["5-Table4-1.png", "4-Table1-1.png", "4-Table2-1.png", "5-Table3-1.png", "5-Table5-1.png", "2-Figure1-1.png"], "referred_figures_names": ["5-Table4-1.png"], "answer": "3%"}, "9": {"question": "How does their model learn using mostly raw data?", "referred_figures_indices": [4], "response": "{'Image': 4, 'Rationale': 'This image outlines the methodology of polarity propagation and how discourse relations affect the learning process.'}\n\nThe answer is: The model learns using raw data by focusing on pairs of events which are connected by discourse relations such as CAUSE or CONCESSION. It uses types of event pairs (AL, CA, CO) to propagate polarity from a latter event to a former event, applying automatic labeling or encouraging same or reversed polarity based on the type of discourse relation.", "all_figures_names": ["4-Table2-1.png", "5-Table3-1.png", "5-Table5-1.png", "5-Table4-1.png", "2-Figure1-1.png", "4-Table1-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "by exploiting discourse relations to propagate polarity from seed predicates to final sentiment polarity"}, "10": {"question": "How big is seed lexicon used for training?", "referred_figures_indices": [3], "response": "{'Image': 3, 'Rationale': 'This image provides direct statistics on the number of pairs for the AL (Automatically Labeled) pairs, which is indicative of the seed lexicon size used for training.'}\n\nThe answer is: 1,000,000 pairs.", "all_figures_names": ["5-Table3-1.png", "2-Figure1-1.png", "4-Table2-1.png", "4-Table1-1.png", "5-Table4-1.png", "5-Table5-1.png"], "referred_figures_names": ["4-Table1-1.png"], "answer": "30 words"}}