{"220": {"question": "How many people participated in their evaluation study of table-to-text models?", "referred_figures_indices": [5], "response": "{'Image': 1, 'Rationale': 'This image provides the instructions given to crowd-workers, which suggests a group of people were involved in comparing text, implying an evaluation study. It is the only image that implies human participation in a study.'}\n\nThe answer is: The specific number of people who participated in their evaluation study of table-to-text models is not provided in any of the images or captions; therefore, I cannot provide an exact number based on the provided materials.", "all_figures_names": ["7-Figure4-1.png", "6-Figure2-1.png", "9-Figure5-1.png", "6-Table2-1.png", "8-Table4-1.png", "5-Table1-1.png", "7-Figure3-1.png", "11-Table5-1.png"], "referred_figures_names": ["5-Table1-1.png"], "answer": "about 500"}, "222": {"question": "By how much more does PARENT correlate with human judgements in comparison to other text generation metrics?", "referred_figures_indices": [1, 3, 4], "response": "{'Image': 4, 'Rationale': 'Table 2 presents a comparison of correlations with human judgements for different metrics, including PARENT, which is directly relevant to the question.'}\n\nThe answer is: PARENT correlates with human judgements by approximately 0.075 to 0.097 more than other text generation metrics, depending on whether we are comparing PARENT-C or PARENT-W with the average correlations of other metrics.", "all_figures_names": ["12-Table6-1.png", "7-Figure3-1.png", "11-Figure6-1.png", "8-Table4-1.png", "6-Table2-1.png", "11-Table5-1.png", "2-Figure1-1.png", "9-Figure5-1.png"], "referred_figures_names": ["7-Figure3-1.png", "8-Table4-1.png", "6-Table2-1.png"], "answer": "Best proposed metric has average correlation with human judgement of 0.913 and 0.846 compared to best compared metrics result of 0.758 and 0.829 on WikiBio and WebNLG challenge."}, "223": {"question": "By how much more does PARENT correlate with human judgements in comparison to other text generation metrics?", "referred_figures_indices": [7], "response": "{'Image': 0, 'Rationale': 'This image shows the correlation of different metrics, including PARENT, with human judgment as the percentage of entailed examples vary, making it most relevant for comparing PARENT to other metrics.'}\n\nThe answer is: It is difficult to quantify the exact difference from the provided images, as they don't include precise numerical values for correlation differences. Nonetheless, based on Image 0, PARENT correlates more with human judgments than BLEU, BLEU-T, and RG-F; however, the exact amount of this difference cannot be determined without numerical data.", "all_figures_names": ["7-Figure4-1.png", "9-Figure5-1.png", "7-Figure3-1.png", "2-Figure1-1.png", "5-Table1-1.png", "11-Table5-1.png", "8-Table3-1.png", "6-Table2-1.png"], "referred_figures_names": ["6-Table2-1.png"], "answer": "Their average correlation tops the best other model by 0.155 on WikiBio."}}