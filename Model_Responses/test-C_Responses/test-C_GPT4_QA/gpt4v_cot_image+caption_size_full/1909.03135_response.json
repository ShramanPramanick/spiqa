{"736": {"question": "How big was the corpora they trained ELMo on?", "referred_figures_indices": [0], "response": "{'Image': 0, 'Rationale': 'The table lists the training corpora sizes for ELMo, which directly answers the question about the size of the corpora used for training ELMo.'}\n\nThe answer is: ELMo was trained on a corpus of 2,174 million tokens and 1,977 million lemmas for English.", "all_figures_names": ["2-Table1-1.png", "4-Table3-1.png", "5-Figure2-1.png", "6-Table6-1.png", "3-Table2-1.png", "5-Figure1-1.png", "5-Table5-1.png", "4-Table4-1.png"], "referred_figures_names": ["2-Table1-1.png"], "answer": "2174000000, 989000000"}, "737": {"question": "How big was the corpora they trained ELMo on?", "referred_figures_indices": [2], "response": "{'Image': 2, 'Rationale': 'This image provides information on the size of training corpora, which is relevant to the question about the size of the corpora used for training ELMo.'}\n\nThe answer is: ELMo was trained on a corpus with 2,174 million tokens and 1,977 million lemmas for English, and 989 million tokens and 988 million lemmas for Russian.", "all_figures_names": ["4-Table3-1.png", "3-Table2-1.png", "2-Table1-1.png", "5-Table5-1.png", "5-Figure2-1.png", "4-Table4-1.png", "5-Figure1-1.png", "6-Table6-1.png"], "referred_figures_names": ["2-Table1-1.png"], "answer": "2174 million tokens for English and 989 million tokens for Russian"}}