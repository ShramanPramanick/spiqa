{"1392": {"question": "How are sentence embeddings incorporated into the speech recognition system?", "referred_figures_indices": [5, 4], "response": "{'Image': 4, 'Rationale': 'This image visually demonstrates how conversational-context embeddings are incorporated into a speech recognition system, aligning closely with the question.'}\n\nThe answer is: Sentence embeddings are incorporated into the speech recognition system as conversational-context embeddings, which provide external contextual information to enhance the understanding of current speech segments. They are integrated through a model that includes an encoder and a decoder where the encoder processes the current acoustics and the decoder utilizes a combination of embeddings of conversational context, previous words, and current speech to predict the next word.", "all_figures_names": ["7-Figure4-1.png", "8-Figure5-1.png", "7-Figure3-1.png", "6-Table2-1.png", "4-Figure1-1.png", "5-Figure2-1.png", "5-Table1-1.png"], "referred_figures_names": ["5-Figure2-1.png", "4-Figure1-1.png"], "answer": "BERT generates sentence embeddings that represent words in context. These sentence embeddings are merged into a single conversational-context vector that is used to calculate a gated embedding and is later combined with the output of the decoder h to provide the gated activations for the next hidden layer."}}