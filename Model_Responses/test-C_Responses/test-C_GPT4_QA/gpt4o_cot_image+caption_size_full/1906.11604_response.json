{"1392": {"question": "How are sentence embeddings incorporated into the speech recognition system?", "referred_figures_indices": [3, 6], "response": "{'Image': 3, 'Rationale': 'This image visually explains how sentence embeddings from external sources like fastText or BERT are integrated into the speech recognition system through conversational-context embeddings, which is directly relevant to the question.'}\n\nThe answer is: Sentence embeddings are incorporated into the speech recognition system through conversational-context embeddings. These embeddings, derived from external word or sentence embeddings like fastText or BERT, are used to capture the contextual information from previous utterances. This contextual information is combined with the current speech and previous word embeddings to provide a more informed input to the decoder LSTM, thereby improving the speech recognition system's performance", "all_figures_names": ["6-Table2-1.png", "7-Figure4-1.png", "7-Figure3-1.png", "4-Figure1-1.png", "5-Table1-1.png", "8-Figure5-1.png", "5-Figure2-1.png"], "referred_figures_names": ["4-Figure1-1.png", "5-Figure2-1.png"], "answer": "BERT generates sentence embeddings that represent words in context. These sentence embeddings are merged into a single conversational-context vector that is used to calculate a gated embedding and is later combined with the output of the decoder h to provide the gated activations for the next hidden layer."}}