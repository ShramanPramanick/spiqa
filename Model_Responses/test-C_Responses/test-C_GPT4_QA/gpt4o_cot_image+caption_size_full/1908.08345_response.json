{"836": {"question": "What rouge score do they achieve?", "referred_figures_indices": [2, 6, 7, 3], "response": "{'Image': Image 6, 'Rationale': 'Image 6 displays a table of ROUGE scores for various models, which directly answers the question about ROUGE scores achieved.'}\n\nThe answer is: Various models achieve different ROUGE scores, such as BERTSUMEXTABS achieving R1 42.13, R2 19.60, and RL 39.18 on the CNN/DailyMail dataset.", "all_figures_names": ["8-Figure2-1.png", "9-Table6-1.png", "7-Table4-1.png", "7-Table3-1.png", "9-Figure3-1.png", "8-Table5-1.png", "6-Table2-1.png", "5-Table1-1.png"], "referred_figures_names": ["7-Table4-1.png", "6-Table2-1.png", "5-Table1-1.png", "7-Table3-1.png"], "answer": "Best results on unigram:\nCNN/Daily Mail: Rogue F1 43.85\nNYT: Rogue Recall 49.02\nXSum: Rogue F1 38.81"}, "837": {"question": "What rouge score do they achieve?", "referred_figures_indices": [5, 2], "response": "{'Image': 2, 'Rationale': 'Image 2 lists ROUGE scores (R1, R2, RL) for various models, which directly addresses the question.'}\n\nThe answer is : The ROUGE scores they achieve are:\n- R1: 42.13\n- R2: 19.60\n- RL: 39.18", "all_figures_names": ["9-Figure3-1.png", "8-Table5-1.png", "6-Table2-1.png", "8-Figure2-1.png", "3-Figure1-1.png", "7-Table4-1.png", "9-Table6-1.png", "9-Table7-1.png"], "referred_figures_names": ["7-Table4-1.png", "6-Table2-1.png"], "answer": "Highest scores for ROUGE-1, ROUGE-2 and ROUGE-L on CNN/DailyMail test set are 43.85, 20.34 and 39.90 respectively; on the XSum test set 38.81, 16.50 and 31.27 and on the NYT test set 49.02, 31.02 and 45.55"}}