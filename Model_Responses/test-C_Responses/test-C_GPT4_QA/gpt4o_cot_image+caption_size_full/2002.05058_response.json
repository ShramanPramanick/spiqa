{"989": {"question": "How much better peformance is achieved in human evaluation when model is trained considering proposed metric?", "referred_figures_indices": [1, 0], "response": "{'Image': 1, 'Rationale': 'Image 1 provides a direct comparison of model-level correlation between metrics and human judgments, indicating how much better the model performs when considering the proposed metric.'}\n\nThe answer is: When the model is trained considering the proposed metric, it achieves a Spearman correlation of 0.764 and Pearson correlation of 0.783 in human evaluation, compared to lower correlations for other metrics (e.g., ADEM or BLEU). This shows a significantly better performance in human evaluation.", "all_figures_names": ["6-Table1-1.png", "6-Table2-1.png", "7-Table4-1.png", "7-Table3-1.png", "7-Table5-1.png", "4-Figure1-1.png"], "referred_figures_names": ["6-Table2-1.png", "6-Table1-1.png"], "answer": "Pearson correlation to human judgement - proposed vs next best metric\nSample level comparison:\n- Story generation: 0.387 vs 0.148\n- Dialogue: 0.472 vs 0.341\nModel level comparison:\n- Story generation:  0.631 vs 0.302\n- Dialogue: 0.783 vs 0.553"}}