{"1107": {"question": "How big are the datasets used?", "referred_figures_indices": [2], "response": "{'Image': 2, 'Rationale': 'Image 2 provides the statistics of the datasets (CMRC 2018 and DRCD), including the number of questions and answers in the train, dev, test, and challenge sets. This directly addresses the question about the size of the datasets.'}\n\nThe answer is : The datasets used are CMRC 2018 with 10,321 training questions, 3,219 development questions, 4,895 test questions, and 504 challenge questions, and DRCD with 26,936 training questions, 3,524 development questions, and 3,493 test questions", "all_figures_names": ["8-Table4-1.png", "7-Table2-1.png", "6-Table1-1.png", "3-Figure1-1.png", "8-Figure3-1.png", "5-Figure2-1.png", "7-Table3-1.png"], "referred_figures_names": ["6-Table1-1.png"], "answer": "Evaluation datasets used:\nCMRC 2018 - 18939 questions, 10 answers\nDRCD - 33953 questions, 5 answers\nNIST MT02/03/04/05/06/08 Chinese-English - Not specified\n\nSource language train data:\nSQuAD - Not specified"}, "1108": {"question": "Is this a span-based (extractive) QA task?", "referred_figures_indices": [6], "response": "{'Image': 4, 'Rationale': 'Image 4 directly illustrates different back-translation approaches for cross-lingual machine reading comprehension, which involves extracting answer spans, directly related to the span-based extractive QA task.'}\n\nThe answer is : Yes, this is a span-based (extractive) QA task.", "all_figures_names": ["8-Figure3-1.png", "8-Table4-1.png", "7-Table3-1.png", "7-Table2-1.png", "3-Figure1-1.png", "5-Figure2-1.png", "6-Table1-1.png"], "referred_figures_names": ["6-Table1-1.png"], "answer": "Yes"}}