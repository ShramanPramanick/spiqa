{"1259": {"question": "By how much does their method outperform the multi-head attention model?", "referred_figures_indices": [3], "response": "{'Image': 3, 'Rationale': 'The table shows experimental results, which likely include performance metrics of different models.'}\n\nThe answer is: Their method outperforms the multi-head attention model by 0.3% to 0.8% depending on the task.", "all_figures_names": ["2-Figure1-1.png", "4-Figure3-1.png", "4-Table1-1.png", "4-Table2-1.png", "3-Figure2-1.png"], "referred_figures_names": ["4-Table2-1.png"], "answer": "Their average improvement in Character Error Rate over the best MHA model was 0.33 percent points."}, "1260": {"question": "How large is the corpus they use?", "referred_figures_indices": [1], "response": "{'Image': 1, 'Rationale': 'This image provides details on the corpus size, including the number of training and evaluation utterances.'}\n\nThe answer is : 445,068 utterances (581 hours) for training, and varying hours (1.9 to 2 hours) for different evaluation tasks.", "all_figures_names": ["4-Figure3-1.png", "4-Table1-1.png", "3-Figure2-1.png", "2-Figure1-1.png", "4-Table2-1.png"], "referred_figures_names": ["4-Table1-1.png"], "answer": "449050"}}