{"1340": {"question": "Which are the sequence model architectures this method can be transferred across?", "referred_figures_indices": [0], "response": "{'Image': 0, 'Rationale': 'Image 0 lists the performance across different model architectures: LSTM, CNN, and Transformer, making it directly relevant to answering which sequence model architectures the method can be transferred across.'}\n\nThe answer is: LSTM, CNN, and Transformer.", "all_figures_names": ["9-Table8-1.png", "9-Table7-1.png", "9-Table6-1.png", "6-Table1-1.png", "8-Table3-1.png", "7-Figure1-1.png", "8-Table4-1.png", "9-Table5-1.png"], "referred_figures_names": ["9-Table8-1.png"], "answer": "The sequence model architectures which this method is transferred to are: LSTM and Transformer-based models"}, "1341": {"question": " What percentage of improvement in inference speed is obtained by the proposed method over the newest state-of-the-art methods?", "referred_figures_indices": [1], "response": "{'Image': 1, 'Rationale': 'Image 1 provides the inference speed for different models, including the proposed method, which is necessary to determine the improvement.'}\n\nThe answer is: The percentage of improvement in inference speed obtained by the proposed method (CNN implementation) over LR-CNN is approximately ((80.75 - 26.73) / 26.73) * 100 \u2248 202% for the OntoNotes dataset, ((92.76 - 23.20) / 23.20) * 100 \u2248 300% for MSRA, ((74.24 - 26", "all_figures_names": ["8-Table4-1.png", "8-Table3-1.png", "7-Table2-1.png", "9-Table5-1.png", "7-Figure1-1.png", "6-Table1-1.png", "9-Table6-1.png", "9-Table8-1.png"], "referred_figures_names": ["8-Table3-1.png"], "answer": "Across 4 datasets, the best performing proposed model (CNN) achieved an average of 363% improvement over the state of the art method (LR-CNN)"}}