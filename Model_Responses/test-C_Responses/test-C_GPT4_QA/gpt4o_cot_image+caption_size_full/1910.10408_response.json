{"483": {"question": "Do they conduct any human evaluation?", "referred_figures_indices": [3], "response": "{'Image': 7, 'Rationale': 'Image 7 provides information about the manual (human) evaluation of translation quality, which directly addresses the question.'}\n\nThe answer is : Yes, they conduct human evaluation.", "all_figures_names": ["2-Figure2-1.png", "4-Figure3-1.png", "4-Table1-1.png", "2-Figure1-1.png", "6-Table5-1.png", "5-Table3-1.png", "4-Table2-1.png", "7-Table6-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "Yes"}, "485": {"question": "How do they enrich the positional embedding with length information", "referred_figures_indices": [5], "response": "{'Image': 5, 'Rationale': 'Image 5 shows the Transformer architecture with the decoder input enriched with length embedding, directly illustrating how positional embedding is enhanced with length information.'}\n\nThe answer is : They enrich the positional embedding with length information by adding length embeddings to the position and word embeddings in the decoder, computed based on the desired target length.", "all_figures_names": ["7-Table7-1.png", "4-Table2-1.png", "2-Figure1-1.png", "6-Table5-1.png", "6-Table4-1.png", "4-Figure3-1.png", "7-Table6-1.png", "5-Table3-1.png"], "referred_figures_names": ["4-Figure3-1.png"], "answer": "They introduce new trigonometric encoding which besides information about position uses additional length information (abs or relative)."}, "486": {"question": "How do they condition the output to a given target-source class?", "referred_figures_indices": [4], "response": "{'Image': 0, 'Rationale': 'Image 0 illustrates the Transformer architecture where the decoder input is enriched with position and length embeddings to condition the output to a target-source class.'}\n\nThe answer is: They condition the output to a given target-source class by enriching the decoder input with positional information and length embeddings computed according to the desired target string length.", "all_figures_names": ["4-Figure3-1.png", "6-Table5-1.png", "4-Table1-1.png", "5-Table3-1.png", "2-Figure2-1.png", "6-Table4-1.png", "7-Table7-1.png", "4-Table2-1.png"], "referred_figures_names": ["2-Figure2-1.png"], "answer": "They use three groups short/normal/long translation classes to learn length token, which is in inference used to bias network to generate desired length group."}}