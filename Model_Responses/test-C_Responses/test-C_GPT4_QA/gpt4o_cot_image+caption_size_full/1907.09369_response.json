{"601": {"question": "Do they report results only on English data?", "referred_figures_indices": [1], "response": "{'Image': 5, 'Rationale': 'This table mentions that the data is from CrowdFlower, which provides context about the type of data and language.'}\n\nThe answer is: No, they do not report results only on English data since CrowdFlower datasets often include multiple languages. However, without further clarification, it is not definite whether only English data was used.", "all_figures_names": ["4-Table5-1.png", "2-Table2-1.png", "4-Table4-1.png", "2-Table1-1.png", "3-Table3-1.png", "5-Table7-1.png", "5-Table6-1.png", "3-Figure1-1.png"], "referred_figures_names": ["2-Table2-1.png"], "answer": "Yes"}, "603": {"question": "What are the hyperparameters of the bi-GRU?", "referred_figures_indices": [6, 4], "response": "{'Image': 6, 'Rationale': 'This image contains a diagram of the bidirectional GRU architecture, which is most relevant to understanding its hyperparameters.'}\n\nThe answer is: The hyperparameters of the bidirectional GRU typically include the number of layers, the number of units (or neurons) in each GRU cell, the dropout rate, learning rate, batch size, and the type of optimizer used. From the architecture in the image, we can see mentions of dropout (0.5). Other hyperparameters would be defined based on specific implementation details not fully captured in the image.", "all_figures_names": ["2-Table2-1.png", "5-Table7-1.png", "4-Table4-1.png", "3-Table3-1.png", "4-Table5-1.png", "5-Table6-1.png", "3-Figure1-1.png", "2-Table1-1.png"], "referred_figures_names": ["3-Figure1-1.png", "4-Table5-1.png"], "answer": "They use the embedding layer with a size 35 and embedding dimension of 300. They use a dense layer with 70 units and a dropout layer with a rate of 50%."}}