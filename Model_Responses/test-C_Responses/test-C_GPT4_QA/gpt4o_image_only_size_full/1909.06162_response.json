{"909": {"question": "What is best performing model among author's submissions, what performance it had?", "referred_figures_indices": [2], "response": "{'Answer': 'The best performing model among the author's submissions is r26 relax-voting, |M| \u2265 30% in Dev (external) with an F1 score of .679, Precision of .622 and Recall of .747.'}", "all_figures_names": ["2-Table1-1.png", "3-Figure1-1.png", "3-Table2-1.png", "4-Table3-1.png", "4-Table4-1.png"], "referred_figures_names": ["3-Table2-1.png"], "answer": "For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."}, "910": {"question": "What extracted features were most influencial on performance?", "referred_figures_indices": [3], "response": "{'Answer': 'Polarity, POS, NER features combined with BERT embeddings were most influential on performance.'}", "all_figures_names": ["3-Table2-1.png", "4-Table4-1.png", "3-Figure1-1.png", "4-Table3-1.png", "2-Table1-1.png"], "referred_figures_names": ["4-Table3-1.png"], "answer": "Linguistic"}, "912": {"question": "Did ensemble schemes help in boosting peformance, by how much?", "referred_figures_indices": [3], "response": "{'Answer': 'Yes, ensemble schemes helped in boosting performance. For instance, the ensemble of models (r3, r6, r12) within Fold1 showed an improvement in F1 score from 0.664 to 0.673 on Dev (external) set when comparing r11 before ensemble (0.664) and after ensemble without post-processing (r19: 0.673). Similarly, another example shows that ensemble+ with postprocess improved F1 scores from 0.671 to 0.676 when comparing r27 (0.671) and r28 (0.676).' }", "all_figures_names": ["3-Figure1-1.png", "4-Table4-1.png", "2-Table1-1.png", "4-Table3-1.png", "3-Table2-1.png"], "referred_figures_names": ["4-Table3-1.png"], "answer": "The best ensemble topped the best single model by 0.029 in F1 score on dev (external)."}, "913": {"question": "Did ensemble schemes help in boosting peformance, by how much?", "referred_figures_indices": [3, 1, 0], "response": "{'Answer': 'Yes, the ensemble schemes helped in boosting performance. For instance, in Image 1, the ensemble approach (r17) achieved an F1 score of .666 for Dev (internal) and .683 for Dev (external), both higher than most single model performances. In Image 3, the ensemble approach (Ensemble+ from each Fold1-3 with postprocess) achieved an F1 score of .164 for Dev (external), which is an improvement over the individual models.'}", "all_figures_names": ["3-Table2-1.png", "4-Table3-1.png", "3-Figure1-1.png", "4-Table4-1.png", "2-Table1-1.png"], "referred_figures_names": ["4-Table4-1.png", "4-Table3-1.png", "3-Table2-1.png"], "answer": "They increased F1 Score by 0.029 in Sentence Level Classification, and by 0.044 in Fragment-Level classification"}, "914": {"question": "Which basic neural architecture perform best by itself?", "referred_figures_indices": [1], "response": "{'Answer': 'BERT + Fine-tune'}", "all_figures_names": ["3-Figure1-1.png", "4-Table3-1.png", "3-Table2-1.png", "2-Table1-1.png", "4-Table4-1.png"], "referred_figures_names": ["4-Table3-1.png"], "answer": "BERT"}, "915": {"question": "What participating systems had better results than ones authors submitted?", "referred_figures_indices": [3], "response": "{'Answer': 'teams Iturop, ProperGander, YMJA, MIC-CIS, TeamOne in SLC task and team newspeak in FLC task'}", "all_figures_names": ["4-Table3-1.png", "4-Table4-1.png", "3-Figure1-1.png", "3-Table2-1.png", "2-Table1-1.png"], "referred_figures_names": ["3-Table2-1.png"], "answer": "For SLC task : Ituorp, ProperGander and YMJA  teams had better results.\nFor FLC task: newspeak and Antiganda teams had better results."}, "916": {"question": "What is specific to multi-granularity and multi-tasking neural arhiteture design?", "referred_figures_indices": [3], "response": "{'Answer': 'Multi-granularity in multi-tasking neural architecture design refers to combining different levels of granular information, such as sentence-level and word-level features, to enhance task performance. Multi-tasking involves sharing knowledge across related tasks, such as SLC, FLC, and PFD, within a single model. This integration helps improve the model's ability to generalize and capture complex patterns by leveraging diverse feature sets (linguistic, layout, topical features) and multiple neural architectures (Logistic Regression, CNN, BERT, LSTM).'}", "all_figures_names": ["3-Table2-1.png", "4-Table3-1.png", "2-Table1-1.png", "3-Figure1-1.png", "4-Table4-1.png"], "referred_figures_names": ["3-Figure1-1.png"], "answer": "An output layer for each task"}}