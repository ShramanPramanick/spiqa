{"836": {"question": "What rouge score do they achieve?", "referred_figures_indices": [0, 1, 2, 5], "response": "{'Answer': 'The images provided contain various models and their ROUGE scores (R1, R2, RL) for different datasets and summarization types. Since there is no specific model mentioned in the question, I can't provide a direct answer.'}", "all_figures_names": ["5-Table1-1.png", "6-Table2-1.png", "7-Table4-1.png", "9-Table7-1.png", "9-Table6-1.png", "7-Table3-1.png", "9-Figure3-1.png", "3-Figure1-1.png"], "referred_figures_names": ["5-Table1-1.png", "6-Table2-1.png", "7-Table4-1.png", "7-Table3-1.png"], "answer": "Best results on unigram:\nCNN/Daily Mail: Rogue F1 43.85\nNYT: Rogue Recall 49.02\nXSum: Rogue F1 38.81"}, "837": {"question": "What rouge score do they achieve?", "referred_figures_indices": [7, 4], "response": "{'Answer': 'The Rouge score varies by model and type. For instance, the BERT-based BERTSumExt model achieves an R1 score of 43.25, an R2 score of 20.24, and an RL score of 39.63 from Image 7.'}", "all_figures_names": ["7-Table3-1.png", "9-Figure3-1.png", "9-Table6-1.png", "8-Table5-1.png", "7-Table4-1.png", "3-Figure1-1.png", "5-Table1-1.png", "6-Table2-1.png"], "referred_figures_names": ["6-Table2-1.png", "7-Table4-1.png"], "answer": "Highest scores for ROUGE-1, ROUGE-2 and ROUGE-L on CNN/DailyMail test set are 43.85, 20.34 and 39.90 respectively; on the XSum test set 38.81, 16.50 and 31.27 and on the NYT test set 49.02, 31.02 and 45.55"}}