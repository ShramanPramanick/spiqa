{"856": {"question": "What baseline did they compare Entity-GCN to?", "referred_figures_indices": [3], "response": "{'Answer': 'MHQA-GRN (Song et al., 2018)'}", "all_figures_names": ["7-Table3-1.png", "8-Table4-1.png", "3-Figure2-1.png", "6-Table2-1.png", "1-Figure1-1.png", "11-Table5-1.png", "13-Figure3-1.png", "5-Table1-1.png"], "referred_figures_names": ["6-Table2-1.png"], "answer": "Human, FastQA, BiDAF, Coref-GRU, MHPGM, Weaver / Jenga, MHQA-GRN"}, "858": {"question": "Did they use a relation extraction method to construct the edges in the graph?", "referred_figures_indices": [3], "response": "{'Answer': 'Yes'}", "all_figures_names": ["12-Table6-1.png", "8-Table4-1.png", "1-Figure1-1.png", "3-Figure2-1.png", "13-Figure3-1.png", "6-Table2-1.png", "7-Table3-1.png", "11-Table5-1.png"], "referred_figures_names": ["3-Figure2-1.png"], "answer": "No"}, "859": {"question": "How did they get relations between mentions?", "referred_figures_indices": [2], "response": "{'Answer': 'They used a model that includes both ELMo embeddings for the query and candidates, processed these through bi-directional LSTMs and feed-forward layers, and incorporated relational graph convolutional networks (R-GCN). This model assesses the relationships between different mentions by evaluating the connections via induced edges and various types of relations, as depicted in the architecture and performance comparison charts. Additionally, the model's output probabilities help in discerning the relations, supported by detailed examples of query-answer instances with corresponding support passages from the dataset.'}", "all_figures_names": ["8-Table4-1.png", "12-Table6-1.png", "3-Figure2-1.png", "13-Figure3-1.png", "11-Table5-1.png", "6-Table2-1.png", "7-Table3-1.png", "1-Figure1-1.png"], "referred_figures_names": ["3-Figure2-1.png"], "answer": "Assign a value to the relation based on whether mentions occur in the same document, if mentions are identical, or if mentions are in the same coreference chain."}, "862": {"question": "What performance does the Entity-GCN get on WIKIHOP?", "referred_figures_indices": [1], "response": "{'Answer': '68.5'}", "all_figures_names": ["3-Figure2-1.png", "6-Table2-1.png", "12-Table6-1.png", "1-Figure1-1.png", "13-Figure3-1.png", "8-Table4-1.png", "11-Table5-1.png", "5-Table1-1.png"], "referred_figures_names": ["6-Table2-1.png"], "answer": "During testing: 67.6 for single model without coreference, 66.4 for single model with coreference, 71.2 for ensemble of 5 models"}}