{"1392": {"question": "How are sentence embeddings incorporated into the speech recognition system?", "referred_figures_indices": [1, 5], "response": "{'Answer': 'Sentence embeddings are incorporated into the speech recognition system by leveraging contextual and word-level embeddings in the decoding process. Both fastText and BERT embeddings are used to capture conversational context. These embeddings, combined with the current speech signal and past word embeddings, are fed into an LSTM decoder for improved recognition accuracy.'}", "all_figures_names": ["7-Figure4-1.png", "5-Figure2-1.png", "8-Figure5-1.png", "7-Figure3-1.png", "6-Table2-1.png", "4-Figure1-1.png", "5-Table1-1.png"], "referred_figures_names": ["5-Figure2-1.png", "4-Figure1-1.png"], "answer": "BERT generates sentence embeddings that represent words in context. These sentence embeddings are merged into a single conversational-context vector that is used to calculate a gated embedding and is later combined with the output of the decoder h to provide the gated activations for the next hidden layer."}}