{"845": {"question": "By how much does their best model outperform the state-of-the-art?", "referred_figures_indices": [0], "response": "{'Answer': '0.8%'}", "all_figures_names": ["5-Table3-1.png", "4-Table1-1.png", "5-Table2-1.png", "3-Figure2-1.png", "3-Figure1-1.png"], "referred_figures_names": ["5-Table3-1.png"], "answer": "0.8% F1 better than the best state-of-the-art"}, "846": {"question": "By how much does their best model outperform the state-of-the-art?", "referred_figures_indices": [1], "response": "{'Answer': '0.8%'}", "all_figures_names": ["3-Figure2-1.png", "5-Table3-1.png", "5-Table2-1.png", "3-Figure1-1.png", "4-Table1-1.png"], "referred_figures_names": ["5-Table3-1.png"], "answer": "Best proposed model achieves F1 score of 84.9 compared to best previous result of 84.1."}, "852": {"question": "How do they obtain the new context represetation?", "referred_figures_indices": [1], "response": "{'Answer': 'The new context representation is obtained through a process involving convolution and pooling layers as seen in the architecture diagram. The sentence representation is formed by applying convolutions over the embedded words of a sentence to capture local features. These features undergo pooling to summarize the information and reduce the dimensionality. Subsequently, for bidirectional representations, two such sentence representations formed from opposite directions are concatenated to provide a more comprehensive feature set that includes context from both directions in the sentence.'}", "all_figures_names": ["5-Table3-1.png", "3-Figure1-1.png", "5-Table2-1.png", "3-Figure2-1.png", "4-Table1-1.png"], "referred_figures_names": ["3-Figure1-1.png"], "answer": "They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."}}