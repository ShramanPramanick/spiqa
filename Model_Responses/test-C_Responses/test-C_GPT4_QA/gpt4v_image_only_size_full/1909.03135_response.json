{"736": {"question": "How big was the corpora they trained ELMo on?", "referred_figures_indices": [4], "response": "{'Answer': 'The ELMo model was trained on a dataset comprising approximately 2,174 million tokens for English and separately trained on a dataset containing 989 million tokens for Russian.'}", "all_figures_names": ["5-Table5-1.png", "6-Table6-1.png", "4-Table3-1.png", "4-Table4-1.png", "2-Table1-1.png", "5-Figure2-1.png", "5-Figure1-1.png", "3-Table2-1.png"], "referred_figures_names": ["2-Table1-1.png"], "answer": "2174000000, 989000000"}, "737": {"question": "How big was the corpora they trained ELMo on?", "referred_figures_indices": [6], "response": "{'Answer': 'The size of the corpora they trained ELMo on for English is approximately 2.17 billion tokens and for Russian is approximately 989 million tokens.'}", "all_figures_names": ["5-Figure2-1.png", "5-Table5-1.png", "4-Table3-1.png", "4-Table4-1.png", "6-Table6-1.png", "5-Figure1-1.png", "2-Table1-1.png", "3-Table2-1.png"], "referred_figures_names": ["2-Table1-1.png"], "answer": "2174 million tokens for English and 989 million tokens for Russian"}}