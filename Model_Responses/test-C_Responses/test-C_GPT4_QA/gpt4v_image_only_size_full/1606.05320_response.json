{"382": {"question": "What kind of features are used by the HMM models, and how interpretable are those?", "referred_figures_indices": [3, 2], "response": "{'Answer': 'Hidden Markov Models (HMMs) typically use states that correspond to the underlying process which is being modeled, and transitions among these states along with the observation probabilities of the observable events given the hidden states. The features used in an HMM can range from discrete categorical variables to continuous features that can be discretized if needed. In the provided images, it is indicated that both discretized and continuous features are used. Interpretability of HMMs generally depends on the context and complexity of the model; however, because they model probabilities of transitions and emissions explicitly, they are often considered to have a degree of interpretability", "all_figures_names": ["2-Figure1-1.png", "3-Table1-1.png", "4-Figure2-1.png", "4-Figure3-1.png"], "referred_figures_names": ["4-Figure3-1.png", "4-Figure2-1.png"], "answer": "A continuous emission HMM uses the hidden states of a 2-layer LSTM as features and a discrete emission HMM uses data as features. \nThe interpretability of the model is shown in Figure 2. "}, "383": {"question": "What kind of information do the HMMs learn that the LSTMs don't?", "referred_figures_indices": [3, 1], "response": "{'Answer': 'Hidden Markov Models (HMMs) typically learn the probabilistic transitions between latent states representing the underlying processes generating the sequence data. Unlike LSTMs, which use continuous hidden states and can theoretically remember long-term dependencies, HMMs possess discrete state spaces and their learning focuses on the direct probabilistic mappings between these states. Therefore, HMMs might explicitly capture the transition dynamics and the emission probabilities from these discrete states, while LSTMs intrinsically learn and encode this information within continuous vector representations.'}", "all_figures_names": ["2-Figure1-1.png", "4-Figure2-1.png", "3-Table1-1.png", "4-Figure3-1.png"], "referred_figures_names": ["4-Figure3-1.png", "4-Figure2-1.png"], "answer": "The HMM can identify punctuation or pick up on vowels."}, "385": {"question": "How large is the gap in performance between the HMMs and the LSTMs?", "referred_figures_indices": [2], "response": "Based on the provided images, Image 2 suggests a comparison of HMM (Hidden Markov Model) and LSTM (Long Short-Term Memory) performance on different datasets, as indicated by the log-likelihood (LL) values listed for each combination of method and configured parameters.\n\nFrom Image 2, we can extract the log-likelihood values for each method and the settings used (LSTM dimension and HMM states) for different types of data. The performance gap can be observed by comparing the LL values between HMM and LSTM for the same dimension and number of states, where a higher LL value generally indicates better performance.\n\nFor example", "all_figures_names": ["4-Figure3-1.png", "4-Figure2-1.png", "3-Table1-1.png", "2-Figure1-1.png"], "referred_figures_names": ["3-Table1-1.png"], "answer": "With similar number of parameters, the log likelihood is about 0.1 lower for LSTMs across datasets. When the number of parameters in LSTMs is increased, their log likelihood is up to 0.7 lower."}}