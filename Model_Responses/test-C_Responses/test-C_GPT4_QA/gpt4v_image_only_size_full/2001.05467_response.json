{"715": {"question": "To what other competitive baselines is this approach compared?", "referred_figures_indices": [4], "response": "{'Answer': 'The approach is compared to the following competitive baselines: LSTM (attn), MMI, VHRED (attn), MinAvgOut, LFT, RL, MinAvgOut+RL.'}", "all_figures_names": ["6-Table3-1.png", "7-Table4-1.png", "4-Figure3-1.png", "6-Table2-1.png", "5-Table1-1.png", "5-Figure6-1.png", "4-Figure4-1.png", "3-Figure2-1.png"], "referred_figures_names": ["5-Table1-1.png"], "answer": "LSTMs with and without attention, HRED, VHRED with and without attention, MMI and Reranking-RL"}, "717": {"question": "How much better were results of the proposed models than base LSTM-RNN model?", "referred_figures_indices": [7], "response": "{'Answer': 'Looking at the provided images, particularly Image 0 and Image 7, the results of the proposed models such as MinAvgOut, LFT, and MinAvgOut+RL show improvements over the base LSTM (attn) model across various metrics. Specifically, Image 0 shows that for \"Plaus.\", \"Rich\", and \"Avg.\", the base LSTM (attn) model scores are 3.46, 2.62, and 3.04 respectively, while the proposed models score higher in these categories, particularly LFT with scores of 3.83, 3.47, and", "all_figures_names": ["6-Table3-1.png", "3-Figure2-1.png", "4-Figure5-1.png", "3-Figure1-1.png", "4-Figure4-1.png", "4-Figure3-1.png", "7-Table4-1.png", "5-Table1-1.png"], "referred_figures_names": ["5-Table1-1.png"], "answer": "on diversity 6.87 and on relevance 4.6 points higher"}, "718": {"question": "Which one of the four proposed models performed best?", "referred_figures_indices": [2, 6], "response": "{'Answer': 'MinAvgOut+RL'}", "all_figures_names": ["4-Figure5-1.png", "5-Figure6-1.png", "5-Table1-1.png", "4-Figure4-1.png", "3-Figure2-1.png", "6-Table2-1.png", "7-Table4-1.png", "4-Figure3-1.png"], "referred_figures_names": ["5-Table1-1.png", "7-Table4-1.png"], "answer": "the hybrid model MinAvgOut + RL"}}