{"856": {"question": "What baseline did they compare Entity-GCN to?", "referred_figures_indices": [6], "response": "{'Answer': 'FastQA, BiDAF, Coref-GRU, MHPGM, Weaver/Jenga, MHQA-GRN'}", "all_figures_names": ["3-Figure2-1.png", "8-Table4-1.png", "11-Table5-1.png", "13-Figure3-1.png", "12-Table6-1.png", "5-Table1-1.png", "6-Table2-1.png", "1-Figure1-1.png"], "referred_figures_names": ["6-Table2-1.png"], "answer": "Human, FastQA, BiDAF, Coref-GRU, MHPGM, Weaver / Jenga, MHQA-GRN"}, "858": {"question": "Did they use a relation extraction method to construct the edges in the graph?", "referred_figures_indices": [4], "response": "{'Answer': 'Yes'}", "all_figures_names": ["8-Table4-1.png", "6-Table2-1.png", "13-Figure3-1.png", "12-Table6-1.png", "3-Figure2-1.png", "7-Table3-1.png", "11-Table5-1.png", "5-Table1-1.png"], "referred_figures_names": ["3-Figure2-1.png"], "answer": "No"}, "859": {"question": "How did they get relations between mentions?", "referred_figures_indices": [0], "response": "{'Answer': 'The relations between mentions are inferred using a model architecture that incorporates various techniques, such as an R-GCN (Relational Graph Convolutional Network), bi-LSTM (bi-directional Long Short-Term Memory networks), feed-forward layers, and embeddings like ELMo (Embeddings from Language Models). The process involves deriving context from supporting documents, entity candidates, and queries to generate probabilities of correct answers. The models are trained and evaluated on datasets, and their performance is measured in various experiments that assess factors like accuracy, precision, and impact of different model components on the outcome.'}", "all_figures_names": ["3-Figure2-1.png", "5-Table1-1.png", "7-Table3-1.png", "11-Table5-1.png", "12-Table6-1.png", "8-Table4-1.png", "13-Figure3-1.png", "6-Table2-1.png"], "referred_figures_names": ["3-Figure2-1.png"], "answer": "Assign a value to the relation based on whether mentions occur in the same document, if mentions are identical, or if mentions are in the same coreference chain."}, "862": {"question": "What performance does the Entity-GCN get on WIKIHOP?", "referred_figures_indices": [3], "response": "{'Answer': '68.5'}", "all_figures_names": ["8-Table4-1.png", "12-Table6-1.png", "7-Table3-1.png", "6-Table2-1.png", "3-Figure2-1.png", "13-Figure3-1.png", "5-Table1-1.png", "11-Table5-1.png"], "referred_figures_names": ["6-Table2-1.png"], "answer": "During testing: 67.6 for single model without coreference, 66.4 for single model with coreference, 71.2 for ensemble of 5 models"}}