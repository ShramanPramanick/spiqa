{"291": {"question": "Do they train a different training method except from scheduled sampling?", "referred_figures_indices": [4], "response": "{'Answer': 'Yes, they train different methods besides scheduled sampling. The diagrams show architectures using attention mechanisms, LSTM (Long Short-Term Memory) networks, dense layers, 2D FiLM (Feature-wise Linear Modulation) Residual Blocks, video and audio features, and an auxiliary decoder module. These components indicate a complexity in the training approach that goes beyond simple scheduled sampling.'}", "all_figures_names": ["5-Table3-1.png", "3-Figure3-1.png", "4-Table2-1.png", "1-Table1-1.png", "6-Table4-1.png", "3-Figure2-1.png", "3-Figure1-1.png"], "referred_figures_names": ["6-Table4-1.png"], "answer": "Answer with content missing: (list missing) \nScheduled sampling: In our experiments, we found that models trained with scheduled sampling performed better (about 0.004 BLEU-4 on validation set) than the ones trained using teacher-forcing for the AVSD dataset. Hence, we use scheduled sampling for all the results we report in this paper.\n\nYes."}}