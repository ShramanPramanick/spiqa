{"601": {"question": "Do they report results only on English data?", "referred_figures_indices": [1], "response": "{'Answer': 'No'}", "all_figures_names": ["4-Table4-1.png", "2-Table2-1.png", "2-Table1-1.png", "4-Table5-1.png", "3-Table3-1.png", "5-Table7-1.png", "5-Table6-1.png", "3-Figure1-1.png"], "referred_figures_names": ["2-Table2-1.png"], "answer": "Yes"}, "603": {"question": "What are the hyperparameters of the bi-GRU?", "referred_figures_indices": [1, 6], "response": "{'Answer': 'The hyperparameters of the bi-GRU include the following configurations - Dimension of word embeddings: 300 (from fastText), and the Dropout rate: 0.5. This can be inferred from Figure 1.'}", "all_figures_names": ["4-Table4-1.png", "3-Figure1-1.png", "5-Table6-1.png", "2-Table1-1.png", "5-Table7-1.png", "2-Table2-1.png", "4-Table5-1.png", "3-Table3-1.png"], "referred_figures_names": ["3-Figure1-1.png", "4-Table5-1.png"], "answer": "They use the embedding layer with a size 35 and embedding dimension of 300. They use a dense layer with 70 units and a dropout layer with a rate of 50%."}}