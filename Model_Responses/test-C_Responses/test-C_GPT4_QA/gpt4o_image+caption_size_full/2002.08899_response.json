{"874": {"question": "Do they perform a quantitative analysis of their model displaying knowledge distortions?", "referred_figures_indices": [0, 3], "response": "{'Answer': 'Yes, they perform a quantitative analysis of their model displaying knowledge distortions.'}", "all_figures_names": ["4-Table2-1.png", "2-Figure1-1.png", "4-Table1-1.png", "5-Figure2-1.png"], "referred_figures_names": ["4-Table2-1.png", "5-Figure2-1.png"], "answer": "Yes"}, "875": {"question": "How do they damage different neural modules?", "referred_figures_indices": [2], "response": "{'Answer': 'Damage to different neural modules is accomplished by randomly initializing their weights, causing the loss of all learned information. This results in artificial Wernicke\u2019s aphasia when the LSTM units are damaged, and artificial Broca\u2019s aphasia when the Lexicon Unit is damaged. The effects on performance metrics such as mean precision, recall, accuracy, and corpus-level BLEU are detailed in Table 2, with each type of damage impacting these metrics differently depending on the task.'}", "all_figures_names": ["2-Figure1-1.png", "5-Figure2-1.png", "4-Table2-1.png", "4-Table1-1.png"], "referred_figures_names": ["4-Table2-1.png"], "answer": "Damage to neural modules is done by randomly initializing their weights, causing the loss of all learned information."}}