{"909": {"question": "What is best performing model among author's submissions, what performance it had?", "referred_figures_indices": [2], "response": "{'Answer': 'The best performing model among the author\\'s submissions is the Ensemble+ of (r4, r7, r12) with postprocess in each Fold1-5 with relax-voting, \\( \\mathcal{M} \\geq 30\\% \\), which had an F1 score of .679 on the Dev (external) set.'}", "all_figures_names": ["3-Figure1-1.png", "4-Table3-1.png", "3-Table2-1.png", "4-Table4-1.png", "2-Table1-1.png"], "referred_figures_names": ["3-Table2-1.png"], "answer": "For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."}, "910": {"question": "What extracted features were most influencial on performance?", "referred_figures_indices": [3], "response": "{\n   'Answer': 'The most influential extracted features on performance were the Logistic Regression classifier with BERTSentenceEmbeddings and Linguistic, Layout, and Topical features, as they consistently produced high scores. Additionally, ensembles of models, particularly those that included post-processing, were influential in improving performance.'\n}", "all_figures_names": ["3-Table2-1.png", "2-Table1-1.png", "3-Figure1-1.png", "4-Table3-1.png", "4-Table4-1.png"], "referred_figures_names": ["4-Table3-1.png"], "answer": "Linguistic"}, "912": {"question": "Did ensemble schemes help in boosting peformance, by how much?", "referred_figures_indices": [2], "response": "{'Answer': 'Yes, ensemble schemes did help in boosting performance. For instance, in Table 3 (Image 2), the ensemble of models (r3, r6, r12) with majority-voting achieved an F1 score of .666 on the Dev (external) set, which is an improvement compared to individual models like logisticReg + BERTSentEmb which had an F1 score of .636.'}", "all_figures_names": ["3-Figure1-1.png", "2-Table1-1.png", "4-Table3-1.png", "4-Table4-1.png", "3-Table2-1.png"], "referred_figures_names": ["4-Table3-1.png"], "answer": "The best ensemble topped the best single model by 0.029 in F1 score on dev (external)."}, "913": {"question": "Did ensemble schemes help in boosting peformance, by how much?", "referred_figures_indices": [0, 3, 4], "response": "{'Answer': 'Yes, ensemble schemes boosted performance. For example, in Table 3, using the ensemble model (r15) within Fold1 for SLC resulted in a F1 score of .666 compared to .664 for the best single classifier model (r11). For FLC, the ensemble model with postprocess from each Fold1-3 (M=6) resulted in a F1 score of .164 compared to .158 for the best single model (II) as shown in Table 4.'}", "all_figures_names": ["4-Table3-1.png", "3-Figure1-1.png", "2-Table1-1.png", "3-Table2-1.png", "4-Table4-1.png"], "referred_figures_names": ["4-Table3-1.png", "3-Table2-1.png", "4-Table4-1.png"], "answer": "They increased F1 Score by 0.029 in Sentence Level Classification, and by 0.044 in Fragment-Level classification"}, "914": {"question": "Which basic neural architecture perform best by itself?", "referred_figures_indices": [0], "response": "Based on the given images and captions, the basic neural architecture that performs best by itself is BERT (specifically BERT + Fine-tune).\n\n{'Answer': 'BERT + Fine-tune'}", "all_figures_names": ["4-Table3-1.png", "4-Table4-1.png", "3-Table2-1.png", "2-Table1-1.png", "3-Figure1-1.png"], "referred_figures_names": ["4-Table3-1.png"], "answer": "BERT"}, "915": {"question": "What participating systems had better results than ones authors submitted?", "referred_figures_indices": [2], "response": "{'Answer': 'r10, r11, r12, r17, r18, r19, r20, r21, r22, r23, r24, r25, r26, r27, r28'}", "all_figures_names": ["4-Table3-1.png", "4-Table4-1.png", "3-Table2-1.png", "2-Table1-1.png", "3-Figure1-1.png"], "referred_figures_names": ["3-Table2-1.png"], "answer": "For SLC task : Ituorp, ProperGander and YMJA  teams had better results.\nFor FLC task: newspeak and Antiganda teams had better results."}, "916": {"question": "What is specific to multi-granularity and multi-tasking neural arhiteture design?", "referred_figures_indices": [0], "response": "{'Answer': 'The multi-granularity and multi-tasking neural architecture design involves incorporating several layers of tasks, such as Propaganda Fragment Detection (PFD), Fine-grained Label Classification (FLC), and Sentence-level Classification (SLC). This design signifies that multiple tasks are performed jointly at different levels of granularity, leveraging a recurrent architecture that integrates Long Short-Term Memory (LSTM) networks, Conditional Random Fields (CRF), and various classifiers like Logistic Regression, CNN, and BERT fine-tuning. The architecture maximizes performance by using transfer learning with pre-trained embeddings like FastText and BERT, and employing an", "all_figures_names": ["3-Figure1-1.png", "4-Table3-1.png", "2-Table1-1.png", "3-Table2-1.png", "4-Table4-1.png"], "referred_figures_names": ["3-Figure1-1.png"], "answer": "An output layer for each task"}}