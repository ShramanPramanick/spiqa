{"214": {"question": "What is the results of multimodal compared to unimodal models?", "referred_figures_indices": [1, 5], "response": "{'Answer': 'Multimodal models, which utilize both text and image inputs, generally perform better in hate speech detection compared to unimodal models that use only one type of input. For instance, models like FCM, SCM, and TKM which use multiple inputs (TT, IT, I) achieve higher AUC and ACC scores compared to the FCM model using only images (I).'}", "all_figures_names": ["4-Figure3-1.png", "7-Table1-1.png", "6-Figure4-1.png", "3-Figure2-1.png", "6-Figure5-1.png", "7-Figure6-1.png", "2-Figure1-1.png", "7-Figure7-1.png"], "referred_figures_names": ["7-Table1-1.png", "7-Figure6-1.png"], "answer": "Unimodal LSTM vs Best Multimodal (FCM)\n- F score: 0.703 vs 0.704\n- AUC: 0.732 vs 0.734 \n- Mean Accuracy: 68.3 vs 68.4 "}}