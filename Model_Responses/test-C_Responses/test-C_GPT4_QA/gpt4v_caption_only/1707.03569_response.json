{"812": {"question": "By how much did they improve?", "referred_figures_indices": [4, 0], "response": "{'Answer': 'The improvement is not quantified in the given captions, but the best performance is achieved in the multitask setting with the biLSTM architecture.'}", "all_figures_names": ["5-Table3-1.png", "3-Table2-1.png", "2-Table1-1.png", "5-Figure2-1.png", "3-Figure1-1.png"], "referred_figures_names": ["3-Figure1-1.png", "5-Table3-1.png"], "answer": "They decrease MAE in 0.34"}, "813": {"question": "What dataset did they use?", "referred_figures_indices": [2], "response": "{'Answer': 'The dataset used is not explicitly mentioned in the provided captions.'}", "all_figures_names": ["5-Table3-1.png", "3-Figure1-1.png", "3-Table2-1.png", "5-Figure2-1.png", "2-Table1-1.png"], "referred_figures_names": ["3-Table2-1.png"], "answer": " high-quality datasets  from SemEval-2016 \u201cSentiment Analysis in Twitter\u201d task"}}