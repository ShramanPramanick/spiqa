{"2": {"question": "What are the results?", "referred_figures_indices": [5, 0], "response": "{'Answer': 'The results include the performance of various models on the ACP test set (Caption 0), details of the ACP dataset (Caption 1), statistics of the AL, CA, and CO datasets (Caption 2), examples of polarity scores predicted by the BiGRU model trained with AL+CA+CO (Caption 3), and results for small labeled training data using BERT trained only with the AL data (Caption 5).'}", "all_figures_names": ["5-Table3-1.png", "4-Table2-1.png", "4-Table1-1.png", "5-Table5-1.png", "2-Figure1-1.png", "5-Table4-1.png"], "referred_figures_names": ["5-Table4-1.png", "5-Table3-1.png"], "answer": "Using all data to train: AL -- BiGRU achieved 0.843 accuracy, AL -- BERT achieved 0.863 accuracy, AL+CA+CO -- BiGRU achieved 0.866 accuracy, AL+CA+CO -- BERT achieved 0.835, accuracy, ACP -- BiGRU achieved 0.919 accuracy, ACP -- BERT achived 0.933, accuracy, ACP+AL+CA+CO -- BiGRU achieved 0.917 accuracy, ACP+AL+CA+CO -- BERT achieved 0.913 accuracy. \nUsing a subset to train: BERT achieved 0.876 accuracy using ACP (6K), BERT achieved 0.886 accuracy using ACP (6K) + AL, BiGRU achieved 0.830 accuracy using ACP (6K), BiGRU achieved 0.879 accuracy using ACP (6K) + AL + CA + CO."}, "3": {"question": "How are relations used to propagate polarity?", "referred_figures_indices": [2], "response": "{'Answer': 'Relations are used to propagate polarity by connecting pairs of events with a discourse relation, such as CAUSE or CONCESSION. The polarity of the latter event is propagated to the former event, with the same polarity used for CAUSE and the reversed polarity for CONCESSION. In the case of unknown polarity for the latter event, the discourse relation encourages the polarities of the two events to be the same for CAUSE and reversed for CONCESSION.'}", "all_figures_names": ["5-Table5-1.png", "5-Table4-1.png", "2-Figure1-1.png", "4-Table1-1.png", "4-Table2-1.png", "5-Table3-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "based on the relation between events, the suggested polarity of one event can determine the possible polarity of the other event "}, "4": {"question": "How are relations used to propagate polarity?", "referred_figures_indices": [0], "response": "{'Answer': 'Relations are used to propagate polarity by analyzing the connection between pairs of events and their associated discourse relation. In the case of a CAUSE relation, the polarity of the latter event is propagated to the former event with the same polarity. In the case of a CONCESSION relation, the polarity is reversed. For events where the latter event's polarity is not known, the polarities are encouraged to be the same for a CA relation and reversed for a CO relation.'}", "all_figures_names": ["2-Figure1-1.png", "4-Table1-1.png", "5-Table3-1.png", "5-Table5-1.png", "4-Table2-1.png", "5-Table4-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "cause relation: both events in the relation should have the same polarity; concession relation: events should have opposite polarity"}, "5": {"question": "How big is the Japanese data?", "referred_figures_indices": [5, 1], "response": "{'Answer': 'The size of the Japanese data is not specified in the input captions.'}", "all_figures_names": ["5-Table4-1.png", "4-Table1-1.png", "2-Figure1-1.png", "5-Table3-1.png", "5-Table5-1.png", "4-Table2-1.png"], "referred_figures_names": ["4-Table2-1.png", "4-Table1-1.png"], "answer": "7000000 pairs of events were extracted from the Japanese Web corpus, 529850 pairs of events were extracted from the ACP corpus"}, "6": {"question": "How big is the Japanese data?", "referred_figures_indices": [4], "response": "{'Answer': 'The size of the Japanese data is not explicitly mentioned in the provided captions.'}", "all_figures_names": ["5-Table3-1.png", "5-Table4-1.png", "4-Table1-1.png", "5-Table5-1.png", "4-Table2-1.png", "2-Figure1-1.png"], "referred_figures_names": ["4-Table2-1.png"], "answer": "The ACP corpus has around 700k events split into positive and negative polarity "}, "8": {"question": "How big are improvements of supervszed learning results trained on smalled labeled data enhanced with proposed approach copared to basic approach?", "referred_figures_indices": [5], "response": "{'Answer': 'The captions provided do not contain specific information about the improvements of supervised learning results trained on small labeled data enhanced with the proposed approach compared to the basic approach. Therefore, it is not possible to answer the question based on the given input captions.'}", "all_figures_names": ["2-Figure1-1.png", "4-Table1-1.png", "4-Table2-1.png", "5-Table5-1.png", "5-Table3-1.png", "5-Table4-1.png"], "referred_figures_names": ["5-Table4-1.png"], "answer": "3%"}, "9": {"question": "How does their model learn using mostly raw data?", "referred_figures_indices": [2], "response": "{'Answer': 'Their model learns using mostly raw data by focusing on pairs of events connected with a discourse relation and dividing them into three types: AL, CA, and CO. In AL, the polarity of a latter event is automatically identified and propagated to the former event. In CA and CO, the polarities are encouraged to be the same or reversed depending on the discourse relation. This method allows the model to learn from the raw data without requiring extensive labeled training data.'}", "all_figures_names": ["5-Table3-1.png", "5-Table4-1.png", "2-Figure1-1.png", "5-Table5-1.png", "4-Table2-1.png", "4-Table1-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "by exploiting discourse relations to propagate polarity from seed predicates to final sentiment polarity"}, "10": {"question": "How big is seed lexicon used for training?", "referred_figures_indices": [3], "response": "{'Answer': 'The size of the seed lexicon used for training is not explicitly mentioned in the provided captions.'}", "all_figures_names": ["5-Table4-1.png", "4-Table2-1.png", "2-Figure1-1.png", "4-Table1-1.png", "5-Table3-1.png", "5-Table5-1.png"], "referred_figures_names": ["4-Table1-1.png"], "answer": "30 words"}}