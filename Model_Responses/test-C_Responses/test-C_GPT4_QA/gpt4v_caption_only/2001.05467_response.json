{"715": {"question": "To what other competitive baselines is this approach compared?", "referred_figures_indices": [4], "response": "{'Answer': 'LSTM, HRED, VHRED, VHRED (attn), Reranking-RL, MMI'}", "all_figures_names": ["4-Figure5-1.png", "6-Table2-1.png", "5-Figure6-1.png", "6-Table3-1.png", "5-Table1-1.png", "4-Figure4-1.png", "4-Figure3-1.png", "3-Figure2-1.png"], "referred_figures_names": ["5-Table1-1.png"], "answer": "LSTMs with and without attention, HRED, VHRED with and without attention, MMI and Reranking-RL"}, "717": {"question": "How much better were results of the proposed models than base LSTM-RNN model?", "referred_figures_indices": [7], "response": "{'Answer': 'The proposed models had statistically significantly higher F1 values against VHRED (attn) and MMI, and human evaluation results showed best results in plausibility, richness, and scaled difference for our models, indicating that the proposed models performed better than the base LSTM-RNN model.'}", "all_figures_names": ["6-Table2-1.png", "5-Figure6-1.png", "3-Figure2-1.png", "4-Figure4-1.png", "3-Figure1-1.png", "4-Figure5-1.png", "6-Table3-1.png", "5-Table1-1.png"], "referred_figures_names": ["5-Table1-1.png"], "answer": "on diversity 6.87 and on relevance 4.6 points higher"}, "718": {"question": "Which one of the four proposed models performed best?", "referred_figures_indices": [6, 0], "response": "{'Answer': 'Not enough information provided to determine which model performed best.'}", "all_figures_names": ["5-Table1-1.png", "6-Table3-1.png", "3-Figure1-1.png", "4-Figure3-1.png", "4-Figure5-1.png", "4-Figure4-1.png", "7-Table4-1.png", "3-Figure2-1.png"], "referred_figures_names": ["7-Table4-1.png", "5-Table1-1.png"], "answer": "the hybrid model MinAvgOut + RL"}}