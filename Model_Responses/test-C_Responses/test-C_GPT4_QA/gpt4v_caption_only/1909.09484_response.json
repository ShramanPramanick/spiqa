{"720": {"question": "How much is proposed model better than baselines in performed experiments?", "referred_figures_indices": [3], "response": "{'Answer': 'The proposed model is better than baselines in performed experiments as it can hold more information about dialogue policy, has a bigger model size with more dialogue policy parameters due to the RNN-based dialogue policy maker, and is more effective in handling complex datasets with continuous value spaces.'}", "all_figures_names": ["6-Table1-1.png", "2-Figure1-1.png", "4-Figure2-1.png", "7-Table2-1.png", "8-Figure3-1.png", "8-Table3-1.png"], "referred_figures_names": ["7-Table2-1.png"], "answer": "most of the models have similar performance on BPRA: DSTC2 (+0.0015), Maluuba (+0.0729)\nGDP achieves the best performance in APRA: DSTC2 (+0.2893), Maluuba (+0.2896)\nGDP significantly outperforms the baselines on BLEU: DSTC2 (+0.0791), Maluuba (+0.0492)"}}