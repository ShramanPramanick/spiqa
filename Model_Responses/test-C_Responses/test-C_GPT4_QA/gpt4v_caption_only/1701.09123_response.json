{"951": {"question": "what are the evaluation metrics?", "referred_figures_indices": [0], "response": "{'Answer': 'T-F1 (token-based F1), Local model (L), cluster model (C), difference between them (\u2206), text genre, shallow local features, linguistic features, global features, gazetteers, word representation features, manually encoded rules, stack of classifiers or ensemble system, publicly distributed system.'}", "all_figures_names": ["15-Table5-1.png", "20-Table16-1.png", "19-Table14-1.png", "21-Table17-1.png", "16-Table7-1.png", "19-Table15-1.png", "6-Table2-1.png", "18-Table13-1.png"], "referred_figures_names": ["15-Table5-1.png"], "answer": "Precision, Recall, F1"}, "952": {"question": "which datasets were used in evaluation?", "referred_figures_indices": [7], "response": "{'Answer': 'Basque Egunkaria, GermEval 2014, MEANTIME, Wikigold, CoNLL 2002, MUC7, SONAR-1, Ancora 2.0'}", "all_figures_names": ["18-Table12-1.png", "15-Table6-1.png", "22-Table18-1.png", "21-Table17-1.png", "22-Table19-1.png", "16-Table9-1.png", "11-Figure1-1.png", "5-Table1-1.png"], "referred_figures_names": ["5-Table1-1.png"], "answer": "CoNLL 2003, GermEval 2014, CoNLL 2002, Egunkaria, MUC7, Wikigold, MEANTIME, SONAR-1, Ancora 2.0"}}