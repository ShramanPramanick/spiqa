{"48": {"question": "Do they report results only on English datasets?", "referred_figures_indices": [0, 7], "response": "{'Answer': 'No, they report results on datasets other than just English.'}", "all_figures_names": ["10-Table4-1.png", "16-Table7-1.png", "8-Table1-1.png", "9-Table3-1.png", "15-Figure3-1.png", "14-Table6-1.png", "12-Table5-1.png", "9-Table2-1.png"], "referred_figures_names": ["10-Table4-1.png", "9-Table2-1.png"], "answer": "Yes"}, "51": {"question": "Do they test their approach on a dataset without incomplete data?", "referred_figures_indices": [4], "response": "{'Answer': 'Yes, they do test their approach on a dataset without incomplete data.'}", "all_figures_names": ["5-Figure1-1.png", "9-Table3-1.png", "14-Table6-1.png", "15-Figure3-1.png", "11-Figure2-1.png", "16-Table7-1.png", "12-Table5-1.png", "9-Table2-1.png"], "referred_figures_names": ["11-Figure2-1.png"], "answer": "No"}, "52": {"question": "Do they test their approach on a dataset without incomplete data?", "referred_figures_indices": [7], "response": "{'Answer': 'Yes, they do test their approach on a dataset without incomplete data.'}", "all_figures_names": ["5-Figure1-1.png", "9-Table2-1.png", "15-Figure3-1.png", "17-Figure5-1.png", "14-Table6-1.png", "17-Figure4-1.png", "16-Table7-1.png", "8-Table1-1.png"], "referred_figures_names": ["8-Table1-1.png"], "answer": "No"}, "53": {"question": "Should their approach be applied only when dealing with incomplete data?", "referred_figures_indices": [4], "response": "{'Answer': 'No'}", "all_figures_names": ["9-Table2-1.png", "9-Table3-1.png", "17-Figure5-1.png", "15-Figure3-1.png", "14-Table6-1.png", "8-Table1-1.png", "17-Figure4-1.png", "10-Table4-1.png"], "referred_figures_names": ["14-Table6-1.png"], "answer": "No"}, "54": {"question": "Should their approach be applied only when dealing with incomplete data?", "referred_figures_indices": [2], "response": "{'Answer': 'No, their approach should not be applied only when dealing with incomplete data. The information provided across the images and captions indicates that the proposed Stacked DeBERT model is also effective on complete data. The model shows robustness to both clean and noisy data, suggesting it can be generally applied beyond just scenarios with incomplete information.'}", "all_figures_names": ["10-Table4-1.png", "11-Figure2-1.png", "5-Figure1-1.png", "8-Table1-1.png", "17-Figure5-1.png", "14-Table6-1.png", "15-Figure3-1.png", "16-Table7-1.png"], "referred_figures_names": ["5-Figure1-1.png"], "answer": "No"}, "55": {"question": "By how much do they outperform other models in the sentiment in intent classification tasks?", "referred_figures_indices": [5, 4], "response": "{'Answer': 'The Stacked DeBERT model outperforms other models by various margins depending on the dataset and condition. For the Twitter Sentiment Classification task on Kaggle\u2019s Sentiment140 Corpus, Stacked DeBERT's F1-micro score is 80.00% for the original dataset (Inc), which is 8.00% higher than the next best model, BERT, which scored 72.00%. In the corrected version of the dataset (Corr), Stacked DeBERT achieved 82.00%, which is 6.00% higher than BERT at 76.00%. For the", "all_figures_names": ["11-Figure2-1.png", "9-Table2-1.png", "17-Figure4-1.png", "10-Table4-1.png", "14-Table6-1.png", "16-Table7-1.png", "15-Figure3-1.png", "8-Table1-1.png"], "referred_figures_names": ["16-Table7-1.png", "14-Table6-1.png"], "answer": "In the sentiment classification task by 6% to 8% and in the intent classification task by 0.94% on average"}}