{"296": {"question": "what is the state of the art?", "referred_figures_indices": [0], "response": "{'Answer': 'Based on the provided input images and captions, the state of the art in named entity recognition (NER) can be inferred from the highest F1 scores reported in the tables. For the common English news texts datasets (CoNLL2003, KORE50, ACE2004, MSNBC), \"Stanford NER\" with a method described as \"CRF+Dist\" shows the highest F1 score of 89.3% on MSNBC dataset (as per Caption 0, Image 0).\n\nFor the biomedical text dataset (GENIA), \"LingPipe GENIA\" with a \"DICT\"", "all_figures_names": ["6-Table2-1.png", "3-Figure1-1.png", "7-Table3-1.png", "7-Table4-1.png", "5-Table1-1.png"], "referred_figures_names": ["6-Table2-1.png"], "answer": "Babelfy, DBpedia Spotlight, Entityclassifier.eu, FOX, LingPipe MUC-7, NERD-ML, Stanford NER, TagMe 2"}}