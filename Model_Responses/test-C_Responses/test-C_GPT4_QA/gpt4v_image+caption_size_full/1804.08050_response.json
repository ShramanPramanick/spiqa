{"1259": {"question": "By how much does their method outperform the multi-head attention model?", "referred_figures_indices": [3], "response": "{\n  'Answer': 'For Task 1, the method outperforms the multi-head attention model by 0.2% (MHA-Loc 11.5% to HMHD 11.3%). For Task 2, the improvement is 0.5% (MHA-Loc 8.6% to HMHD 8.1%). For Task 3, the method outperforms the multi-head attention model by 0.1% (MHA-Loc 9.0% to HMHD 8.9%).'\n}", "all_figures_names": ["3-Figure2-1.png", "4-Table1-1.png", "2-Figure1-1.png", "4-Table2-1.png", "4-Figure3-1.png"], "referred_figures_names": ["4-Table2-1.png"], "answer": "Their average improvement in Character Error Rate over the best MHA model was 0.33 percent points."}, "1260": {"question": "How large is the corpus they use?", "referred_figures_indices": [3], "response": "{'Answer': 'The corpus they use for training consists of 445,068 utterances, which corresponds to 581 hours of data.'}", "all_figures_names": ["3-Figure2-1.png", "4-Figure3-1.png", "4-Table2-1.png", "4-Table1-1.png", "2-Figure1-1.png"], "referred_figures_names": ["4-Table1-1.png"], "answer": "449050"}}