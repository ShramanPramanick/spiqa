{"909": {"question": "What is best performing model among author's submissions, what performance it had?", "referred_figures_indices": [4], "response": "{'Answer': 'r23 relax-voting, |M| \u2265 30% with .852 F1 score'}", "all_figures_names": ["2-Table1-1.png", "4-Table3-1.png", "3-Figure1-1.png", "4-Table4-1.png", "3-Table2-1.png"], "referred_figures_names": ["3-Table2-1.png"], "answer": "For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."}, "910": {"question": "What extracted features were most influencial on performance?", "referred_figures_indices": [4], "response": "{'Answer': 'BERT Sentence Embeddings and ensembles with relaxed voting thresholds were most influential on performance.'}", "all_figures_names": ["4-Table4-1.png", "3-Table2-1.png", "3-Figure1-1.png", "2-Table1-1.png", "4-Table3-1.png"], "referred_figures_names": ["4-Table3-1.png"], "answer": "Linguistic"}, "912": {"question": "Did ensemble schemes help in boosting peformance, by how much?", "referred_figures_indices": [0], "response": "{'Answer': 'Yes, ensemble schemes helped in boosting performance. For the SLC task, the ensemble led to an improvement of up to 0.107 in F1 score for the internal Dev set and up to 0.145 in F1 score for the external Dev set. For the FLC task, the ensemble led to an improvement of up to 0.048 in F1 score for the internal Dev set and up to 0.069 in F1 score for the external Dev set.'}", "all_figures_names": ["4-Table3-1.png", "4-Table4-1.png", "3-Figure1-1.png", "2-Table1-1.png", "3-Table2-1.png"], "referred_figures_names": ["4-Table3-1.png"], "answer": "The best ensemble topped the best single model by 0.029 in F1 score on dev (external)."}, "913": {"question": "Did ensemble schemes help in boosting peformance, by how much?", "referred_figures_indices": [0, 4, 1], "response": "{'Answer': 'Yes, ensemble schemes helped in boosting performance. In Image 1, the ensemble of classifiers (r3, r6, r12) achieved an F1 score of 0.679 when using the \"relax-voting, |M| \u2265 30%\" method, which is higher compared to individual classifiers (such as r3 with F1 of 0.614, and r6 with F1 of 0.612). Additionally, Image 4 shows that Ensemble+ of (II and IV) from each Fold1-3 with postprocess achieved the highest F1 score of 0.164", "all_figures_names": ["3-Table2-1.png", "4-Table3-1.png", "2-Table1-1.png", "3-Figure1-1.png", "4-Table4-1.png"], "referred_figures_names": ["3-Table2-1.png", "4-Table4-1.png", "4-Table3-1.png"], "answer": "They increased F1 Score by 0.029 in Sentence Level Classification, and by 0.044 in Fragment-Level classification"}, "914": {"question": "Which basic neural architecture perform best by itself?", "referred_figures_indices": [4], "response": "{'Answer': 'BERT with Fine-tune'}", "all_figures_names": ["3-Table2-1.png", "2-Table1-1.png", "3-Figure1-1.png", "4-Table4-1.png", "4-Table3-1.png"], "referred_figures_names": ["4-Table3-1.png"], "answer": "BERT"}, "915": {"question": "What participating systems had better results than ones authors submitted?", "referred_figures_indices": [2], "response": "{'Answer': 'Ensemble+ (r3, r6, r12) from each Fold1-5, i.e., |M| = 15 (r19) and Ensemble of (r4, r7, r12) within Fold1 (r22) had better results than ones authors submitted (MIC-CIS).'}", "all_figures_names": ["4-Table3-1.png", "2-Table1-1.png", "3-Table2-1.png", "3-Figure1-1.png", "4-Table4-1.png"], "referred_figures_names": ["3-Table2-1.png"], "answer": "For SLC task : Ituorp, ProperGander and YMJA  teams had better results.\nFor FLC task: newspeak and Antiganda teams had better results."}, "916": {"question": "What is specific to multi-granularity and multi-tasking neural arhiteture design?", "referred_figures_indices": [2], "response": "{'Answer': 'Multi-granularity and multi-tasking neural architecture designs refer to models that integrate different levels of analysis (granularity) or types of tasks into a single cohesive framework. From the provided images and captions, we can see that such architectures might combine various features like linguistic, layout, and topical information, utilize different embedding techniques (e.g., FastText and BERT), and apply an ensemble of classifiers (e.g., Logistic Regression, CNN, BERT with fine-tuning) to improve the performance of tasks such as propaganda detection. These tasks may include sentence-level classification (SLC) and finer-grained fragment-level", "all_figures_names": ["4-Table3-1.png", "2-Table1-1.png", "3-Figure1-1.png", "3-Table2-1.png", "4-Table4-1.png"], "referred_figures_names": ["3-Figure1-1.png"], "answer": "An output layer for each task"}}