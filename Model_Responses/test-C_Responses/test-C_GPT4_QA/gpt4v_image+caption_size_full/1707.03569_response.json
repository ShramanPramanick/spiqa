{"812": {"question": "By how much did they improve?", "referred_figures_indices": [1, 3], "response": "{'Answer': 'From the single task to the multitask setting, the F1 score improved from 0.469 to 0.481, and the MAEM score improved from 0.694\u00b10.04 to 0.685\u00b10.024.'}", "all_figures_names": ["2-Table1-1.png", "3-Figure1-1.png", "5-Figure2-1.png", "5-Table3-1.png", "3-Table2-1.png"], "referred_figures_names": ["3-Figure1-1.png", "5-Table3-1.png"], "answer": "They decrease MAE in 0.34"}, "813": {"question": "What dataset did they use?", "referred_figures_indices": [1], "response": "{'Answer': 'The dataset used in the study consisted of Twitter message data, as indicated by Table 1 which demonstrates various levels of sentiment in tweets.'}", "all_figures_names": ["5-Table3-1.png", "3-Table2-1.png", "5-Figure2-1.png", "3-Figure1-1.png", "2-Table1-1.png"], "referred_figures_names": ["3-Table2-1.png"], "answer": " high-quality datasets  from SemEval-2016 \u201cSentiment Analysis in Twitter\u201d task"}}