{"382": {"question": "What kind of features are used by the HMM models, and how interpretable are those?", "referred_figures_indices": [0, 1], "response": "{'Answer': 'HMM models use features that can range from discrete binary or multinary symbols to continuous-valued features. The interpretable nature of these features depends on how they are presented or visualized. In the hybrid HMM-LSTM model described by the provided information, the HMM component appears to complement the LSTM by learning features related to specific character structures such as spaces and comments in text data, as visualized in Image 0. Moreover, the decision tree in Image 1 provides insight into the decision-making process for predicting an individual hidden state dimension, indicating a level of interpretability regarding which preceding characters influence certain states.", "all_figures_names": ["4-Figure2-1.png", "4-Figure3-1.png", "2-Figure1-1.png", "3-Table1-1.png"], "referred_figures_names": ["4-Figure2-1.png", "4-Figure3-1.png"], "answer": "A continuous emission HMM uses the hidden states of a 2-layer LSTM as features and a discrete emission HMM uses data as features. \nThe interpretability of the model is shown in Figure 2. "}, "383": {"question": "What kind of information do the HMMs learn that the LSTMs don't?", "referred_figures_indices": [0, 2], "response": "{'Answer': 'HMMs learn some complementary features in the text related to spaces and comments that LSTMs do not.'}", "all_figures_names": ["4-Figure2-1.png", "3-Table1-1.png", "4-Figure3-1.png", "2-Figure1-1.png"], "referred_figures_names": ["4-Figure2-1.png", "4-Figure3-1.png"], "answer": "The HMM can identify punctuation or pick up on vowels."}, "385": {"question": "How large is the gap in performance between the HMMs and the LSTMs?", "referred_figures_indices": [2], "response": "{'Answer': 'The gap in performance between HMMs and LSTMs varies depending on the dataset and the configuration of the models. On the Linux text data, the best LSTM model with a dimensionality of 20 has a loglikelihood (LL) of -1.88, while the best HMM model with 20 states has an LL of -2.55, which shows a considerable gap in performance. In the Shakespeare text data, the best LSTM model (20 dimensions) has an LL of -2.02 and the best HMM (20 states) an LL of -2.51, again showing a notable", "all_figures_names": ["4-Figure2-1.png", "4-Figure3-1.png", "3-Table1-1.png", "2-Figure1-1.png"], "referred_figures_names": ["3-Table1-1.png"], "answer": "With similar number of parameters, the log likelihood is about 0.1 lower for LSTMs across datasets. When the number of parameters in LSTMs is increased, their log likelihood is up to 0.7 lower."}}