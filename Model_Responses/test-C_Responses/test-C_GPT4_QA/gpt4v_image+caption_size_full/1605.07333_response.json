{"845": {"question": "By how much does their best model outperform the state-of-the-art?", "referred_figures_indices": [2], "response": "{'Answer': 'The best model outperforms the state-of-the-art by 0.8.'}", "all_figures_names": ["3-Figure1-1.png", "5-Table2-1.png", "5-Table3-1.png", "3-Figure2-1.png", "4-Table1-1.png"], "referred_figures_names": ["5-Table3-1.png"], "answer": "0.8% F1 better than the best state-of-the-art"}, "846": {"question": "By how much does their best model outperform the state-of-the-art?", "referred_figures_indices": [4], "response": "{'Answer': 'By 0.8%'}", "all_figures_names": ["3-Figure1-1.png", "4-Table1-1.png", "3-Figure2-1.png", "5-Table2-1.png", "5-Table3-1.png"], "referred_figures_names": ["5-Table3-1.png"], "answer": "Best proposed model achieves F1 score of 84.9 compared to best previous result of 84.1."}, "852": {"question": "How do they obtain the new context represetation?", "referred_figures_indices": [1], "response": "{'Answer': 'The new context representation is obtained by utilizing various neural network architectures and strategies. For the RNN, it involves starting with a unidirectional baseline and incrementally adding components such as position embeddings, entity flag, position indicators, converting to a bi-directional approach, adding a connectionist architecture, incorporating a ranking layer, and increasing the embedding dimension to 400. For the CNN, they start with a baseline and add position features, create a multi-windows features map, add a ranking layer, extend the middle context, and also increase the embedding dimension to 400. Ensemble methods are used in both cases to further improve", "all_figures_names": ["5-Table2-1.png", "3-Figure1-1.png", "4-Table1-1.png", "5-Table3-1.png", "3-Figure2-1.png"], "referred_figures_names": ["3-Figure1-1.png"], "answer": "They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."}}