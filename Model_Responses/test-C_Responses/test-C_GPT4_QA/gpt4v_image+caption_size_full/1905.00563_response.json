{"96": {"question": "What datasets are used to evaluate this approach?", "referred_figures_indices": [4], "response": "{'Answer': 'YAGO3-10, WN18, Nations, Kinship'}", "all_figures_names": ["7-Table4-1.png", "2-Figure1-1.png", "7-Table5-1.png", "6-Table3-1.png", "5-Table2-1.png", "5-Table1-1.png", "7-Figure4-1.png", "4-Figure2-1.png"], "referred_figures_names": ["5-Table2-1.png"], "answer": " Kinship and Nations knowledge graphs, YAGO3-10 and WN18KGs knowledge graphs "}, "99": {"question": "Can this adversarial approach be used to directly improve model accuracy?", "referred_figures_indices": [4], "response": "{'Answer': 'The provided images and captions focus on the impact of adversarial approaches on link prediction models in knowledge graphs, specifically the robustness of such models to adversarial attacks. From the results shown, while adversarial approaches such as modifying data with adversarial examples (like adding random or opposite attacks, or using CRIAGE for targeted modifications) seem to negatively affect model performance based on metrics like MRR and Hits@1, these approaches do not directly improve model accuracy. Instead, they reveal the vulnerabilities and robustness of models to adversarial conditions. Adversarial approaches serve as an evaluation tool to understand how a model behaves", "all_figures_names": ["5-Table2-1.png", "5-Figure3-1.png", "7-Table4-1.png", "7-Figure4-1.png", "12-Table7-1.png", "4-Figure2-1.png", "6-Table3-1.png", "7-Table5-1.png"], "referred_figures_names": ["12-Table7-1.png"], "answer": "Yes"}}