{"220": {"question": "How many people participated in their evaluation study of table-to-text models?", "referred_figures_indices": [3], "response": "Based on the given captions, none of them provides information about the number of people who participated in the evaluation study for table-to-text models. Therefore, I can't extract the exact answer from the input captions provided.\n\n{'Answer': 'The provided captions do not specify this information'}", "all_figures_names": ["12-Table6-1.png", "8-Table4-1.png", "9-Figure5-1.png", "5-Table1-1.png", "7-Figure4-1.png", "11-Table5-1.png", "11-Figure6-1.png", "6-Table2-1.png"], "referred_figures_names": ["5-Table1-1.png"], "answer": "about 500"}, "222": {"question": "By how much more does PARENT correlate with human judgements in comparison to other text generation metrics?", "referred_figures_indices": [7, 0, 4], "response": "{'Answer': 'PARENT significantly outperforms other text generation metrics in correlation with human judgments, as indicated by the superscripts in Table 2, which denote lower correlations for the other metrics using a bootstrap confidence test for \u03b1 = 0.1.'}", "all_figures_names": ["6-Table2-1.png", "8-Table3-1.png", "6-Figure2-1.png", "2-Figure1-1.png", "8-Table4-1.png", "11-Table5-1.png", "5-Table1-1.png", "7-Figure3-1.png"], "referred_figures_names": ["7-Figure3-1.png", "6-Table2-1.png", "8-Table4-1.png"], "answer": "Best proposed metric has average correlation with human judgement of 0.913 and 0.846 compared to best compared metrics result of 0.758 and 0.829 on WikiBio and WebNLG challenge."}, "223": {"question": "By how much more does PARENT correlate with human judgements in comparison to other text generation metrics?", "referred_figures_indices": [5], "response": "```json\n{\n    \"Answer\": \"The exact numerical difference is not provided in the presented captions, but it is indicated that the correlation of other metrics with human judgments is significantly lower than that of PARENT's correlation as shown in Table 2.\"\n}\n```", "all_figures_names": ["11-Figure6-1.png", "9-Figure5-1.png", "5-Table1-1.png", "12-Table6-1.png", "7-Figure3-1.png", "6-Table2-1.png", "2-Figure1-1.png", "6-Figure2-1.png"], "referred_figures_names": ["6-Table2-1.png"], "answer": "Their average correlation tops the best other model by 0.155 on WikiBio."}}