{"93": {"question": "Did the annotators agreed and how much?", "referred_figures_indices": [7], "response": "```json\n{\n  \"Answer\": \"Yes, the annotators agreed. The amount of agreement can be found in Figure 4: Inter-annotator agreement statistics.\"\n}\n```", "all_figures_names": ["2-Figure2-1.png", "6-Figure6-1.png", "7-Figure8-1.png", "4-Figure3-1.png", "8-Figure11-1.png", "1-Figure1-1.png", "2-Table1-1.png", "6-Figure4-1.png"], "referred_figures_names": ["6-Figure4-1.png"], "answer": "For event types and participant types, there was a moderate to substantial level of agreement using the Fleiss' Kappa. For coreference chain annotation, there was average agreement of 90.5%."}, "94": {"question": "Did the annotators agreed and how much?", "referred_figures_indices": [0], "response": "```json\n{\n  \"Answer\": \"The question about inter-annotator agreement is referenced in Caption 0, which suggests that Figure 4 contains statistics related to inter-annotator agreement. However, the exact level of agreement is not provided in these captions.\"\n}\n```", "all_figures_names": ["6-Figure4-1.png", "8-Figure10-1.png", "2-Table1-1.png", "7-Figure9-1.png", "3-Table2-1.png", "8-Figure11-1.png", "4-Figure3-1.png", "7-Figure8-1.png"], "referred_figures_names": ["6-Figure4-1.png"], "answer": "Moderate agreement of 0.64-0.68 Fleiss\u2019 Kappa over event type labels, 0.77 Fleiss\u2019 Kappa over participant labels, and good agreement of 90.5% over coreference information."}}