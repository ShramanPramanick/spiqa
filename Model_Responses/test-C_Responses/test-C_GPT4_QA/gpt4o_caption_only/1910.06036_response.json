{"654": {"question": "How they extract \"structured answer-relevant relation\"?", "referred_figures_indices": [5], "response": "Based on the provided captions, the most relevant information pertaining to the extraction of \"structured answer-relevant relation\" can be found in Caption 4.\n\nCaption 4 provides insights on how n-ary extractions from sentences are conducted using OpenIE (Open Information Extraction). The relationships within sentences are extracted, and confidence scores are assigned to each relation. Specific relations are then selected based on certain criteria detailed in Section 2.2.\n\nTherefore, the direct answer to the question is found in the method of using OpenIE for extraction and selecting relations based on predefined criteria.\n\n{'Answer': 'They extract \"structured answer-relevant relation\" using", "all_figures_names": ["3-Table2-1.png", "7-Figure4-1.png", "7-Table5-1.png", "5-Table3-1.png", "3-Figure2-1.png", "1-Figure1-1.png", "6-Table4-1.png", "8-Figure5-1.png"], "referred_figures_names": ["1-Figure1-1.png"], "answer": "Using the OpenIE toolbox and applying heuristic rules to select the most relevant relation."}, "656": {"question": "How big are significant improvements?", "referred_figures_indices": [6], "response": "```json\n{'Answer': 'Values in parenthesis are the improvement percentage of Our Model over Hybrid.'}\n```", "all_figures_names": ["1-Figure1-1.png", "3-Table2-1.png", "2-Table1-1.png", "8-Figure5-1.png", "7-Table5-1.png", "7-Figure4-1.png", "6-Table4-1.png", "5-Table3-1.png"], "referred_figures_names": ["6-Table4-1.png"], "answer": "Metrics show better results on all metrics compared to baseline except Bleu1  on Zhou split (worse by 0.11 compared to baseline). Bleu1 score on DuSplit is 45.66 compared to best baseline 43.47, other metrics on average by 1"}}