{"909": {"question": "What is best performing model among author's submissions, what performance it had?", "response": {"3-Table2-1.png": ["No", "The best performing model among the author's submissions is MIC-CIS. The performance on the SLC task is 6336.608, and the performance on the FLC task is 3488.286."]}, "referred_figures_names": ["3-Table2-1.png"], "answer": "For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."}, "910": {"question": "What extracted features were most influencial on performance?", "response": {"4-Table3-1.png": ["No", "Majority voting,  [S/C] 1,  [S/C] 2,  [S/C] 3,  [S/C] 4,  [S/C] 5,  [S/C] 6,  [S/C] 7,  [S/C] 8,  [S/C] 9,  [S/C] 10,  [S/C] 11,  [S/C] 12,  [S/C] 13,  [S/C] 14,  [S/C] 15,  [S/C] 16,  [S/C] 17,  [S/C] 18,  [S/C] 19,  [S/C] 20,  [S/C] 21,  [S/C] 22,  [S/C] 23,  [S/C] 24,  [S/C] 25,  [S/C] 26, "]}, "referred_figures_names": ["4-Table3-1.png"], "answer": "Linguistic"}, "912": {"question": "Did ensemble schemes help in boosting peformance, by how much?", "response": {"4-Table3-1.png": ["No", "Yes, they did."]}, "referred_figures_names": ["4-Table3-1.png"], "answer": "The best ensemble topped the best single model by 0.029 in F1 score on dev (external)."}, "913": {"question": "Did ensemble schemes help in boosting peformance, by how much?", "response": {"4-Table4-1.png": ["Yes", "Yes, ensemble schemes helped in boosting performance by 10.5%."], "3-Table2-1.png": ["No", "Ensemble schemes helped in boosting performance by 1.099 in the FMA task and 1.455 in the MIC-CIS task."], "4-Table3-1.png": ["No", "Yes, they did."]}, "referred_figures_names": ["4-Table4-1.png", "3-Table2-1.png", "4-Table3-1.png"], "answer": "They increased F1 Score by 0.029 in Sentence Level Classification, and by 0.044 in Fragment-Level classification"}, "914": {"question": "Which basic neural architecture perform best by itself?", "response": {"4-Table3-1.png": ["No", "ResNet-18."]}, "referred_figures_names": ["4-Table3-1.png"], "answer": "BERT"}, "915": {"question": "What participating systems had better results than ones authors submitted?", "response": {"3-Table2-1.png": ["No", "6336. 6088. 6649. newspeak. 2488. 2863. 2201. 6564. 6497. 6549. 6253. 6546. 6234. 1808. 6183. 5779. 6549. 6581. 6819. 1455. 1921. 1169. 1311. 3235. 1822."]}, "referred_figures_names": ["3-Table2-1.png"], "answer": "For SLC task : Ituorp, ProperGander and YMJA  teams had better results.\nFor FLC task: newspeak and Antiganda teams had better results."}, "916": {"question": "What is specific to multi-granularity and multi-tasking neural arhiteture design?", "response": {"3-Figure1-1.png": ["No", "The specific design of the multi-granularity and multi-tasking neural architecture includes the integration of the Propaganda Fragment Detection (PFD) and FLC layers, as well as the binary classification component at the last hidden layer. This allows for joint propaganda detection, including the detection of both propaganda and non-propaganda content. The architecture also utilizes FastText and BERT pre-trained word embeddings and fine-tuning of the BERT model for improved performance."]}, "referred_figures_names": ["3-Figure1-1.png"], "answer": "An output layer for each task"}}