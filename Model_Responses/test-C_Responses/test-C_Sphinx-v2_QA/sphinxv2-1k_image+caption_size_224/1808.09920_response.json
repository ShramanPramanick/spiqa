{"856": {"question": "What baseline did they compare Entity-GCN to?", "response": {"6-Table2-1.png": ["No", "Human (Welzel et al., 2015) FastQA (Welzel et al., 2015) BIDAF (Welzel et al., 2018) CcT-GRU (Ding et al., 2018) MHPGM (Bauer et al., 2015) Weaver (Jeng (Raoso etal., 2018) MHQA-GRN (Song etal., 2015) Entity-GCN without coreference; single model Entity-GCN with coreference; single model Entity-GCN (ensemble 5 models) Model Ummaskol Masked Test Dev Test Dev 74.1 25.7 42.9 59.3 58.2 66.3 64.1 65.4 62.1 71.2 88.5 71.6 75.5"]}, "referred_figures_names": ["6-Table2-1.png"], "answer": "Human, FastQA, BiDAF, Coref-GRU, MHPGM, Weaver / Jenga, MHQA-GRN"}, "858": {"question": "Did they use a relation extraction method to construct the edges in the graph?", "response": {"3-Figure2-1.png": ["No", "Yes"]}, "referred_figures_names": ["3-Figure2-1.png"], "answer": "No"}, "859": {"question": "How did they get relations between mentions?", "response": {"3-Figure2-1.png": ["No", "Dash lines."]}, "referred_figures_names": ["3-Figure2-1.png"], "answer": "Assign a value to the relation based on whether mentions occur in the same document, if mentions are identical, or if mentions are in the same coreference chain."}, "862": {"question": "What performance does the Entity-GCN get on WIKIHOP?", "response": {"6-Table2-1.png": ["Yes", "Entity-GCN without coreference: single model: 71.6  Entity-GCN with coreference: single model: 71.6  Entity-GCN* (resemble 5 models): 71.2"]}, "referred_figures_names": ["6-Table2-1.png"], "answer": "During testing: 67.6 for single model without coreference, 66.4 for single model with coreference, 71.2 for ensemble of 5 models"}}