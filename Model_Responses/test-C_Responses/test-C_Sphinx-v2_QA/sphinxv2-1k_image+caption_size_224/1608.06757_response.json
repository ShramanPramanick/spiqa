{"296": {"question": "what is the state of the art?", "response": {"6-Table2-1.png": ["No", "Table 2: Comparison of annotators trained for common English news texts (micro-averaged scores on match per annotation span). The table shows micro-precision, recall and NER-style F1 for CoNLL2003, KORE50, ACE2004 and MSNBC datasets. Please provide a brief answer to the following question after looking into the input image and caption. Question: what is the state of the art?."]}, "referred_figures_names": ["6-Table2-1.png"], "answer": "Babelfy, DBpedia Spotlight, Entityclassifier.eu, FOX, LingPipe MUC-7, NERD-ML, Stanford NER, TagMe 2"}}