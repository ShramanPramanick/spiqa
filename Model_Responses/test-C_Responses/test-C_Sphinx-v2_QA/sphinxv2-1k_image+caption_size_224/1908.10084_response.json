{"434": {"question": "What other sentence embeddings methods are evaluated?", "response": {"4-Table1-1.png": ["No", "11-16, 18-22, 24-25, 27-28, 30-31, 33-34, 36-37, 39-40, 42-43, 45-46, 48-49, 51-52, 54-55, 57-58, 60-61, 63-64, 66-67, 69-70, 72-73, 75-76, 78-79, 81-82, 84-85, 87-88, 90-91, 93-94, 96-97, 99-100, 102-103, 105-106, 108-109, 111-112, 114-115, 117-118, 120-"], "6-Table3-1.png": ["No", "None"]}, "referred_figures_names": ["4-Table1-1.png", "6-Table3-1.png"], "answer": "GloVe, BERT, Universal Sentence Encoder, TF-IDF, InferSent"}, "435": {"question": "What other sentence embeddings methods are evaluated?", "response": {"7-Table5-1.png": ["No", "1. GPT-2, 2. GPT-2, 3. GPT-2, 4. GPT-2, 5. GPT-2, 6. GPT-2, 7. GPT-2, 8. GPT-2, 9. GPT-2, 10. GPT-2, 11. GPT-2, 12. GPT-2, 13. GPT-2, 14. GPT-2, 15. GPT-2, 16. GPT-2, 17. GPT-2, 18. GPT-2, 19. GPT-2, 20. GPT-2, 21. GPT-2, 22. GPT-2, 23. GPT-2, 24. GPT-2, 25. GPT-2, 26. GPT-2, 27. GPT-2, 28. GPT-2, 29. GPT-2, 30."]}, "referred_figures_names": ["7-Table5-1.png"], "answer": "Avg. GloVe embeddings, Avg. fast-text embeddings, Avg. BERT embeddings, BERT CLS-vector, InferSent - GloVe and Universal Sentence Encoder."}}