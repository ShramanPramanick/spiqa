{"248": {"question": "How were the human judgements assembled?", "response": {"11-Table2-1.png": ["Answer: The human judgements were assembled by a single annotator.", "The human judgements were assembled using a table with different values of the acoustic features."], "12-Table3-1.png": ["Answer: 0.605 0.33 0.410 0.714 0.33 0.573 0.714 0.33 0.573 0.714 0.33 0.573 0.714 0.33 0.573 0.714 0.33 0.573 0.714 0.33 0.573 0.714 0.33 0.573 0.714 0.33 0.573 0.714 0.33 0.573 0.714 0.33 0.573 0.714 0.33 0.573 0.714 0.33 0.573 0.714 0.33 0.573 0.714 0.33 0.57", "The human judgements were assembled using a model that incorporated a combination of the PIA and PE. The PIA model was used to score the RWVSearch-Nord2Vec features, and the PE model was used to score the RMMorpo features. The scores from the two models were then combined to produce the final ranking."]}, "referred_figures_names": ["11-Table2-1.png", "12-Table3-1.png"], "answer": "50 human annotators ranked a random sample of 100 translations by Adequacy, Fluency and overall ranking on a 5-point scale."}}