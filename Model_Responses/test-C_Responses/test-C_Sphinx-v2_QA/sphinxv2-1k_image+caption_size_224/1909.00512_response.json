{"31": {"question": "What experiments are proposed to test that upper layers produce context-specific embeddings?", "response": {"6-Figure2-1.png": ["No", "We propose three experiments to test that upper layers produce context-specific embeddings. First, we train a language model on the same corpus for different layers, and measure the cosine similarity between the word representations in the lower and upper layers. Second, we train a language model on the same corpus for different random seeds, and measure the cosine similarity between the word representations in the lower and upper layers. Third, we train a language model on the same corpus for different initializations, and measure the cosine similarity between the word representations in the lower and upper layers. We use a language model trained on the same corpus for different random seeds, initializations, and layers as a baseline. We also train a language model on the same corpus for different random seeds, initializations, and layers, but with a larger number of training steps, to test the robustness of the results."], "5-Figure1-1.png": ["No", "Experiments on the average cosine similarity between uniformly randomly sampled words are proposed."], "7-Figure3-1.png": ["No", "11"]}, "referred_figures_names": ["6-Figure2-1.png", "5-Figure1-1.png", "7-Figure3-1.png"], "answer": "They plot the average cosine similarity between uniformly random words increases exponentially from layers 8 through 12.  \nThey plot the average self-similarity of uniformly randomly sampled words in each layer of BERT, ELMo, and GPT-2 and shown that the higher layer produces more context-specific embeddings.\nThey plot that word representations in a sentence become more context-specific in upper layers, they drift away from one another."}, "32": {"question": "How do they calculate a static embedding for each word?", "response": {"8-Table1-1.png": ["No", "The best result for each task is in bold. For the contextualizing models (ELMo, BERT, GPT-2), we use the first principal component of a word\u2019s contextualized representations in a given layer as its static embedding."]}, "referred_figures_names": ["8-Table1-1.png"], "answer": "They use the first principal component of a word's contextualized representation in a given layer as its static embedding."}}