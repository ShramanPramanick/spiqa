{"989": {"question": "How much better peformance is achieved in human evaluation when model is trained considering proposed metric?", "response": {"6-Table2-1.png": ["", "0.112"], "6-Table1-1.png": ["|Metric|DE|BLEU|Repeat|Few Rel|Average Rel|\n|---|---|---|---|---|---|\n|\"$^{2}S_{1}$\"|0.14|0.08|0.07|0.11|0.16|\n|\"$^{2}S_{2}$\"|0.14|0.08|0.07|0.11|0.16|\n|\"$^{2}S_{3}$\"|0.14|0.08|0.07|0.11|0.16|\n|\"$^{2}S_{4}$\"|0.14|0.08|0.07|0.11|0.16|\n|\"$^{2}S_{5}$\"|0.14|0.08|0.07|0.11|0.16|\n|\"$^{2}S_{6}$\"|0.14|0.08|0.07|0.1", "11"]}, "referred_figures_names": ["6-Table2-1.png", "6-Table1-1.png"], "answer": "Pearson correlation to human judgement - proposed vs next best metric\nSample level comparison:\n- Story generation: 0.387 vs 0.148\n- Dialogue: 0.472 vs 0.341\nModel level comparison:\n- Story generation:  0.631 vs 0.302\n- Dialogue: 0.783 vs 0.553"}}