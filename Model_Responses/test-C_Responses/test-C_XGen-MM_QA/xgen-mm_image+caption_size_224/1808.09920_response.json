{"856": {"question": "What baseline did they compare Entity-GCN to?", "response": {"6-Table2-1.png": ["Yes. ", "ELMo. "]}, "referred_figures_names": ["6-Table2-1.png"], "answer": "Human, FastQA, BiDAF, Coref-GRU, MHPGM, Weaver / Jenga, MHQA-GRN"}, "858": {"question": "Did they use a relation extraction method to construct the edges in the graph?", "response": {"3-Figure2-1.png": ["Yes. ", "Yes. "]}, "referred_figures_names": ["3-Figure2-1.png"], "answer": "No"}, "859": {"question": "How did they get relations between mentions?", "response": {"3-Figure2-1.png": ["Yes. ", "They used a graph with nodes representing mentions of either candidate entities or query entities, and connected them using three types of edges to represent co-occurrence, exact matches, and coreference. "]}, "referred_figures_names": ["3-Figure2-1.png"], "answer": "Assign a value to the relation based on whether mentions occur in the same document, if mentions are identical, or if mentions are in the same coreference chain."}, "862": {"question": "What performance does the Entity-GCN get on WIKIHOP?", "response": {"6-Table2-1.png": ["Yes. ", "71.1. "]}, "referred_figures_names": ["6-Table2-1.png"], "answer": "During testing: 67.6 for single model without coreference, 66.4 for single model with coreference, 71.2 for ensemble of 5 models"}}