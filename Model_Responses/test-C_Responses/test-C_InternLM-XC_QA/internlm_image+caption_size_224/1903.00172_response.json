{"1026": {"question": "Where did they get training data?", "response": {"5-Table1-1.png": ["Yes", "The training data was obtained from various sources, including ConciergeQA, AmazonQA, Ambiguous, and Jointly from Q-A."], "6-Table3-1.png": ["No", "The training data for the ConciergeQA task was likely obtained from various sources, such as online reviews, customer feedback, and other relevant textual information. The table provided in the image shows the precision (P), recall (R), and relative coverage (RC) results on this task, which are typically used to evaluate the performance of a machine learning model or system."], "7-Table4-1.png": ["No", "The training data was obtained from the AmazonQA dataset."]}, "referred_figures_names": ["5-Table1-1.png", "6-Table3-1.png", "7-Table4-1.png"], "answer": "AmazonQA and ConciergeQA datasets"}, "1027": {"question": "What extraction model did they use?", "response": {"3-Figure1-1.png": ["Yes", "The extraction model used in the image is a Multi-Encoder, Constrained-Decoder model for tuple extraction from (q, a)."]}, "referred_figures_names": ["3-Figure1-1.png"], "answer": "Multi-Encoder, Constrained-Decoder model"}, "1028": {"question": "Which datasets did they experiment on?", "response": {"5-Table1-1.png": ["Yes", "They experimented on the ConciergeQA and AmazonQA datasets."]}, "referred_figures_names": ["5-Table1-1.png"], "answer": "ConciergeQA and AmazonQA"}}