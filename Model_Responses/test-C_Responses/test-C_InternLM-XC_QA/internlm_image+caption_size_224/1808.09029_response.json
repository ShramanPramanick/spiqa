{"1031": {"question": "what previous RNN models do they compare with?", "response": {"6-Table1-1.png": ["No", "The table compares the single model word-level perplexity of the current model with state-of-the-art models on the Penn Treebank and Wikitext-2 datasets. The previous RNN models being compared are not explicitly mentioned in the image caption, but it can be inferred that they are other popular RNN-based language models used for text generation tasks."]}, "referred_figures_names": ["6-Table1-1.png"], "answer": "Variational LSTM, CharCNN, Pointer Sentinel-LSTM, RHN, NAS Cell, SRU, QRNN, RAN, 4-layer skip-connection LSTM, AWD-LSTM, Quantized LSTM"}}