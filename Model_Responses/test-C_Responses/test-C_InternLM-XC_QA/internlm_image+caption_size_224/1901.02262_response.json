{"457": {"question": "What do they mean by answer styles?", "response": {"5-Table1-1.png": ["Yes", "Answer styles refer to the different ways in which a question can be answered. In this case, there are four answer styles: summary, narrative, dev, and eval. The table provides information on the number of questions used for each style in the experiments."]}, "referred_figures_names": ["5-Table1-1.png"], "answer": "well-formed sentences vs concise answers"}, "458": {"question": "Is there exactly one \"answer style\" per dataset?", "response": {"5-Table1-1.png": ["Yes", "Yes, there is exactly one \"answer style\" per dataset."]}, "referred_figures_names": ["5-Table1-1.png"], "answer": "Yes"}, "459": {"question": "What are the baselines that Masque is compared against?", "response": {"6-Table2-1.png": ["Yes", "Masque is compared against several baselines, including BIDAF, Deep Cascade QA, S-Net+CES25, BERT+Multi-PGN, Selector+CCG, VNET, and Human Performance."], "8-Table5-1.png": ["Yes", "Masque is compared against the following baselines: BidAF, DECARPROP, MHPGM+NOIC, ConZNet, RMR+A2D, and Maskue (NQA)."]}, "referred_figures_names": ["6-Table2-1.png", "8-Table5-1.png"], "answer": "BiDAF, Deep Cascade QA, S-Net+CES2S, BERT+Multi-PGNet, Selector+CCG, VNET, DECAPROP, MHPGM+NOIC, ConZNet, RMR+A2D"}, "460": {"question": "What is the performance achieved on NarrativeQA?", "response": {"8-Table5-1.png": ["Yes", "The performance achieved on NarrativeQA is 52.78 for our model and 28.72 for the competing models."]}, "referred_figures_names": ["8-Table5-1.png"], "answer": "Bleu-1: 54.11, Bleu-4: 30.43, METEOR: 26.13, ROUGE-L: 59.87"}, "461": {"question": "What is an \"answer style\"?", "response": {"5-Table1-1.png": ["No", "Answer style refers to the way a question is answered, which can be in various forms such as multiple choice, short answer, or open-ended. In this context, it seems that the table is listing different types of questions used in an experiment, with each row representing a specific type of question and its corresponding data."]}, "referred_figures_names": ["5-Table1-1.png"], "answer": "well-formed sentences vs concise answers"}}