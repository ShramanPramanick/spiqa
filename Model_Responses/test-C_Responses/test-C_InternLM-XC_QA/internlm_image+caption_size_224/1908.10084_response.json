{"434": {"question": "What other sentence embeddings methods are evaluated?", "response": {"6-Table3-1.png": ["Yes", "In addition to GloVe embeddings, the following sentence embedding methods are evaluated: InterSentence - GloVe, BERT-AFS-base, BERT-AFS-large, SBERT-AFS-base, SBERT-AFS-large, and Cross-Topic Evaluation."], "4-Table1-1.png": ["No", "The other sentence embeddings methods evaluated are Spearman rank correlation \u03c1 between the cosine similarity of sentence representations and the gold labels for various Textual Similarity (STS) tasks."]}, "referred_figures_names": ["6-Table3-1.png", "4-Table1-1.png"], "answer": "GloVe, BERT, Universal Sentence Encoder, TF-IDF, InferSent"}, "435": {"question": "What other sentence embeddings methods are evaluated?", "response": {"7-Table5-1.png": ["No", "In addition to the BERT sentence embeddings, the table also evaluates the RoBERTa and XLNet sentence embeddings using the SentEval toolkit."]}, "referred_figures_names": ["7-Table5-1.png"], "answer": "Avg. GloVe embeddings, Avg. fast-text embeddings, Avg. BERT embeddings, BERT CLS-vector, InferSent - GloVe and Universal Sentence Encoder."}}