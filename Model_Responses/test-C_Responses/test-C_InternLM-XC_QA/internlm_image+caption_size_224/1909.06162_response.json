{"909": {"question": "What is best performing model among author's submissions, what performance it had?", "response": {"3-Table2-1.png": ["Yes", "The best performing model among the author's submissions is the MIC-CIS model, which achieved a score of 0.7361 on the SLC task and 0.8189 on the FLC task."]}, "referred_figures_names": ["3-Table2-1.png"], "answer": "For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."}, "910": {"question": "What extracted features were most influencial on performance?", "response": {"4-Table3-1.png": ["No", "The extracted features that were most influential on performance are \"L1 norm\" and \"L2 norm\"."]}, "referred_figures_names": ["4-Table3-1.png"], "answer": "Linguistic"}, "912": {"question": "Did ensemble schemes help in boosting peformance, by how much?", "response": {"4-Table3-1.png": ["Yes", "Yes, ensemble schemes helped in boosting performance. The table shows that using ensemble methods (majority voting and majority writing) improved the results on both Dev (internal) and Dev (external) compared to using individual classifiers and features."]}, "referred_figures_names": ["4-Table3-1.png"], "answer": "The best ensemble topped the best single model by 0.029 in F1 score on dev (external)."}, "913": {"question": "Did ensemble schemes help in boosting peformance, by how much?", "response": {"4-Table3-1.png": ["Yes", "Yes, ensemble schemes helped in boosting performance. The table shows that using ensemble methods (majority voting and majority writing) improved the results on both Dev (internal) and Dev (external) compared to using individual classifiers and features."], "3-Table2-1.png": ["Yes", "Yes, ensemble schemes helped in boosting performance. The table shows that the scores of the proposed system (MIC-CIS) are higher than those of the top-5 participants on both SLC and FLC tasks."], "4-Table4-1.png": ["Yes", "Yes, ensemble schemes helped in boosting performance. The table shows that the ensemble of (IL and IV) within each Fold1,2,3, and the ensemble of (IL and IV) from each Fold1,2,3, with postprocessing resulted in better performance compared to individual models."]}, "referred_figures_names": ["4-Table3-1.png", "3-Table2-1.png", "4-Table4-1.png"], "answer": "They increased F1 Score by 0.029 in Sentence Level Classification, and by 0.044 in Fragment-Level classification"}, "914": {"question": "Which basic neural architecture perform best by itself?", "response": {"4-Table3-1.png": ["No", "Based on the table, it appears that the basic neural architecture with features \"L1\" and \"L2\" perform best by themselves."]}, "referred_figures_names": ["4-Table3-1.png"], "answer": "BERT"}, "915": {"question": "What participating systems had better results than ones authors submitted?", "response": {"3-Table2-1.png": ["No", "The participating systems that had better results than the authors' submission are: \"Mic-CIS\" and \"TeamOne\"."]}, "referred_figures_names": ["3-Table2-1.png"], "answer": "For SLC task : Ituorp, ProperGander and YMJA  teams had better results.\nFor FLC task: newspeak and Antiganda teams had better results."}, "916": {"question": "What is specific to multi-granularity and multi-tasking neural arhiteture design?", "response": {"3-Figure1-1.png": ["Yes", "The multi-granularity and multi-tasking neural architecture design allows the system to perform multiple tasks simultaneously, such as propaganda detection (Propaganda Fragment Detection, FLC), sentiment analysis (SLC), and language identification (LC). This approach improves efficiency and accuracy by leveraging shared features across different tasks."]}, "referred_figures_names": ["3-Figure1-1.png"], "answer": "An output layer for each task"}}