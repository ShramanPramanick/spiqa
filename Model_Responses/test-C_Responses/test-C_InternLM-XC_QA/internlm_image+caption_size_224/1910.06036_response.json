{"654": {"question": "How they extract \"structured answer-relevant relation\"?", "response": {"1-Figure1-1.png": ["Yes", "The structured answer-relevant relation is extracted by identifying the key information in the given text and highlighting it. In this case, the relevant information is \"The daily mean temperature in January; is 32.6 \u00b0F (0.3 \u00b0C)\". The answer is then provided as a structured response, which includes the mean temperature for both Fahrenheit and Celsius."]}, "referred_figures_names": ["1-Figure1-1.png"], "answer": "Using the OpenIE toolbox and applying heuristic rules to select the most relevant relation."}, "656": {"question": "How big are significant improvements?", "response": {"6-Table4-1.png": ["Yes", "The significant improvements are in the range of 3 to 5 points, as indicated by the numbers in the table."]}, "referred_figures_names": ["6-Table4-1.png"], "answer": "Metrics show better results on all metrics compared to baseline except Bleu1  on Zhou split (worse by 0.11 compared to baseline). Bleu1 score on DuSplit is 45.66 compared to best baseline 43.47, other metrics on average by 1"}}