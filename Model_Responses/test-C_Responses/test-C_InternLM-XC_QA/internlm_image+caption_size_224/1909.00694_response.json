{"2": {"question": "What are the results?", "response": {"5-Table4-1.png": ["Yes", "The results show the performance of BERT and Bigru models trained with different subsets of labeled data. The table includes the accuracy (Acc) and the encoded training data (Encoder)."], "5-Table3-1.png": ["Yes", "The results show the performance of various models on the ACP test set. The table includes encoders and their corresponding accuracy (acc) values for different models such as AL, AL+CA+CO, ACP, ACP+AL+CA+CO, and random+seed."]}, "referred_figures_names": ["5-Table4-1.png", "5-Table3-1.png"], "answer": "Using all data to train: AL -- BiGRU achieved 0.843 accuracy, AL -- BERT achieved 0.863 accuracy, AL+CA+CO -- BiGRU achieved 0.866 accuracy, AL+CA+CO -- BERT achieved 0.835, accuracy, ACP -- BiGRU achieved 0.919 accuracy, ACP -- BERT achived 0.933, accuracy, ACP+AL+CA+CO -- BiGRU achieved 0.917 accuracy, ACP+AL+CA+CO -- BERT achieved 0.913 accuracy. \nUsing a subset to train: BERT achieved 0.876 accuracy using ACP (6K), BERT achieved 0.886 accuracy using ACP (6K) + AL, BiGRU achieved 0.830 accuracy using ACP (6K), BiGRU achieved 0.879 accuracy using ACP (6K) + AL + CA + CO."}, "3": {"question": "How are relations used to propagate polarity?", "response": {"2-Figure1-1.png": ["Yes", "The image shows that discourse relations are used to propagate polarity between event pairs. For example, if the discourse relation is CAUSE, the polarity of the latter event is automatically identified as either positive or negative and then propagated to the former event. Similarly, if the discourse relation is CONCESSION, the reversed polarity of the latter event is used for the former event. This helps in determining the overall sentiment of the text by considering the relationships between events."]}, "referred_figures_names": ["2-Figure1-1.png"], "answer": "based on the relation between events, the suggested polarity of one event can determine the possible polarity of the other event "}, "4": {"question": "How are relations used to propagate polarity?", "response": {"2-Figure1-1.png": ["Yes", "The image shows that discourse relations are used to propagate polarity between event pairs. For example, if the discourse relation is CAUSE, the polarity of the latter event is automatically identified as either positive or negative and then propagated to the former event. Similarly, if the discourse relation is CONCESSION, the reversed polarity of the latter event is used for the former event. This helps in determining the overall sentiment of the text by considering the relationships between events."]}, "referred_figures_names": ["2-Figure1-1.png"], "answer": "cause relation: both events in the relation should have the same polarity; concession relation: events should have opposite polarity"}, "5": {"question": "How big is the Japanese data?", "response": {"4-Table2-1.png": ["No", "I'm sorry, but I cannot provide an answer to your question as there is no information about the size of the Japanese data in the given table."], "4-Table1-1.png": ["No", "I'm sorry, but I cannot provide a brief answer to the question as there is no image or data provided in the given context."]}, "referred_figures_names": ["4-Table2-1.png", "4-Table1-1.png"], "answer": "7000000 pairs of events were extracted from the Japanese Web corpus, 529850 pairs of events were extracted from the ACP corpus"}, "6": {"question": "How big is the Japanese data?", "response": {"4-Table2-1.png": ["No", "I'm sorry, but I cannot provide an answer to your question as there is no information about the size of the Japanese data in the given table."]}, "referred_figures_names": ["4-Table2-1.png"], "answer": "The ACP corpus has around 700k events split into positive and negative polarity "}, "8": {"question": "How big are improvements of supervszed learning results trained on smalled labeled data enhanced with proposed approach copared to basic approach?", "response": {"5-Table4-1.png": ["Yes", "The improvements of supervised learning results trained on small labeled data enhanced with the proposed approach compared to the basic approach are not explicitly mentioned in the provided image and caption."]}, "referred_figures_names": ["5-Table4-1.png"], "answer": "3%"}, "9": {"question": "How does their model learn using mostly raw data?", "response": {"2-Figure1-1.png": ["No", "The model learns using mostly raw data by focusing on pairs of events, the former events and the latter events, which are connected with a discourse relation. The polarity of a latter event is automatically identified as either positive or negative based on a seed lexicon. Depending on the discourse relation, the model encourages the two events' polarities to be the same for CAUSE or reversed for CONCESSION. This approach allows the model to learn from raw data without relying on predefined rules or manually labeled examples."]}, "referred_figures_names": ["2-Figure1-1.png"], "answer": "by exploiting discourse relations to propagate polarity from seed predicates to final sentiment polarity"}, "10": {"question": "How big is seed lexicon used for training?", "response": {"4-Table1-1.png": ["No", "The table does not provide information about the size of the seed lexicon used for training."]}, "referred_figures_names": ["4-Table1-1.png"], "answer": "30 words"}}