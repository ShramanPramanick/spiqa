{"856": {"question": "What baseline did they compare Entity-GCN to?", "response": {"6-Table2-1.png": ["Yes", "The authors compared Entity-GCN to several baselines, including ELMo without fine-tuning and R-GCN."]}, "referred_figures_names": ["6-Table2-1.png"], "answer": "Human, FastQA, BiDAF, Coref-GRU, MHPGM, Weaver / Jenga, MHQA-GRN"}, "858": {"question": "Did they use a relation extraction method to construct the edges in the graph?", "response": {"3-Figure2-1.png": ["Yes", "Yes, they used a relation extraction method to construct the edges in the graph. The nodes are connected by three simple relations: co-occurrence in the same document (solid edges), exact match (dashed edges), and coreference (bold-red line)."]}, "referred_figures_names": ["3-Figure2-1.png"], "answer": "No"}, "859": {"question": "How did they get relations between mentions?", "response": {"3-Figure2-1.png": ["Yes", "The relations between mentions were obtained by analyzing the co-occurrence of candidate entities and query entities in the supporting documents. The nodes with the same color indicate that they refer to the same entity, either through exact match, coreference or both. The connections between these nodes represent different types of relations: co-occurrence in the same document, exact match, and coreference."]}, "referred_figures_names": ["3-Figure2-1.png"], "answer": "Assign a value to the relation based on whether mentions occur in the same document, if mentions are identical, or if mentions are in the same coreference chain."}, "862": {"question": "What performance does the Entity-GCN get on WIKIHOP?", "response": {"6-Table2-1.png": ["Yes", "Entity-GCN achieves a performance of 71.6 on the WIKIHOP closed test set and 64.8 on the public validation set."]}, "referred_figures_names": ["6-Table2-1.png"], "answer": "During testing: 67.6 for single model without coreference, 66.4 for single model with coreference, 71.2 for ensemble of 5 models"}}