{"654": {"question": "How they extract \"structured answer-relevant relation\"?", "response": {"1-Figure1-1.png": [" Yes", " The image shows a question related to the weather in New York City in January. The question asks for the lowest temperature in January, and the baseline prediction is 32.2 degrees Fahrenheit. The answer is highlighted as 32.2 degrees Fahrenheit."]}, "referred_figures_names": ["1-Figure1-1.png"], "answer": "Using the OpenIE toolbox and applying heuristic rules to select the most relevant relation."}, "656": {"question": "How big are significant improvements?", "response": {"6-Table4-1.png": [" Yes", " The table shows significant improvements in the model's performance compared to other baselines."]}, "referred_figures_names": ["6-Table4-1.png"], "answer": "Metrics show better results on all metrics compared to baseline except Bleu1  on Zhou split (worse by 0.11 compared to baseline). Bleu1 score on DuSplit is 45.66 compared to best baseline 43.47, other metrics on average by 1"}}