{"845": {"question": "By how much does their best model outperform the state-of-the-art?", "response": {"5-Table3-1.png": [" Yes", " The best model outperforms the state-of-the-art by 89%."]}, "referred_figures_names": ["5-Table3-1.png"], "answer": "0.8% F1 better than the best state-of-the-art"}, "846": {"question": "By how much does their best model outperform the state-of-the-art?", "response": {"5-Table3-1.png": [" Yes", " The best model outperforms the state-of-the-art by 89%."]}, "referred_figures_names": ["5-Table3-1.png"], "answer": "Best proposed model achieves F1 score of 84.9 compared to best previous result of 84.1."}, "852": {"question": "How do they obtain the new context represetation?", "response": {"3-Figure1-1.png": [" Yes", " The new context representation is obtained by extending the context of the CNN model. This is done by adding more information to the input image, such as the presence of pain and headaches, which are described in the caption. The extended context is then used to train the model to recognize and classify the new information."]}, "referred_figures_names": ["3-Figure1-1.png"], "answer": "They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."}}