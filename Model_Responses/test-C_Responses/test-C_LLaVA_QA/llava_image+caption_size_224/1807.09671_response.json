{"962": {"question": "Do they build one model per topic or on all topics?", "response": {"20-Figure2-1.png": [" No", " The image shows a chart with a purple background, displaying the percentage of human preference scores by date and system summary. The chart is divided into several sections, each showing a different percentage of preference scores. The chart is likely used to analyze and understand the preferences of a certain group of people."], "9-Table1-1.png": [" Yes", " The image shows a table with statistics related to student responses, tasks, and word counts. The table is divided into different sections, each providing information on various aspects of the data. The statistics involve the number of summarization tasks (Tasks), average number of documents per task (Docs/task), average word count per task (WC/task), average word count per sentence (WC/sen), and average number of words in human summaries (Length). The table is filled with data"]}, "referred_figures_names": ["20-Figure2-1.png", "9-Table1-1.png"], "answer": "One model per topic."}, "963": {"question": "Do they quantitavely or qualitatively evalute the output of their low-rank approximation to verify the grouping of lexical items?", "response": {"10-Table2-1.png": [" Yes", " Yes, they use a human summary to evaluate the output of their low-rank approximation."], "15-Table7-1.png": [" Yes", " Yes"]}, "referred_figures_names": ["10-Table2-1.png", "15-Table7-1.png"], "answer": "They evaluate quantitatively."}}