{"989": {"question": "How much better peformance is achieved in human evaluation when model is trained considering proposed metric?", "response": {"6-Table2-1.png": [" Yes", " The table shows the correlation between human judgments and model-level performance. The p-values in brackets indicate the significance of the correlation. The table shows that the model-level performance is significantly better when trained considering the proposed metric."], "6-Table1-1.png": [" Yes", " The table shows the correlation between metrics and human judgments, with p-values shown in brackets. The table is organized in a way that allows for easy comparison of the metrics and human judgments. The table is filled with data, making it a useful tool for analyzing the performance of the model when it is trained considering the proposed metric."]}, "referred_figures_names": ["6-Table2-1.png", "6-Table1-1.png"], "answer": "Pearson correlation to human judgement - proposed vs next best metric\nSample level comparison:\n- Story generation: 0.387 vs 0.148\n- Dialogue: 0.472 vs 0.341\nModel level comparison:\n- Story generation:  0.631 vs 0.302\n- Dialogue: 0.783 vs 0.553"}}