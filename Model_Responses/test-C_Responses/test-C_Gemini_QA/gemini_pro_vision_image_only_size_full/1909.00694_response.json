{"2": {"question": "What are the results?", "referred_figures_indices": [3, 5], "response": " {'Answer': 'In Table 2, the number of automatically labeled pairs is 1,000,000, the number of cause pairs is 5,000,000, and the number of concession pairs is 5,000,000.'}", "all_figures_names": ["2-Figure1-1.png", "4-Table2-1.png", "4-Table1-1.png", "5-Table3-1.png", "5-Table5-1.png", "5-Table4-1.png"], "referred_figures_names": ["5-Table3-1.png", "5-Table4-1.png"], "answer": "Using all data to train: AL -- BiGRU achieved 0.843 accuracy, AL -- BERT achieved 0.863 accuracy, AL+CA+CO -- BiGRU achieved 0.866 accuracy, AL+CA+CO -- BERT achieved 0.835, accuracy, ACP -- BiGRU achieved 0.919 accuracy, ACP -- BERT achived 0.933, accuracy, ACP+AL+CA+CO -- BiGRU achieved 0.917 accuracy, ACP+AL+CA+CO -- BERT achieved 0.913 accuracy. \nUsing a subset to train: BERT achieved 0.876 accuracy using ACP (6K), BERT achieved 0.886 accuracy using ACP (6K) + AL, BiGRU achieved 0.830 accuracy using ACP (6K), BiGRU achieved 0.879 accuracy using ACP (6K) + AL + CA + CO."}, "3": {"question": "How are relations used to propagate polarity?", "referred_figures_indices": [3], "response": " {'Answer': 'In\u60c5\u7dd2\u5206\u985e\u4efb\u52d9\u4e2d\uff0c\u6211\u5011\u53ef\u4ee5\u901a\u904e\u5728\u8a13\u7df4\u96c6\u4e2d\u52a0\u5165\u4e00\u4e9b\u4eba\u5de5\u6a19\u8a18\u7684\u56e0\u679c\u95dc\u806f\u548c\u8b93\u6b65\u95dc\u806f\uff0c\u4f86\u589e\u5f37\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002'}", "all_figures_names": ["5-Table3-1.png", "4-Table2-1.png", "4-Table1-1.png", "2-Figure1-1.png", "5-Table4-1.png", "5-Table5-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "based on the relation between events, the suggested polarity of one event can determine the possible polarity of the other event "}, "4": {"question": "How are relations used to propagate polarity?", "referred_figures_indices": [1], "response": " {'Answer': 'In this paper, we propose a novel neural relation extraction model to predict the polarity of events in a sentence. Our model leverages the rich information encoded in dependency relations to capture the semantic relatedness between events. Specifically, we first construct a dependency tree for each sentence, and then identify the relations between events based on the dependency tree. We then use these relations to propagate polarity information between events. Finally, we use a neural network to predict the polarity of each event. Our model achieves state-of-the-art results on three benchmark datasets.'}", "all_figures_names": ["5-Table5-1.png", "2-Figure1-1.png", "4-Table1-1.png", "5-Table3-1.png", "4-Table2-1.png", "5-Table4-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "cause relation: both events in the relation should have the same polarity; concession relation: events should have opposite polarity"}, "5": {"question": "How big is the Japanese data?", "referred_figures_indices": [2, 3], "response": " {'Answer': '6K in total.'}", "all_figures_names": ["2-Figure1-1.png", "5-Table4-1.png", "4-Table2-1.png", "4-Table1-1.png", "5-Table3-1.png", "5-Table5-1.png"], "referred_figures_names": ["4-Table2-1.png", "4-Table1-1.png"], "answer": "7000000 pairs of events were extracted from the Japanese Web corpus, 529850 pairs of events were extracted from the ACP corpus"}, "6": {"question": "How big is the Japanese data?", "referred_figures_indices": [3], "response": " {'Answer': 'The Japanese data contains 6K training data, 1K dev data, and 1K test data.'}", "all_figures_names": ["5-Table4-1.png", "2-Figure1-1.png", "5-Table5-1.png", "4-Table2-1.png", "4-Table1-1.png", "5-Table3-1.png"], "referred_figures_names": ["4-Table2-1.png"], "answer": "The ACP corpus has around 700k events split into positive and negative polarity "}, "8": {"question": "How big are improvements of supervszed learning results trained on smalled labeled data enhanced with proposed approach copared to basic approach?", "referred_figures_indices": [4], "response": " {'Answer': 'The improvements are not large, about 0.01.'}", "all_figures_names": ["2-Figure1-1.png", "4-Table1-1.png", "4-Table2-1.png", "5-Table5-1.png", "5-Table4-1.png", "5-Table3-1.png"], "referred_figures_names": ["5-Table4-1.png"], "answer": "3%"}, "9": {"question": "How does their model learn using mostly raw data?", "referred_figures_indices": [4], "response": " {'Answer': 'The model is trained on raw data with distant supervision. Distant supervision is a type of semi-supervised learning where the model is trained on a large amount of unlabeled data, and a small amount of labeled data. In this case, the model is trained on a large amount of unlabeled event data, and a small amount of labeled event data. The model learns to predict the polarity of events by using the labeled data, and then it uses the unlabeled data to improve its performance.'}", "all_figures_names": ["5-Table5-1.png", "5-Table4-1.png", "4-Table1-1.png", "4-Table2-1.png", "2-Figure1-1.png", "5-Table3-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "by exploiting discourse relations to propagate polarity from seed predicates to final sentiment polarity"}, "10": {"question": "How big is seed lexicon used for training?", "referred_figures_indices": [1], "response": " {'Answer': '6K'}", "all_figures_names": ["4-Table2-1.png", "4-Table1-1.png", "5-Table5-1.png", "5-Table4-1.png", "2-Figure1-1.png", "5-Table3-1.png"], "referred_figures_names": ["4-Table1-1.png"], "answer": "30 words"}}