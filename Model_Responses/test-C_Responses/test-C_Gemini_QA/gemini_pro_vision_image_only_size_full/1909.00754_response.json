{"332": {"question": "Does this approach perform better in the multi-domain or single-domain setting?", "referred_figures_indices": [3], "response": " The model performs better in the multi-domain setting.\n\nThe first image shows the model architecture. The model is a hierarchical encoder-decoder model. The encoder consists of a belief encoder and a user encoder. The belief encoder encodes the previous belief state and the user encoder encodes the user utterance. The decoder consists of a system action decoder and a user action decoder. The system action decoder decodes the system action and the user action decoder decodes the user action.\n\nThe second image shows the performance of the model on the MultiWOZ dataset. The model achieves an average of 13.68 turns per dialog and an average of 13.18 tokens per turn. The model also achieves a success rate of 48.62%.\n\nThe third image shows an example of the model's output. The user is looking for a cheap seafood restaurant. The model corrects the user's request and finds four Chinese restaurants.\n\nThe fourth image shows the ablation study results. The model achieves the best performance when using hierarchical attention.\n\nThe fifth image shows the attention weights of the model. The model attends to the relevant words in the user utterance.\n\nThe sixth image shows the time complexity of the model. The model has a time complexity of O(mn).\n\nThe seventh image shows the model's performance on the JD dataset. The model achieves a joint goal accuracy of 95.53%, a joint dialog state accuracy of 54.74%, and a joint generation accuracy of 45.72%.", "all_figures_names": ["3-Figure3-1.png", "6-Table2-1.png", "2-Figure2-1.png", "7-Table3-1.png", "7-Table4-1.png", "9-Figure5-1.png", "1-Table1-1.png", "7-Table5-1.png"], "referred_figures_names": ["7-Table3-1.png"], "answer": "single-domain setting"}}