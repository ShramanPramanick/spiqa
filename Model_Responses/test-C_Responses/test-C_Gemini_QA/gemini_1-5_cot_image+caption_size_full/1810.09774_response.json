{"412": {"question": "Which training dataset allowed for the best generalization to benchmark sets?", "referred_figures_indices": [0], "response": "```json\n{\n 'Image': 0,\n 'Rationale': 'Image 0 is a table of test accuracies for various model and training dataset combinations, allowing for direct comparison and identification of the best generalization performance.'\n}\n```\nThe answer is : Training on the combination of SNLI + MultiNLI datasets consistently yielded the highest test accuracies across various models, indicating the best generalization to benchmark sets. \n", "all_figures_names": ["6-Table4-1.png", "10-Table6-1.png", "9-Table5-1.png", "5-Table3-1.png", "3-Table1-1.png", "4-Table2-1.png"], "referred_figures_names": ["6-Table4-1.png"], "answer": "MultiNLI"}, "414": {"question": "Which models were compared?", "referred_figures_indices": [0], "response": "```json\n{\n 'Image': 0,\n 'Rationale': 'Image 0 is a table that lists models and their types, directly answering the question.'\n}\n```\nThe answer is : The models compared are BiLSTM-max, HBMP, ESIM, KIM, ESIM + ELMo, and BERT-base. \n", "all_figures_names": ["5-Table3-1.png", "3-Table1-1.png", "10-Table6-1.png", "6-Table4-1.png", "9-Table5-1.png", "4-Table2-1.png"], "referred_figures_names": ["5-Table3-1.png"], "answer": "BiLSTM-max, HBMP, ESIM, KIM, ESIM + ELMo, and BERT"}}