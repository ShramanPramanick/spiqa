{"1392": {"question": "How are sentence embeddings incorporated into the speech recognition system?", "referred_figures_indices": [0, 1], "response": "```json\n{\n 'Image': 1,\n 'Rationale': 'Image 1 highlights the conversational-context embedding representations from external word or sentence embeddings which are fed to the decoder.'\n}\n```\nThe answer is : Sentence embeddings, derived from pre-trained models like fastText or BERT, can be used to represent the conversational context in a speech recognition system. These embeddings capture the semantic meaning of previous utterances in the conversation. The decoder of the speech recognition system then utilizes this conversational context information along with the current acoustic input to predict the most likely word sequence. \n", "all_figures_names": ["5-Figure2-1.png", "4-Figure1-1.png", "7-Figure3-1.png", "7-Figure4-1.png", "6-Table2-1.png", "8-Figure5-1.png", "5-Table1-1.png"], "referred_figures_names": ["5-Figure2-1.png", "4-Figure1-1.png"], "answer": "BERT generates sentence embeddings that represent words in context. These sentence embeddings are merged into a single conversational-context vector that is used to calculate a gated embedding and is later combined with the output of the decoder h to provide the gated activations for the next hidden layer."}}