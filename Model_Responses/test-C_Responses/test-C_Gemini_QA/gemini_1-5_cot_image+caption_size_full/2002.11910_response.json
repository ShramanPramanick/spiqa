{"180": {"question": "What are previous state of the art results?", "referred_figures_indices": [1], "response": "{'Image': 1, 'Rationale': 'Image 1 directly shows the previous state of the art results for named entity and nominal mention recognition, which are relevant to the question.'} \nThe answer is : The previous state-of-the-art results for named entity recognition are: He and Sun (2017) achieved an F1 score of 54.50, Peng and Dredze (2017) achieved an F1 score of 55.28, and Xu et al. (2018) achieved an F1 score of 57.14. For nominal mention recognition, the previous state-of-the-art results are: He and Sun (2017) achieved an F1 score of 62.17, Peng and Dredze (2017) achieved an F1 score of 62.97, and Xu et al. (2018) achieved an F1 score of 61.22. \n", "all_figures_names": ["2-Figure1-1.png", "4-Table1-1.png"], "referred_figures_names": ["4-Table1-1.png"], "answer": "Overall F1 score:\n- He and Sun (2017) 58.23\n- Peng and Dredze (2017) 58.99\n- Xu et al. (2018) 59.11"}, "181": {"question": "What are previous state of the art results?", "referred_figures_indices": [0], "response": "{'Image': 0, 'Rationale': 'Image 0 is a table summarizing previous state of the art results for NER.'}\nThe answer is : Previous state of the art results for Named Entity Recognition include He and Sun (2017) with an F1 score of 54.50, Peng and Dredze (2017) with an F1 score of 55.28, and Xu et al. (2018) with an F1 score of 57.14. \n", "all_figures_names": ["4-Table1-1.png", "2-Figure1-1.png"], "referred_figures_names": ["4-Table1-1.png"], "answer": "For Named entity the maximum precision was 66.67%, and the average 62.58%, same values for Recall was 55.97% and 50.33%, and for F1 57.14% and 55.64%. Where for Nominal Mention had maximum recall of 74.48% and average of 73.67%, Recall had values of 54.55% and 53.7%,  and F1 had values of  62.97% and 62.12%. Finally the Overall F1 score had maximum value of 59.11% and average of 58.77%"}}