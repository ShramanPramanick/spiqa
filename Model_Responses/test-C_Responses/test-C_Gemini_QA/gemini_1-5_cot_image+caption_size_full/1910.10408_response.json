{"483": {"question": "Do they conduct any human evaluation?", "referred_figures_indices": [1], "response": "{'Image': 4, 'Rationale': 'This image mentions a manual evaluation being conducted and shows the results.'}\nThe answer is : Yes, they conducted a manual evaluation to rank translation quality, comparing baseline and token short translation against the reference translation. \n", "all_figures_names": ["5-Table3-1.png", "2-Figure1-1.png", "4-Figure3-1.png", "4-Table2-1.png", "7-Table6-1.png", "4-Table1-1.png", "7-Table7-1.png", "2-Figure2-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "Yes"}, "485": {"question": "How do they enrich the positional embedding with length information", "referred_figures_indices": [0], "response": "```json\n{'Image': 0, 'Rationale': 'Image 0 clearly shows the architecture of a transformer model with the positional embedding being added with length information.'}\n```\n\nThe answer is : In the provided image, the positional embedding in the decoder is enriched with length information by concatenating the position embedding with a length embedding. The length embedding is computed based on the desired target string length. This allows the model to be aware of the desired output length during decoding. \n", "all_figures_names": ["4-Figure3-1.png", "7-Table6-1.png", "6-Table4-1.png", "2-Figure1-1.png", "5-Table3-1.png", "6-Table5-1.png", "4-Table2-1.png", "7-Table7-1.png"], "referred_figures_names": ["4-Figure3-1.png"], "answer": "They introduce new trigonometric encoding which besides information about position uses additional length information (abs or relative)."}, "486": {"question": "How do they condition the output to a given target-source class?", "referred_figures_indices": [7], "response": "{'Image': 7, 'Rationale': 'Image 7 shows an architecture where the length of the translation is fed as input and conditioned to produce different length translations.'}\nThe answer is : The length of the translation is fed as input in the form of tokens such as &lt;short&gt;, &lt;norm&gt;, and &lt;long&gt; to condition the output to a specific target length. \n", "all_figures_names": ["7-Table7-1.png", "6-Table5-1.png", "4-Table2-1.png", "6-Table4-1.png", "7-Table6-1.png", "4-Table1-1.png", "4-Figure3-1.png", "2-Figure2-1.png"], "referred_figures_names": ["2-Figure2-1.png"], "answer": "They use three groups short/normal/long translation classes to learn length token, which is in inference used to bias network to generate desired length group."}}