{"346": {"question": "By how much is performance improved with multimodality?", "referred_figures_indices": [1], "response": "{'Image': 1, 'Rationale': 'This table shows the performance of different models with and without multimodal input for intent recognition.'}\nThe answer is : When combining GloVe, Word2Vec, and Speech2Vec embeddings for text and audio modalities, the F1 score for intent recognition reaches 91.3, compared to 89.0 with GloVe for text only. This indicates an improvement of 2.3 percentage points in performance with multimodality. \n", "all_figures_names": ["2-Table2-1.png", "2-Table1-1.png", "3-Table4-1.png", "3-Table3-1.png"], "referred_figures_names": ["2-Table1-1.png"], "answer": "by 2.3-6.8 points in f1 score for intent recognition and 0.8-3.5 for slot filling"}, "347": {"question": "By how much is performance improved with multimodality?", "referred_figures_indices": [3, 1], "response": "{'Image': 1, 'Rationale': 'Image 1 compares the F1 scores achieved with different modality combinations.'}\nThe answer is : Based on the F1 scores for intent recognition in Table 2, the performance improvement with multimodality varies depending on the modalities combined. For instance, combining Text & Audio improves the F1 score by 2.29% compared to using Text alone. The highest F1 score of 89.84% is achieved by combining Text, Video (cabin), and Video (road), reflecting an improvement of 0.82% over using Text & Video (cabin) alone. \n", "all_figures_names": ["3-Table3-1.png", "2-Table2-1.png", "3-Table4-1.png", "2-Table1-1.png"], "referred_figures_names": ["2-Table1-1.png", "2-Table2-1.png"], "answer": "F1 score increased from 0.89 to 0.92"}}