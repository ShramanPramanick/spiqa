{"193": {"question": "What supplemental tasks are used for multitask learning?", "referred_figures_indices": [0], "response": "{'Image': 'None', 'Rationale': 'The images do not contain information relevant to the question.'}\nThe answer is : Some examples of supplemental tasks used for multitask learning in NLP include: **Part-of-Speech (POS) Tagging**, **Named Entity Recognition (NER)**, **Syntactic Parsing**, **Semantic Role Labeling**, **Natural Language Inference**, **Machine Translation** and **Sentence Similarity**. These tasks can be used to improve the performance of a primary task, such as **text classification** or **question answering**.", "all_figures_names": ["3-Figure1-1.png", "5-Table2-1.png", "5-Figure3-1.png", "3-Figure2-1.png", "5-Figure4-1.png", "7-Table4-1.png", "7-Table3-1.png", "8-Figure5-1.png"], "referred_figures_names": ["3-Figure1-1.png"], "answer": "Multitask learning is used for the task of predicting relevance of a comment on a different question to a given question, where the supplemental tasks are predicting relevance between the questions, and between the comment and the corresponding question"}, "195": {"question": "How much performance gap between their approach and the strong handcrafted method?", "referred_figures_indices": [0], "response": "{'Image': 0, 'Rationale': 'Image 0 compares the performance of different methods, including Feature-Rich & IR, which is mentioned in the question.'}\nThe answer is : The table doesn't provide the exact performance of the \"strong handcrafted method\". However, assuming \"Feature-Rich & IR\" refers to the strong handcrafted method, the performance gap varies across tasks. \n", "all_figures_names": ["7-Table4-1.png", "5-Figure3-1.png", "8-Figure5-1.png", "3-Figure1-1.png", "5-Figure4-1.png", "7-Table3-1.png", "3-Figure2-1.png", "5-Table2-1.png"], "referred_figures_names": ["7-Table4-1.png"], "answer": "0.007 MAP on Task A, 0.032 MAP on Task B, 0.055 MAP on Task C"}}