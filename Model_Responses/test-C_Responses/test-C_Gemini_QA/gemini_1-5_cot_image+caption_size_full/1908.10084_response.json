{"434": {"question": "What other sentence embeddings methods are evaluated?", "referred_figures_indices": [0, 5], "response": "{'Image': 0, 'Rationale': 'Image 0 lists different sentence embedding methods that are evaluated in the paper including tf-idf, GloVe, InferSent, and SBERT.'}\nThe answer is : The evaluated sentence embedding methods are tf-idf, averaging GloVe embeddings, InferSent using GloVe, SVR, and BERT variations with SBERT. \n", "all_figures_names": ["6-Table3-1.png", "6-Table4-1.png", "8-Table7-1.png", "3-Figure2-1.png", "5-Table2-1.png", "4-Table1-1.png", "7-Table5-1.png", "7-Table6-1.png"], "referred_figures_names": ["6-Table3-1.png", "4-Table1-1.png"], "answer": "GloVe, BERT, Universal Sentence Encoder, TF-IDF, InferSent"}, "435": {"question": "What other sentence embeddings methods are evaluated?", "referred_figures_indices": [5], "response": "{'Image': 0, 'Rationale': 'Image 0 lists and compares a few sentence embeddings methods along with their performance on the STS benchmark dataset.'}\nThe answer is : The sentence embeddings methods evaluated include average GloVe embeddings, average BERT embeddings, InferSent - GloVe, Universal Sentence Encoder, SBERT-NLI-base, and SBERT-NLI-large. \n", "all_figures_names": ["5-Table2-1.png", "6-Table4-1.png", "6-Table3-1.png", "4-Table1-1.png", "7-Table6-1.png", "7-Table5-1.png", "8-Table7-1.png", "3-Figure1-1.png"], "referred_figures_names": ["7-Table5-1.png"], "answer": "Avg. GloVe embeddings, Avg. fast-text embeddings, Avg. BERT embeddings, BERT CLS-vector, InferSent - GloVe and Universal Sentence Encoder."}}