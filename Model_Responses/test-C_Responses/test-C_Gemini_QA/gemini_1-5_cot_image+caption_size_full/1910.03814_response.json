{"214": {"question": "What is the results of multimodal compared to unimodal models?", "referred_figures_indices": [2, 0], "response": "{'Image': 0, 'Rationale': 'Image 0 is a table that compares the performance of unimodal and multimodal models.'}\nThe answer is : Multimodal models, which combine text and image information, generally outperform unimodal models (text-only) in tasks such as hate speech detection. This is evident from the higher AUC and accuracy scores achieved by models like FCM, SCM, and TKM when trained on both text and image data compared to using only text data. \n", "all_figures_names": ["7-Table1-1.png", "4-Figure3-1.png", "7-Figure6-1.png", "6-Figure4-1.png", "3-Figure2-1.png", "6-Figure5-1.png", "7-Figure7-1.png", "2-Figure1-1.png"], "referred_figures_names": ["7-Figure6-1.png", "7-Table1-1.png"], "answer": "Unimodal LSTM vs Best Multimodal (FCM)\n- F score: 0.703 vs 0.704\n- AUC: 0.732 vs 0.734 \n- Mean Accuracy: 68.3 vs 68.4 "}}