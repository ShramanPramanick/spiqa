{"1259": {"question": "By how much does their method outperform the multi-head attention model?", "referred_figures_indices": [3], "response": "```json\n{'Image': 3, 'Rationale': 'Image 3 lists the performance (CER) of their method (HMHD) and the multi-head attention model (MHA) on different tasks.'}\n```\nThe answer is : The best HMHD model achieves a CER of 10.4%, which is 0.6% better than the best MHA model (MHA-Add, 11.0% CER) on Task 1.  The performance improvement is even greater on Task 2 (0.8% improvement) and Task 3 (0.2% improvement). \n", "all_figures_names": ["4-Table1-1.png", "3-Figure2-1.png", "2-Figure1-1.png", "4-Table2-1.png", "4-Figure3-1.png"], "referred_figures_names": ["4-Table2-1.png"], "answer": "Their average improvement in Character Error Rate over the best MHA model was 0.33 percent points."}, "1260": {"question": "How large is the corpus they use?", "referred_figures_indices": [0], "response": "```json\n{'Image': 0, 'Rationale': 'The table lists the experimental conditions, which likely include details about the corpus size.'}\n```\nThe answer is : 445,068 utterances. \n", "all_figures_names": ["4-Table1-1.png", "2-Figure1-1.png", "3-Figure2-1.png", "4-Table2-1.png", "4-Figure3-1.png"], "referred_figures_names": ["4-Table1-1.png"], "answer": "449050"}}