{"812": {"question": "By how much did they improve?", "referred_figures_indices": [0, 3], "response": "```json\n{'Image': 3, 'Rationale': 'Image 3 compares the scores of the model with and without multitask settings, which helps determine the improvement.'}\n```\nThe answer is : Based on the MAEM scores from Table 3, the improvement from single task biLSTM to biLSTM with Multitask is  0.6944 - 0.685 = **0.0094**. \n", "all_figures_names": ["3-Figure1-1.png", "2-Table1-1.png", "3-Table2-1.png", "5-Table3-1.png", "5-Figure2-1.png"], "referred_figures_names": ["3-Figure1-1.png", "5-Table3-1.png"], "answer": "They decrease MAE in 0.34"}, "813": {"question": "What dataset did they use?", "referred_figures_indices": [1], "response": "{'Image': 1, 'Rationale': 'This table shows the training/dev/test splits along with class distributions of different datasets.'}\nThe answer is : The text does not provide the names of the datasets used. \n", "all_figures_names": ["3-Figure1-1.png", "3-Table2-1.png", "2-Table1-1.png", "5-Table3-1.png", "5-Figure2-1.png"], "referred_figures_names": ["3-Table2-1.png"], "answer": " high-quality datasets  from SemEval-2016 \u201cSentiment Analysis in Twitter\u201d task"}}