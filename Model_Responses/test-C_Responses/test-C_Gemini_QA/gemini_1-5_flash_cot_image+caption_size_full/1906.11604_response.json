{"1392": {"question": "How are sentence embeddings incorporated into the speech recognition system?", "referred_figures_indices": [6, 0], "response": "{'Image': 0, 'Rationale': 'It shows the integration of three types of embeddings into the decoder network.'}\nThe answer is : The sentence embeddings, along with the previous word's embedding and current speech embedding, are incorporated into the speech recognition system through a gated embedding mechanism in the decoder network. The gate mechanism weights the influence of each embedding based on the context. \n", "all_figures_names": ["5-Figure2-1.png", "5-Table1-1.png", "8-Figure5-1.png", "7-Figure3-1.png", "7-Figure4-1.png", "6-Table2-1.png", "4-Figure1-1.png"], "referred_figures_names": ["4-Figure1-1.png", "5-Figure2-1.png"], "answer": "BERT generates sentence embeddings that represent words in context. These sentence embeddings are merged into a single conversational-context vector that is used to calculate a gated embedding and is later combined with the output of the decoder h to provide the gated activations for the next hidden layer."}}