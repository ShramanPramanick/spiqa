{"483": {"question": "Do they conduct any human evaluation?", "referred_figures_indices": [2], "response": "{'Image': 2, 'Rationale': 'The caption of this image explicitly mentions the use of human translations'}\nThe answer is : The paper does not explicitly say that they conduct any human evaluation. However, they do use \"human and machine translations (MT)\" to compare their model's outputs.", "all_figures_names": ["2-Figure2-1.png", "4-Table1-1.png", "2-Figure1-1.png", "6-Table4-1.png", "4-Figure3-1.png", "7-Table7-1.png", "4-Table2-1.png", "5-Table3-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "Yes"}, "485": {"question": "How do they enrich the positional embedding with length information", "referred_figures_indices": [0], "response": "{'Image': 0, 'Rationale': 'Shows the positional embedding being enriched with length information.'}\nThe answer is : The authors enrich the positional embedding by adding a relative length embedding to the positional and word embeddings. The length embedding is computed based on the target string length, which is 12 characters in the example.", "all_figures_names": ["4-Figure3-1.png", "5-Table3-1.png", "7-Table7-1.png", "6-Table4-1.png", "6-Table5-1.png", "4-Table1-1.png", "2-Figure2-1.png", "7-Table6-1.png"], "referred_figures_names": ["4-Figure3-1.png"], "answer": "They introduce new trigonometric encoding which besides information about position uses additional length information (abs or relative)."}, "486": {"question": "How do they condition the output to a given target-source class?", "referred_figures_indices": [4], "response": "{'Image': 0, 'Rationale': 'Image 0 shows the transformer architecture and how the decoder input is enriched with length embedding computed according to the desired target string length.'}\nThe answer is : The input to the decoder is enriched with a relative length embedding computed according to the desired target string length. The length embedding helps the decoder to predict the correct length of the output sequence, and it can be used to condition the output to a given target-source class.", "all_figures_names": ["4-Figure3-1.png", "6-Table4-1.png", "7-Table6-1.png", "4-Table1-1.png", "2-Figure2-1.png", "6-Table5-1.png", "7-Table7-1.png", "5-Table3-1.png"], "referred_figures_names": ["2-Figure2-1.png"], "answer": "They use three groups short/normal/long translation classes to learn length token, which is in inference used to bias network to generate desired length group."}}