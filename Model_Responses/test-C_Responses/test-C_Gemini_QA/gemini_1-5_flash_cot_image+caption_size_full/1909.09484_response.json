{"720": {"question": "How much is proposed model better than baselines in performed experiments?", "referred_figures_indices": [2], "response": "{'Image': 2, 'Rationale': 'This table shows the performance of different models on both datasets and gives the time for training the whole model and training the dialogue policy maker.'}\nThe answer is : The proposed model (GDP) outperforms the baselines (E2ECM, CDM) in terms of BLEU score on both DSTC2 and Maluuba dataset.  GDP achieves a BLEU score of 0.2847 on DSTC2 and 0.1156 on Maluuba, compared to 0.1782 and 0.0797 achieved by E2ECM on the respective datasets. In terms of training time, GDP has significantly higher training time for both full model and dialogue policy maker but achieves the best performance.", "all_figures_names": ["6-Table1-1.png", "8-Table3-1.png", "7-Table2-1.png", "2-Figure1-1.png", "4-Figure2-1.png", "8-Figure3-1.png"], "referred_figures_names": ["7-Table2-1.png"], "answer": "most of the models have similar performance on BPRA: DSTC2 (+0.0015), Maluuba (+0.0729)\nGDP achieves the best performance in APRA: DSTC2 (+0.2893), Maluuba (+0.2896)\nGDP significantly outperforms the baselines on BLEU: DSTC2 (+0.0791), Maluuba (+0.0492)"}}