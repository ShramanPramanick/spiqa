{"434": {"question": "What other sentence embeddings methods are evaluated?", "referred_figures_indices": [3, 0], "response": "{'Image': 2, 'Rationale': 'Shows the performance of different embedding techniques'}\nThe answer is : InferSent - GloVe, Universal Sentence Encoder, SBERT-NLI-base, SBERT-NLI-large, and the RoBERTa-NLI models.", "all_figures_names": ["6-Table3-1.png", "3-Figure2-1.png", "7-Table5-1.png", "4-Table1-1.png", "6-Table4-1.png", "5-Table2-1.png", "3-Figure1-1.png", "7-Table6-1.png"], "referred_figures_names": ["4-Table1-1.png", "6-Table3-1.png"], "answer": "GloVe, BERT, Universal Sentence Encoder, TF-IDF, InferSent"}, "435": {"question": "What other sentence embeddings methods are evaluated?", "referred_figures_indices": [6], "response": "{'Image': 2, 'Rationale': 'Table 2 describes the evaluated sentence embedding methods.'}\nThe answer is : The sentence embedding methods are GloVe, BERT, InferSent, Universal Sentence Encoder, SBERT, and RoBERTa.", "all_figures_names": ["4-Table1-1.png", "3-Figure1-1.png", "5-Table2-1.png", "8-Table7-1.png", "7-Table6-1.png", "6-Table4-1.png", "7-Table5-1.png", "6-Table3-1.png"], "referred_figures_names": ["7-Table5-1.png"], "answer": "Avg. GloVe embeddings, Avg. fast-text embeddings, Avg. BERT embeddings, BERT CLS-vector, InferSent - GloVe and Universal Sentence Encoder."}}