{"2": {"question": "What are the results?", "referred_figures_indices": [3, 2], "response": "{'Image': 2, 'Rationale': 'This image shows the results of using different datasets for training'}\nThe answer is : The results of training a BiGRU model with different datasets are shown. For example, using a smaller dataset of 6,000 samples and then adding in the automatically labeled pairs (AL), the model's accuracy improved from 0.830 to 0.879. Similarly, the BERT model achieved an accuracy of 0.886 when trained on the smaller dataset with AL added, but only 0.876 when trained on the smaller dataset alone. These results highlight the effectiveness of adding additional data for training language models.", "all_figures_names": ["4-Table1-1.png", "5-Table5-1.png", "5-Table4-1.png", "5-Table3-1.png", "4-Table2-1.png", "2-Figure1-1.png"], "referred_figures_names": ["5-Table3-1.png", "5-Table4-1.png"], "answer": "Using all data to train: AL -- BiGRU achieved 0.843 accuracy, AL -- BERT achieved 0.863 accuracy, AL+CA+CO -- BiGRU achieved 0.866 accuracy, AL+CA+CO -- BERT achieved 0.835, accuracy, ACP -- BiGRU achieved 0.919 accuracy, ACP -- BERT achived 0.933, accuracy, ACP+AL+CA+CO -- BiGRU achieved 0.917 accuracy, ACP+AL+CA+CO -- BERT achieved 0.913 accuracy. \nUsing a subset to train: BERT achieved 0.876 accuracy using ACP (6K), BERT achieved 0.886 accuracy using ACP (6K) + AL, BiGRU achieved 0.830 accuracy using ACP (6K), BiGRU achieved 0.879 accuracy using ACP (6K) + AL + CA + CO."}, "3": {"question": "How are relations used to propagate polarity?", "referred_figures_indices": [0], "response": "{'Image': 0, 'Rationale': 'The image shows the three types of relations used to propagate polarity, with clear examples and explanations'}\nThe answer is : Relations are used to propagate polarity by applying different rules based on the type of relation. For example, in a CAUSE relation, the polarity of the latter event is propagated to the former event, whereas in a CONCESSION relation, the polarity is reversed. In CA and CO, the polarity of the latter event is not known, so the model encourages the two events to have the same polarity (CA) or the reverse polarity (CO).", "all_figures_names": ["2-Figure1-1.png", "5-Table4-1.png", "5-Table3-1.png", "4-Table2-1.png", "5-Table5-1.png", "4-Table1-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "based on the relation between events, the suggested polarity of one event can determine the possible polarity of the other event "}, "4": {"question": "How are relations used to propagate polarity?", "referred_figures_indices": [3], "response": "{'Image': 3, 'Rationale': 'This image shows the relationship between former and latter events in regards to polarity.'}\nThe answer is : In this method, relations are used to propagate polarity from a latter event to a former event. If the relation is CAUSE, the polarity of the latter event is propagated to the former event. If the relation is CONCESSION, the polarity of the latter event is reversed and then propagated to the former event.", "all_figures_names": ["4-Table1-1.png", "5-Table4-1.png", "4-Table2-1.png", "2-Figure1-1.png", "5-Table3-1.png", "5-Table5-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "cause relation: both events in the relation should have the same polarity; concession relation: events should have opposite polarity"}, "5": {"question": "How big is the Japanese data?", "referred_figures_indices": [1, 4], "response": "{'Image': 4, 'Rationale': 'Image 4 contains the details of the ACP dataset.'}\nThe answer is : The Japanese data, also known as the ACP dataset, consists of 299,834 positive events and 300,164 negative events.", "all_figures_names": ["5-Table4-1.png", "4-Table1-1.png", "5-Table3-1.png", "2-Figure1-1.png", "4-Table2-1.png", "5-Table5-1.png"], "referred_figures_names": ["4-Table1-1.png", "4-Table2-1.png"], "answer": "7000000 pairs of events were extracted from the Japanese Web corpus, 529850 pairs of events were extracted from the ACP corpus"}, "6": {"question": "How big is the Japanese data?", "referred_figures_indices": [4], "response": "{'Image': 0, 'Rationale': 'Image 0 provides the number of pairs in the dataset'}\nThe answer is : The Japanese data is comprised of 11 million pairs.", "all_figures_names": ["4-Table1-1.png", "5-Table4-1.png", "2-Figure1-1.png", "5-Table5-1.png", "4-Table2-1.png", "5-Table3-1.png"], "referred_figures_names": ["4-Table2-1.png"], "answer": "The ACP corpus has around 700k events split into positive and negative polarity "}, "8": {"question": "How big are improvements of supervszed learning results trained on smalled labeled data enhanced with proposed approach copared to basic approach?", "referred_figures_indices": [3], "response": "{'Image': 3, 'Rationale': 'Image 3 contains information about the performance of smaller labeled datasets with and without augmentation'}\nThe answer is : The proposed approach shows an improvement from 0.830 to 0.879 accuracy with a BiGRU encoder on a smaller dataset, compared to the basic approach. The BERT encoder shows an improvement from 0.876 to 0.886 accuracy for the same scenario.", "all_figures_names": ["5-Table3-1.png", "5-Table5-1.png", "4-Table1-1.png", "5-Table4-1.png", "4-Table2-1.png", "2-Figure1-1.png"], "referred_figures_names": ["5-Table4-1.png"], "answer": "3%"}, "9": {"question": "How does their model learn using mostly raw data?", "referred_figures_indices": [5], "response": "{'Image': 3, 'Rationale': 'Shows that the model is trained on 3 different datasets, AL, CA and CO'}\nThe answer is : The model learns using three datasets: AL, CA, and CO, each consisting of a million pairs of events. The model is trained using raw data from these three datasets.", "all_figures_names": ["5-Table5-1.png", "5-Table3-1.png", "4-Table2-1.png", "4-Table1-1.png", "5-Table4-1.png", "2-Figure1-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "by exploiting discourse relations to propagate polarity from seed predicates to final sentiment polarity"}, "10": {"question": "How big is seed lexicon used for training?", "referred_figures_indices": [3], "response": "{'Image': 2, 'Rationale': 'This image mentions \"seed lexicon\" in the explanation.'}\nThe answer is : The seed lexicon is used to determine the polarity (positive or negative) of the latter event.", "all_figures_names": ["5-Table3-1.png", "5-Table5-1.png", "2-Figure1-1.png", "4-Table1-1.png", "5-Table4-1.png", "4-Table2-1.png"], "referred_figures_names": ["4-Table1-1.png"], "answer": "30 words"}}