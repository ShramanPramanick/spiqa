{"252": {"question": "Which other approaches do they compare their model with?", "referred_figures_indices": [3], "response": "{'Image': 3, 'Rationale': 'This table explicitly compares the model with existing approaches.'}\nThe answer is : The paper compares its model to the work of Akbik et al. (2018) and Link et al. (2012).", "all_figures_names": ["4-Figure2-1.png", "2-Figure1-1.png", "5-Table2-1.png", "6-Table3-1.png", "5-Figure3-1.png", "2-Table1-1.png"], "referred_figures_names": ["6-Table3-1.png"], "answer": "Akbik et al. (2018), Link et al. (2012)"}, "253": {"question": "Which other approaches do they compare their model with?", "referred_figures_indices": [0], "response": "{'Image': 0, 'Rationale': 'This table shows the performance of other models'}\nThe answer is : The model is compared to Akbik et al. (2018) and Link et al. (2012) models.", "all_figures_names": ["6-Table3-1.png", "5-Table2-1.png", "2-Table1-1.png", "5-Figure3-1.png", "4-Figure2-1.png", "2-Figure1-1.png"], "referred_figures_names": ["6-Table3-1.png"], "answer": "They compare to Akbik et al. (2018) and Link et al. (2012)."}, "254": {"question": "What results do they achieve using their proposed approach?", "referred_figures_indices": [3, 0], "response": "{'Image': 3, 'Rationale': 'The image shows the performance of the proposed model, including the precision, recall, and F-1 scores for each category.'}\nThe answer is : The proposed approach achieved precision of 79%, recall of 59%, and F-1 score of 66% for the 'person' category, precision of 62%, recall of 47%, and F-1 score of 54% for the 'location' category, precision of 45%, recall of 16%, and F-1 score of 23% for the 'organization' category, precision of 81%, recall of 17%, and F-1 score of 28% for the 'event' category, precision of 44%, recall of 4%, and F-1 score of 8% for the 'product' category, precision of 81%, recall of 17%, and F-1 score of 11% for the 'building' category, and precision of 0%, recall of 0%, and F-1 score of 0% for the 'art' category.", "all_figures_names": ["5-Figure3-1.png", "2-Figure1-1.png", "2-Table1-1.png", "5-Table2-1.png", "6-Table3-1.png", "4-Figure2-1.png"], "referred_figures_names": ["5-Table2-1.png", "5-Figure3-1.png"], "answer": "F-1 score on the OntoNotes is 88%, and it is 53% on Wiki (gold)."}, "256": {"question": "How do they combine a deep learning model with a knowledge base?", "referred_figures_indices": [1], "response": "{'Image': 1, 'Rationale': 'Shows the Wikidata being used as the knowledge base and the deep learning model is the LSTM'}\nThe answer is : A deep learning model, specifically a bidirectional LSTM, is used to extract entities from text. These entities are then passed to a knowledge base, in this case, Wikidata, to enhance the understanding and provide more context.  The knowledge base helps to link the extracted entities to their corresponding real-world information, enriching the model's ability to comprehend and reason about the text.", "all_figures_names": ["2-Figure1-1.png", "4-Figure2-1.png", "5-Table2-1.png", "2-Table1-1.png", "5-Figure3-1.png", "6-Table3-1.png"], "referred_figures_names": ["4-Figure2-1.png"], "answer": "Entities from a deep learning model are linked to the related entities from a knowledge base by a lookup."}}