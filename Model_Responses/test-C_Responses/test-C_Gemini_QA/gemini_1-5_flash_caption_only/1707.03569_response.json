{"812": {"question": "By how much did they improve?", "referred_figures_indices": [0, 3], "response": "```json\n{'Answer': 'The caption does not provide information on how much they improved. The caption describes the multitask setting which achieves the best performance but does not quantify the improvement.'}\n```", "all_figures_names": ["3-Figure1-1.png", "3-Table2-1.png", "5-Figure2-1.png", "5-Table3-1.png", "2-Table1-1.png"], "referred_figures_names": ["3-Figure1-1.png", "5-Table3-1.png"], "answer": "They decrease MAE in 0.34"}, "813": {"question": "What dataset did they use?", "referred_figures_indices": [2], "response": "```json\n{'Answer': 'The captions do not mention a specific dataset. They only discuss the cardinality and class distributions of datasets (Caption 2) and the scores on MAEM for different systems (Caption 3).'}\n```", "all_figures_names": ["2-Table1-1.png", "3-Figure1-1.png", "3-Table2-1.png", "5-Table3-1.png", "5-Figure2-1.png"], "referred_figures_names": ["3-Table2-1.png"], "answer": " high-quality datasets  from SemEval-2016 \u201cSentiment Analysis in Twitter\u201d task"}}