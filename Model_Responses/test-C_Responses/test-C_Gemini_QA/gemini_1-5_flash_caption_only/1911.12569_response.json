{"362": {"question": "What was their result on Stance Sentiment Emotion Corpus?", "referred_figures_indices": [1], "response": "```json\n{'Answer': 'The captions do not provide information on the result of any model on the Stance Sentiment Emotion Corpus (SSEC). The captions only mention SSEC as the dataset used for sentiment and emotion analysis (Caption 4). '}\n```", "all_figures_names": ["3-Figure1-1.png", "5-TableII-1.png", "7-TableXI-1.png", "5-TableIII-1.png", "5-TableI-1.png", "6-TableIV-1.png", "5-Figure2-1.png"], "referred_figures_names": ["5-TableII-1.png"], "answer": "F1 score of 66.66%"}, "363": {"question": "What performance did they obtain on the SemEval dataset?", "referred_figures_indices": [4], "response": "```json\n{'Answer': 'Table IV shows the comparison with state-of-the-art systems proposed by [16] on the emotion dataset. The metrics P, R and F stand for precision, recall and F1-score.'}\n```", "all_figures_names": ["5-TableI-1.png", "3-Figure1-1.png", "7-TableXI-1.png", "5-Figure2-1.png", "5-TableII-1.png", "6-TableIV-1.png", "5-TableIII-1.png"], "referred_figures_names": ["5-TableII-1.png"], "answer": "F1 score of 82.10%"}, "364": {"question": "What are the state-of-the-art systems?", "referred_figures_indices": [0, 5], "response": "```json\n{'Answer': 'The state-of-the-art systems are mentioned in Table III, Table IV and Table XI. Table III compares the performance with systems from SemEval 2016 Task 6 on sentiment datasets, Table IV compares the systems proposed by [16] on emotion datasets, and Table XI is a confusion matrix for sadness.'}\n```", "all_figures_names": ["5-TableIII-1.png", "5-Figure2-1.png", "7-TableXI-1.png", "5-TableI-1.png", "5-TableII-1.png", "6-TableIV-1.png", "3-Figure1-1.png"], "referred_figures_names": ["5-TableIII-1.png", "6-TableIV-1.png"], "answer": "For sentiment analysis UWB, INF-UFRGS-OPINION-MINING, LitisMind, pkudblab and SVM + n-grams + sentiment and for emotion analysis MaxEnt, SVM, LSTM, BiLSTM and CNN"}}