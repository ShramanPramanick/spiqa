{"845": {"question": "By how much does their best model outperform the state-of-the-art?", "referred_figures_indices": [2], "response": "```json\n{'Answer': 'The captions provide information on F1 scores for CNN and RNN models, but they don't mention the performance compared to the state-of-the-art. Therefore, the answer cannot be determined from the given captions.'}\n```", "all_figures_names": ["4-Table1-1.png", "5-Table2-1.png", "5-Table3-1.png", "3-Figure1-1.png", "3-Figure2-1.png"], "referred_figures_names": ["5-Table3-1.png"], "answer": "0.8% F1 better than the best state-of-the-art"}, "846": {"question": "By how much does their best model outperform the state-of-the-art?", "referred_figures_indices": [1], "response": "```json\n{'Answer': 'The captions do not contain information about the performance of the best model or a state-of-the-art model. Therefore, I cannot answer the question.'}\n```", "all_figures_names": ["3-Figure1-1.png", "5-Table3-1.png", "3-Figure2-1.png", "4-Table1-1.png", "5-Table2-1.png"], "referred_figures_names": ["5-Table3-1.png"], "answer": "Best proposed model achieves F1 score of 84.9 compared to best previous result of 84.1."}, "852": {"question": "How do they obtain the new context represetation?", "referred_figures_indices": [3], "response": "```json\n{'Answer': 'The captions don't provide information on how new context representation is obtained. They focus on results, components, and model visualizations (RNN, CNN) but not the specific process of context representation creation.'}\n```", "all_figures_names": ["5-Table3-1.png", "3-Figure2-1.png", "4-Table1-1.png", "3-Figure1-1.png", "5-Table2-1.png"], "referred_figures_names": ["3-Figure1-1.png"], "answer": "They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."}}