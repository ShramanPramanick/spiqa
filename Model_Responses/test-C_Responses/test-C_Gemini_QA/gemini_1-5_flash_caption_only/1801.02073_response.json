{"1000": {"question": "Do they employ their indexing-based method to create a sample of a QA Wikipedia dataset?", "referred_figures_indices": [4], "response": "```json\n{'Answer': 'The provided captions do not mention using an indexing-based method to create a sample of a QA Wikipedia dataset.'}\n```", "all_figures_names": ["3-Figure1-1.png", "2-Table1-1.png", "3-Figure2-1.png", "4-Table3-1.png", "3-Table2-1.png"], "referred_figures_names": ["3-Table2-1.png"], "answer": "Yes"}, "1003": {"question": "How many question types do they find in the datasets analyzed?", "referred_figures_indices": [4], "response": "```json\n{'Answer': 'The answer cannot be found in the provided captions.'}\n```", "all_figures_names": ["2-Table1-1.png", "4-Table3-1.png", "3-Table2-1.png", "3-Figure2-1.png", "3-Figure1-1.png"], "referred_figures_names": ["3-Figure1-1.png"], "answer": "7"}, "1004": {"question": "How do they analyze contextual similaries across datasets?", "referred_figures_indices": [4], "response": "```json\n{'Answer': 'The provided captions do not describe how contextual similarities across datasets are analyzed. They focus on statistics about datasets (e.g., question types, answer categories, answer retrieval accuracy) and comparisons between them (e.g., annotation types, answer selection performance). There is no information on how contextual similarity is measured or compared.'}\n```", "all_figures_names": ["3-Table2-1.png", "4-Table3-1.png", "3-Figure1-1.png", "3-Figure2-1.png", "2-Table1-1.png"], "referred_figures_names": ["2-Table1-1.png"], "answer": "They compare the tasks that the datasets are suitable for, average number of answer candidates per question, number of token types, average answer candidate lengths, average question lengths, question-answer word overlap."}}