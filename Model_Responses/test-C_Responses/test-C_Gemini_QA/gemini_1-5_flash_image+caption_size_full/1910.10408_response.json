{"483": {"question": "Do they conduct any human evaluation?", "referred_figures_indices": [2], "response": "{'Answer': 'The provided images do not mention any human evaluation. They only mention machine translation techniques and metrics. Therefore, it is impossible to tell whether any human evaluation is conducted.'}", "all_figures_names": ["2-Figure2-1.png", "7-Table6-1.png", "2-Figure1-1.png", "4-Table2-1.png", "4-Figure3-1.png", "7-Table7-1.png", "6-Table4-1.png", "6-Table5-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "Yes"}, "485": {"question": "How do they enrich the positional embedding with length information", "referred_figures_indices": [7], "response": "{'Answer': 'The decoder input is enriched with length information by adding a relative length embedding to the position and word embedding. For example, for a target length of 12, the length embeddings of the decoder input are 0/12, 1/12, 2/12, and 3/12. This allows the decoder to attend to different parts of the target sentence based on their relative position in the sentence.'}", "all_figures_names": ["7-Table6-1.png", "4-Table2-1.png", "2-Figure1-1.png", "4-Table1-1.png", "6-Table5-1.png", "7-Table7-1.png", "2-Figure2-1.png", "4-Figure3-1.png"], "referred_figures_names": ["4-Figure3-1.png"], "answer": "They introduce new trigonometric encoding which besides information about position uses additional length information (abs or relative)."}, "486": {"question": "How do they condition the output to a given target-source class?", "referred_figures_indices": [1], "response": "{'Answer': 'The authors train three different models: short, normal, and long. Short models are trained on sentences shorter than the average sentence length; normal models are trained on sentences of average length; and long models are trained on sentences longer than the average sentence length. At inference time, the model can then be conditioned to generate a translation that is of a similar length as the input sentence.'}", "all_figures_names": ["4-Table2-1.png", "2-Figure2-1.png", "4-Figure3-1.png", "6-Table4-1.png", "5-Table3-1.png", "7-Table6-1.png", "2-Figure1-1.png", "7-Table7-1.png"], "referred_figures_names": ["2-Figure2-1.png"], "answer": "They use three groups short/normal/long translation classes to learn length token, which is in inference used to bias network to generate desired length group."}}