{"883": {"question": "Do the methods that work best on academic papers also work best on Wikipedia?", "referred_figures_indices": [1], "response": "{'Answer': 'The Joint model appears to perform the best on Wikipedia based on the experimental results in Table 1. The Joint model achieves an accuracy of 59.4 \u00b1 0.47%, compared to the other methods, which have lower accuracy. '}", "all_figures_names": ["4-Table2-1.png", "4-Table1-1.png", "3-Figure2-1.png", "1-Figure1-1.png"], "referred_figures_names": ["4-Table1-1.png"], "answer": "No"}, "884": {"question": "What is their system's absolute accuracy?", "referred_figures_indices": [3], "response": "{'Answer': 'The absolute accuracy of their system on Wikipedia is 59.4\u00b10.47%.'}", "all_figures_names": ["1-Figure1-1.png", "4-Table2-1.png", "3-Figure2-1.png", "4-Table1-1.png"], "referred_figures_names": ["4-Table1-1.png"], "answer": "59.4% on wikipedia dataset, 93.4% on peer-reviewed archive AI papers, 77.1%  on peer-reviewed archive Computation and Language papers, and 79.9% on peer-reviewed archive Machine Learning papers"}, "887": {"question": "Which languages do they use?", "referred_figures_indices": [2], "response": "{'Answer': 'The images do not provide information on the languages used.'}", "all_figures_names": ["1-Figure1-1.png", "3-Figure2-1.png", "4-Table2-1.png", "4-Table1-1.png"], "referred_figures_names": ["4-Table2-1.png"], "answer": "English"}, "888": {"question": "How large is their data set?", "referred_figures_indices": [0], "response": "{'Answer': 'The data set consists of Wikipedia and peer review articles.'}", "all_figures_names": ["4-Table1-1.png", "4-Table2-1.png", "1-Figure1-1.png", "3-Figure2-1.png"], "referred_figures_names": ["4-Table1-1.png"], "answer": "a sample of  29,794 wikipedia articles and 2,794 arXiv papers "}}