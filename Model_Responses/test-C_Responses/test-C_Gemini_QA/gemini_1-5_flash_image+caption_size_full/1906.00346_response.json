{"1011": {"question": "IS the graph representation supervised?", "referred_figures_indices": [2, 0], "response": "{'Answer': 'The graph representation is used in the G-BERT model which is a supervised method that uses ontology embedding, BERT, and a fine-tuned classifier for medication recommendation. Therefore, the graph representation is supervised.'}", "all_figures_names": ["3-Table1-1.png", "6-Table3-1.png", "3-Figure2-1.png", "5-Table2-1.png", "1-Figure1-1.png"], "referred_figures_names": ["3-Figure2-1.png", "3-Table1-1.png"], "answer": "The graph representation appears to be semi-supervised. It is included in the learning pipeline for the medical recommendation, where the attention model is learned. (There is some additional evidence that is unavailable in parsed text)"}, "1012": {"question": "Is the G-BERT model useful beyond the task considered?", "referred_figures_indices": [4], "response": "{'Answer': 'G-BERT is not specifically mentioned as being applicable to tasks beyond medication recommendation. However, the model can be used to predict other medical events based on patient visit data.'}", "all_figures_names": ["5-Table2-1.png", "3-Table1-1.png", "6-Table3-1.png", "1-Figure1-1.png", "3-Figure2-1.png"], "referred_figures_names": ["3-Figure2-1.png"], "answer": "There is nothing specific about the approach that depends on medical recommendations. The approach combines graph data and text data into a single embedding."}}