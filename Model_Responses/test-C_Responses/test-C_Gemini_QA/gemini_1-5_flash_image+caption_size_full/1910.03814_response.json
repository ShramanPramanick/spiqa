{"214": {"question": "What is the results of multimodal compared to unimodal models?", "referred_figures_indices": [0, 1], "response": "{'Answer': 'According to the table, multimodal models, which incorporate both image and text inputs, generally achieve better performance in terms of F-score, AUC, and ACC compared to unimodal models, which rely solely on text or image information. For example, the FCM model with text and image inputs achieves a higher F-score and AUC than the FCM model using only text or image inputs, indicating better performance in hate speech detection.'}", "all_figures_names": ["7-Figure6-1.png", "7-Table1-1.png", "6-Figure5-1.png", "3-Figure2-1.png", "7-Figure7-1.png", "2-Figure1-1.png", "4-Figure3-1.png", "6-Figure4-1.png"], "referred_figures_names": ["7-Figure6-1.png", "7-Table1-1.png"], "answer": "Unimodal LSTM vs Best Multimodal (FCM)\n- F score: 0.703 vs 0.704\n- AUC: 0.732 vs 0.734 \n- Mean Accuracy: 68.3 vs 68.4 "}}