{"1392": {"question": "How are sentence embeddings incorporated into the speech recognition system?", "referred_figures_indices": [5, 1], "response": "{'Answer': 'The figure shows that the convolutional-context embedding is incorporated into the decoder network of the speech recognition system using a gating mechanism that combines embeddings from the previous word, the current speech, and conversational-context embeddings. The gating mechanism is used to weight the contributions of these embeddings, allowing the decoder to focus on the most relevant information when generating the next word.'}", "all_figures_names": ["5-Table1-1.png", "4-Figure1-1.png", "8-Figure5-1.png", "7-Figure4-1.png", "6-Table2-1.png", "5-Figure2-1.png", "7-Figure3-1.png"], "referred_figures_names": ["5-Figure2-1.png", "4-Figure1-1.png"], "answer": "BERT generates sentence embeddings that represent words in context. These sentence embeddings are merged into a single conversational-context vector that is used to calculate a gated embedding and is later combined with the output of the decoder h to provide the gated activations for the next hidden layer."}}