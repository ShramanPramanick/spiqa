{"909": {"question": "What is best performing model among author's submissions, what performance it had?", "referred_figures_indices": [3], "response": "{'Answer': 'The input captions do not contain the best performing model and its performance metrics. Therefore, I cannot answer the question.'}\n", "all_figures_names": ["4-Table3-1.png", "3-Figure1-1.png", "2-Table1-1.png", "3-Table2-1.png", "4-Table4-1.png"], "referred_figures_names": ["3-Table2-1.png"], "answer": "For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."}, "910": {"question": "What extracted features were most influencial on performance?", "referred_figures_indices": [0], "response": "{'Answer': 'While the provided context mentions various features and classifiers used, there is no direct answer regarding the most influential extracted features on performance. Further analysis of the tables and figures, particularly comparing performance metrics against different feature sets, is needed to answer that question.'}", "all_figures_names": ["4-Table3-1.png", "2-Table1-1.png", "3-Figure1-1.png", "4-Table4-1.png", "3-Table2-1.png"], "referred_figures_names": ["4-Table3-1.png"], "answer": "Linguistic"}, "912": {"question": "Did ensemble schemes help in boosting peformance, by how much?", "referred_figures_indices": [3], "response": "{'Answer': 'Ensemble schemes boosted the performance of FLC, as shown in Table 4. However, the exact percentage increase is not mentioned.'}", "all_figures_names": ["3-Figure1-1.png", "3-Table2-1.png", "2-Table1-1.png", "4-Table3-1.png", "4-Table4-1.png"], "referred_figures_names": ["4-Table3-1.png"], "answer": "The best ensemble topped the best single model by 0.029 in F1 score on dev (external)."}, "913": {"question": "Did ensemble schemes help in boosting peformance, by how much?", "referred_figures_indices": [2, 4, 3], "response": "{'Answer': 'Although there are tables that show results for different models and features, there is no information on the performance difference when using ensemble methods. Therefore, I cannot answer your question.'}", "all_figures_names": ["2-Table1-1.png", "3-Figure1-1.png", "3-Table2-1.png", "4-Table3-1.png", "4-Table4-1.png"], "referred_figures_names": ["3-Table2-1.png", "4-Table4-1.png", "4-Table3-1.png"], "answer": "They increased F1 Score by 0.029 in Sentence Level Classification, and by 0.044 in Fragment-Level classification"}, "914": {"question": "Which basic neural architecture perform best by itself?", "referred_figures_indices": [0], "response": "{'Answer': 'Based on the captions provided, the best-performing basic neural architecture by itself is **CNN (Convolutional Neural Network)**. \n\nThis information is derived from Caption 2, which mentions CNN as one of the classifiers used in conjunction with transfer learning from pre-trained word embeddings. While the caption highlights a multi-tasking LSTM-CRF architecture for FLC, it doesn\\'t explicitly compare its individual performance to CNN.  The tables focus on comparing different system configurations and don\\'t offer a direct comparison of individual architectures like CNN against others in isolation.'} \n", "all_figures_names": ["4-Table3-1.png", "2-Table1-1.png", "3-Figure1-1.png", "3-Table2-1.png", "4-Table4-1.png"], "referred_figures_names": ["4-Table3-1.png"], "answer": "BERT"}, "915": {"question": "What participating systems had better results than ones authors submitted?", "referred_figures_indices": [4], "response": "{'Answer': 'Table 4 shows the FLC scores of different models on the Dev set, while Table 2 shows the comparison of the authors system with the top 5 participants, implying that some participating systems had better results.'}", "all_figures_names": ["4-Table3-1.png", "3-Figure1-1.png", "2-Table1-1.png", "4-Table4-1.png", "3-Table2-1.png"], "referred_figures_names": ["3-Table2-1.png"], "answer": "For SLC task : Ituorp, ProperGander and YMJA  teams had better results.\nFor FLC task: newspeak and Antiganda teams had better results."}, "916": {"question": "What is specific to multi-granularity and multi-tasking neural arhiteture design?", "referred_figures_indices": [4], "response": "{'Answer': 'A specific characteristic of multi-granularity and multi-tasking neural architecture design, as exemplified in the context provided, is the incorporation of a binary classification component within a recurrent architecture (like LSTM-CRF) to jointly handle tasks at different levels of granularity, such as Propaganda Fragment Detection (PFD), Fact-Level Claim extraction (FLC), and Sentence-Level Classification (SLC). This simultaneous processing of multiple tasks with varying granularities highlights a key aspect of such architectures.'} \n", "all_figures_names": ["4-Table3-1.png", "2-Table1-1.png", "3-Table2-1.png", "4-Table4-1.png", "3-Figure1-1.png"], "referred_figures_names": ["3-Figure1-1.png"], "answer": "An output layer for each task"}}