{"951": {"question": "what are the evaluation metrics?", "referred_figures_indices": [2], "response": "{'Answer': 'Based on the provided captions, the evaluation metrics appear to be based on the results of the CoNLL 2002 Spanish and CoNLL 2003 English evaluations. Specific metrics are not mentioned in these captions.'}", "all_figures_names": ["9-Table3-1.png", "16-Table9-1.png", "15-Table5-1.png", "22-Table19-1.png", "13-Table4-1.png", "6-Table2-1.png", "18-Table13-1.png", "21-Table17-1.png"], "referred_figures_names": ["15-Table5-1.png"], "answer": "Precision, Recall, F1"}, "952": {"question": "which datasets were used in evaluation?", "referred_figures_indices": [1], "response": "```json\n{'Answer': 'The datasets used for evaluation include CoNLL 2002 Dutch, MUC7, SONAR-1, Ancora 2.0, Basque Egunkaria, GermEval 2014 outer, CoNLL data, Ancora (20150130 version).'}\n```", "all_figures_names": ["17-Table10-1.png", "5-Table1-1.png", "19-Table15-1.png", "18-Table12-1.png", "6-Table2-1.png", "19-Table14-1.png", "13-Table4-1.png", "22-Table18-1.png"], "referred_figures_names": ["5-Table1-1.png"], "answer": "CoNLL 2003, GermEval 2014, CoNLL 2002, Egunkaria, MUC7, Wikigold, MEANTIME, SONAR-1, Ancora 2.0"}}