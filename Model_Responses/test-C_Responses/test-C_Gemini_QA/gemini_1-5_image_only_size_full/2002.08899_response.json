{"874": {"question": "Do they perform a quantitative analysis of their model displaying knowledge distortions?", "referred_figures_indices": [1, 0], "response": "{'Answer': 'The provided document and images don't contain information on whether they perform a quantitative analysis of their model displaying knowledge distortions. Therefore, I cannot answer your question.'}\n", "all_figures_names": ["5-Figure2-1.png", "4-Table2-1.png", "2-Figure1-1.png", "4-Table1-1.png"], "referred_figures_names": ["4-Table2-1.png", "5-Figure2-1.png"], "answer": "Yes"}, "875": {"question": "How do they damage different neural modules?", "referred_figures_indices": [2], "response": "{'Answer': 'They damage different neural modules (LSTMs vs lexicon unit) by zeroing out the module\u2019s parameters or activations.'}", "all_figures_names": ["4-Table1-1.png", "2-Figure1-1.png", "4-Table2-1.png", "5-Figure2-1.png"], "referred_figures_names": ["4-Table2-1.png"], "answer": "Damage to neural modules is done by randomly initializing their weights, causing the loss of all learned information."}}