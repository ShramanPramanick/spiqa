{"909": {"question": "What is best performing model among author's submissions, what performance it had?", "referred_figures_indices": [2], "response": "{'Answer': 'The best performing model by the author achieves an F1 score of 0.676.'}", "all_figures_names": ["3-Figure1-1.png", "4-Table4-1.png", "3-Table2-1.png", "4-Table3-1.png", "2-Table1-1.png"], "referred_figures_names": ["3-Table2-1.png"], "answer": "For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."}, "910": {"question": "What extracted features were most influencial on performance?", "referred_figures_indices": [2], "response": "{'Answer': 'Based on the given tables, BERT embeddings consistently demonstrate strong performance.  For instance, in \"Image 2\", rows r9-r12 highlight the contribution of BERT, especially when fine-tuned. Similarly, \"Image 4\" emphasizes the significance of BERT embeddings, notably in combination with multi-task learning (PFD) in ensembles. '}\n", "all_figures_names": ["3-Table2-1.png", "2-Table1-1.png", "4-Table3-1.png", "3-Figure1-1.png", "4-Table4-1.png"], "referred_figures_names": ["4-Table3-1.png"], "answer": "Linguistic"}, "912": {"question": "Did ensemble schemes help in boosting peformance, by how much?", "referred_figures_indices": [0], "response": "{'Answer': 'Yes, for instance, in Image 0, row 15, an ensemble of models r3, r5 and r6, with majority voting, boosted the performance by 2 percentage points from .645 to .665 in terms of F1 score.'}", "all_figures_names": ["4-Table3-1.png", "3-Table2-1.png", "2-Table1-1.png", "4-Table4-1.png", "3-Figure1-1.png"], "referred_figures_names": ["4-Table3-1.png"], "answer": "The best ensemble topped the best single model by 0.029 in F1 score on dev (external)."}, "913": {"question": "Did ensemble schemes help in boosting peformance, by how much?", "referred_figures_indices": [1, 3, 0], "response": "{'Answer': 'Yes, for example, in the first image, on the Dev (external) column, an F1 score of 0.678 was achieved using ensemble, compared to the best performing individual model with an F1 score of 0.650, an improvement of 2.8 percentage points.'}", "all_figures_names": ["4-Table3-1.png", "4-Table4-1.png", "2-Table1-1.png", "3-Table2-1.png", "3-Figure1-1.png"], "referred_figures_names": ["4-Table4-1.png", "3-Table2-1.png", "4-Table3-1.png"], "answer": "They increased F1 Score by 0.029 in Sentence Level Classification, and by 0.044 in Fragment-Level classification"}, "914": {"question": "Which basic neural architecture perform best by itself?", "referred_figures_indices": [1], "response": "{'Answer': 'Based on the information provided, BERT by itself achieves a 0.662 F1 score, outperforming other base architectures.'}", "all_figures_names": ["2-Table1-1.png", "4-Table3-1.png", "3-Figure1-1.png", "4-Table4-1.png", "3-Table2-1.png"], "referred_figures_names": ["4-Table3-1.png"], "answer": "BERT"}, "915": {"question": "What participating systems had better results than ones authors submitted?", "referred_figures_indices": [3], "response": "{'Answer': 'The team ''ltuorp'' got the best result in the SLC task with F1 score as 0.6323.'}", "all_figures_names": ["2-Table1-1.png", "4-Table4-1.png", "4-Table3-1.png", "3-Table2-1.png", "3-Figure1-1.png"], "referred_figures_names": ["3-Table2-1.png"], "answer": "For SLC task : Ituorp, ProperGander and YMJA  teams had better results.\nFor FLC task: newspeak and Antiganda teams had better results."}, "916": {"question": "What is specific to multi-granularity and multi-tasking neural arhiteture design?", "referred_figures_indices": [0], "response": "{'Answer': 'Multi-granularity is about incorporating information from different levels of granularity, while multi-tasking involves training a single model to perform multiple related tasks simultaneously.'}", "all_figures_names": ["3-Figure1-1.png", "2-Table1-1.png", "4-Table3-1.png", "4-Table4-1.png", "3-Table2-1.png"], "referred_figures_names": ["3-Figure1-1.png"], "answer": "An output layer for each task"}}