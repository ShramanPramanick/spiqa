{"715": {"question": "To what other competitive baselines is this approach compared?", "referred_figures_indices": [1], "response": "{'Answer': 'The authors compared their approach to the following methods: LSTM, LSTM (attn), HRED, VHRED, MMI, VHRED (attn), Reranking-RL, LFT, and RL.'}", "all_figures_names": ["5-Figure6-1.png", "5-Table1-1.png", "4-Figure5-1.png", "6-Table3-1.png", "7-Table4-1.png", "6-Table2-1.png", "3-Figure1-1.png", "4-Figure3-1.png"], "referred_figures_names": ["5-Table1-1.png"], "answer": "LSTMs with and without attention, HRED, VHRED with and without attention, MMI and Reranking-RL"}, "717": {"question": "How much better were results of the proposed models than base LSTM-RNN model?", "referred_figures_indices": [3], "response": "{'Answer': 'The MinAvgOut model achieved the best performance, with an Average score of 3.65, which is 0.61 points better than the base LSTM-RNN model.'}", "all_figures_names": ["3-Figure1-1.png", "3-Figure2-1.png", "6-Table3-1.png", "5-Table1-1.png", "7-Table4-1.png", "4-Figure5-1.png", "4-Figure4-1.png", "4-Figure3-1.png"], "referred_figures_names": ["5-Table1-1.png"], "answer": "on diversity 6.87 and on relevance 4.6 points higher"}, "718": {"question": "Which one of the four proposed models performed best?", "referred_figures_indices": [7, 2], "response": "{'Answer': 'MinAvgOut + RL performed best.'}", "all_figures_names": ["5-Figure6-1.png", "4-Figure5-1.png", "5-Table1-1.png", "3-Figure2-1.png", "4-Figure3-1.png", "6-Table2-1.png", "4-Figure4-1.png", "7-Table4-1.png"], "referred_figures_names": ["7-Table4-1.png", "5-Table1-1.png"], "answer": "the hybrid model MinAvgOut + RL"}}