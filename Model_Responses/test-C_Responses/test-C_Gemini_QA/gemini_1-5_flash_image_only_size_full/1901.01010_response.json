{"883": {"question": "Do the methods that work best on academic papers also work best on Wikipedia?", "referred_figures_indices": [1], "response": "{'Answer': 'No, the table in Image 1 suggests that the Joint model is better than the others for Wikipedia but not for peer reviewed papers.  The best model for peer reviewed papers is BiLSTM.'}", "all_figures_names": ["3-Figure2-1.png", "4-Table1-1.png", "4-Table2-1.png", "1-Figure1-1.png"], "referred_figures_names": ["4-Table1-1.png"], "answer": "No"}, "884": {"question": "What is their system's absolute accuracy?", "referred_figures_indices": [1], "response": "{'Answer': '81.11%'}", "all_figures_names": ["1-Figure1-1.png", "4-Table1-1.png", "3-Figure2-1.png", "4-Table2-1.png"], "referred_figures_names": ["4-Table1-1.png"], "answer": "59.4% on wikipedia dataset, 93.4% on peer-reviewed archive AI papers, 77.1%  on peer-reviewed archive Computation and Language papers, and 79.9% on peer-reviewed archive Machine Learning papers"}, "887": {"question": "Which languages do they use?", "referred_figures_indices": [2], "response": "{'Answer': 'English'}", "all_figures_names": ["1-Figure1-1.png", "3-Figure2-1.png", "4-Table2-1.png", "4-Table1-1.png"], "referred_figures_names": ["4-Table2-1.png"], "answer": "English"}, "888": {"question": "How large is their data set?", "referred_figures_indices": [1], "response": "{'Answer': 'The Wikipedia dataset consists of 397 FA articles, 299 GA articles, 253 B articles, 193 C articles, 239 Start articles and 345 Stub articles.'}", "all_figures_names": ["1-Figure1-1.png", "4-Table1-1.png", "4-Table2-1.png", "3-Figure2-1.png"], "referred_figures_names": ["4-Table1-1.png"], "answer": "a sample of  29,794 wikipedia articles and 2,794 arXiv papers "}}