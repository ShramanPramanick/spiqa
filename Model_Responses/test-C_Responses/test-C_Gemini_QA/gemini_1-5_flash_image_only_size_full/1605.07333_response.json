{"845": {"question": "By how much does their best model outperform the state-of-the-art?", "referred_figures_indices": [3], "response": "{'Answer': 'The best model (ER-CNN + R-RNN) outperforms the state-of-the-art by 0.7 F1 score.'}", "all_figures_names": ["3-Figure1-1.png", "5-Table2-1.png", "3-Figure2-1.png", "5-Table3-1.png", "4-Table1-1.png"], "referred_figures_names": ["5-Table3-1.png"], "answer": "0.8% F1 better than the best state-of-the-art"}, "846": {"question": "By how much does their best model outperform the state-of-the-art?", "referred_figures_indices": [2], "response": "{'Answer': 'Their best model outperforms the state-of-the-art by 0.7 F1 score.'}", "all_figures_names": ["5-Table2-1.png", "3-Figure2-1.png", "5-Table3-1.png", "3-Figure1-1.png", "4-Table1-1.png"], "referred_figures_names": ["5-Table3-1.png"], "answer": "Best proposed model achieves F1 score of 84.9 compared to best previous result of 84.1."}, "852": {"question": "How do they obtain the new context represetation?", "referred_figures_indices": [3], "response": "{'Answer': 'The new context representation is obtained by adding the new contextual vector to the original vector. This contextual vector is obtained by taking the sum of the word vectors of the words in the new context. '}", "all_figures_names": ["3-Figure2-1.png", "5-Table2-1.png", "5-Table3-1.png", "3-Figure1-1.png", "4-Table1-1.png"], "referred_figures_names": ["3-Figure1-1.png"], "answer": "They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."}}