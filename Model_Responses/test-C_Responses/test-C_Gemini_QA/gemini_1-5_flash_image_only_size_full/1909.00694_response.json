{"2": {"question": "What are the results?", "referred_figures_indices": [1, 4], "response": "{'Answer': 'The results show that the BERT encoder outperforms the BiGRU encoder in all cases except for the CA+CO dataset, where the BiGRU encoder achieves a slightly better accuracy.'}", "all_figures_names": ["2-Figure1-1.png", "5-Table4-1.png", "4-Table2-1.png", "5-Table5-1.png", "5-Table3-1.png", "4-Table1-1.png"], "referred_figures_names": ["5-Table4-1.png", "5-Table3-1.png"], "answer": "Using all data to train: AL -- BiGRU achieved 0.843 accuracy, AL -- BERT achieved 0.863 accuracy, AL+CA+CO -- BiGRU achieved 0.866 accuracy, AL+CA+CO -- BERT achieved 0.835, accuracy, ACP -- BiGRU achieved 0.919 accuracy, ACP -- BERT achived 0.933, accuracy, ACP+AL+CA+CO -- BiGRU achieved 0.917 accuracy, ACP+AL+CA+CO -- BERT achieved 0.913 accuracy. \nUsing a subset to train: BERT achieved 0.876 accuracy using ACP (6K), BERT achieved 0.886 accuracy using ACP (6K) + AL, BiGRU achieved 0.830 accuracy using ACP (6K), BiGRU achieved 0.879 accuracy using ACP (6K) + AL + CA + CO."}, "3": {"question": "How are relations used to propagate polarity?", "referred_figures_indices": [0], "response": "{'Answer': 'Relations are used to propagate polarity in a way that depends on the type of relation.  For example, CAUSE relations propagate the same polarity, while CONCESSION relations propagate the reverse polarity.'}", "all_figures_names": ["2-Figure1-1.png", "4-Table2-1.png", "5-Table3-1.png", "5-Table5-1.png", "4-Table1-1.png", "5-Table4-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "based on the relation between events, the suggested polarity of one event can determine the possible polarity of the other event "}, "4": {"question": "How are relations used to propagate polarity?", "referred_figures_indices": [4], "response": "{'Answer': 'The polarity of an event is propagated by its relation with the previous event. In CA relations (CAUSE) the polarity is encouraged to be the same. In CO relations (CONCESSION) the polarity is encouraged to be the opposite.'}", "all_figures_names": ["4-Table2-1.png", "5-Table4-1.png", "5-Table3-1.png", "4-Table1-1.png", "2-Figure1-1.png", "5-Table5-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "cause relation: both events in the relation should have the same polarity; concession relation: events should have opposite polarity"}, "5": {"question": "How big is the Japanese data?", "referred_figures_indices": [0, 2], "response": "{'Answer': 'The Japanese dataset has 600,000 events.'}", "all_figures_names": ["4-Table2-1.png", "5-Table5-1.png", "4-Table1-1.png", "5-Table3-1.png", "5-Table4-1.png", "2-Figure1-1.png"], "referred_figures_names": ["4-Table2-1.png", "4-Table1-1.png"], "answer": "7000000 pairs of events were extracted from the Japanese Web corpus, 529850 pairs of events were extracted from the ACP corpus"}, "6": {"question": "How big is the Japanese data?", "referred_figures_indices": [3], "response": "{'Answer': 'The Japanese dataset has 1,000,000 Automatically Labeled Pairs (AL), 5,000,000 CAUSE Pairs (CA), and 5,000,000 CONCESSION Pairs (CO).'}", "all_figures_names": ["4-Table1-1.png", "5-Table5-1.png", "2-Figure1-1.png", "4-Table2-1.png", "5-Table4-1.png", "5-Table3-1.png"], "referred_figures_names": ["4-Table2-1.png"], "answer": "The ACP corpus has around 700k events split into positive and negative polarity "}, "8": {"question": "How big are improvements of supervszed learning results trained on smalled labeled data enhanced with proposed approach copared to basic approach?", "referred_figures_indices": [4], "response": "{'Answer': 'The proposed approach, training with smaller labelled data enhanced with AL+CA+CO, improved the results by 0.014 for BERT encoder and 0.013 for BiGRU encoder.'}", "all_figures_names": ["2-Figure1-1.png", "5-Table5-1.png", "4-Table2-1.png", "5-Table3-1.png", "5-Table4-1.png", "4-Table1-1.png"], "referred_figures_names": ["5-Table4-1.png"], "answer": "3%"}, "9": {"question": "How does their model learn using mostly raw data?", "referred_figures_indices": [4], "response": "{'Answer': 'The model learns using a dataset that is mostly made up of raw data. The ACP dataset is a large dataset of 600,000 event pairs where the polarity of the event is manually labeled. This dataset is used to train the model. The model learns by identifying patterns in the raw data and using these patterns to predict the polarity of new events.'}", "all_figures_names": ["4-Table2-1.png", "5-Table4-1.png", "5-Table5-1.png", "5-Table3-1.png", "2-Figure1-1.png", "4-Table1-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "by exploiting discourse relations to propagate polarity from seed predicates to final sentiment polarity"}, "10": {"question": "How big is seed lexicon used for training?", "referred_figures_indices": [1], "response": "{'Answer': 'The size of the seed lexicon used for training is not mentioned in the provided images.'}", "all_figures_names": ["4-Table2-1.png", "4-Table1-1.png", "5-Table5-1.png", "5-Table3-1.png", "2-Figure1-1.png", "5-Table4-1.png"], "referred_figures_names": ["4-Table1-1.png"], "answer": "30 words"}}