{"248": {"question": "How were the human judgements assembled?", "referred_figures_indices": [2, 5], "response": "{'Answer': 'The judgments for adequacy, fluency and ranking were assembled by three human annotators and analyzed using Cohen\u2019s kappa to measure inter-annotator agreement.'}", "all_figures_names": ["13-Figure7-1.png", "9-Figure4-1.png", "11-Table2-1.png", "15-Figure9-1.png", "11-Figure5-1.png", "12-Table3-1.png", "12-Figure6-1.png", "16-Figure10-1.png"], "referred_figures_names": ["11-Table2-1.png", "12-Table3-1.png"], "answer": "50 human annotators ranked a random sample of 100 translations by Adequacy, Fluency and overall ranking on a 5-point scale."}}