{"1259": {"question": "By how much does their method outperform the multi-head attention model?", "referred_figures_indices": [4], "response": "{'Answer': 'Their best performing hybrid multi-head decoder (HMHD) model, with two location-based attention heads and two coverage-based attention heads, achieves a CER of 10.4%, outperforming the multi-head attention (MHA) model with location-based attention by 1.1%.'}", "all_figures_names": ["4-Figure3-1.png", "2-Figure1-1.png", "3-Figure2-1.png", "4-Table1-1.png", "4-Table2-1.png"], "referred_figures_names": ["4-Table2-1.png"], "answer": "Their average improvement in Character Error Rate over the best MHA model was 0.33 percent points."}, "1260": {"question": "How large is the corpus they use?", "referred_figures_indices": [0], "response": "{'Answer': 'They used 445,068 utterances for training.'}", "all_figures_names": ["4-Table1-1.png", "4-Figure3-1.png", "3-Figure2-1.png", "4-Table2-1.png", "2-Figure1-1.png"], "referred_figures_names": ["4-Table1-1.png"], "answer": "449050"}}