{"182": {"question": "Do they inspect their model to see if their model learned to associate image parts with words related to entities?", "referred_figures_indices": [0], "response": "{'Answer': 'The paper does not inspect if the model learned to associate image parts with words related to entities. However, it shows what modalities the model attends to when making predictions (words, characters, or visual), as shown in Figure 3.'}", "all_figures_names": ["8-Figure3-1.png", "6-Table1-1.png", "8-Table3-1.png", "3-Figure2-1.png", "7-Table2-1.png", "1-Figure1-1.png"], "referred_figures_names": ["8-Figure3-1.png"], "answer": "Yes"}, "183": {"question": "Do they inspect their model to see if their model learned to associate image parts with words related to entities?", "referred_figures_indices": [0], "response": "{'Answer': 'Yes, Figure 3 showcases modality attention, highlighting successful and unsuccessful cases from their SnapCaptions test data.  This visualization illustrates how the model associates image parts (visual tags from InceptionNet) with words related to entities, revealing the model's learning process.'}", "all_figures_names": ["7-Table2-1.png", "1-Figure1-1.png", "8-Table3-1.png", "8-Figure3-1.png", "3-Figure2-1.png", "6-Table1-1.png"], "referred_figures_names": ["7-Table2-1.png"], "answer": "Yes"}}