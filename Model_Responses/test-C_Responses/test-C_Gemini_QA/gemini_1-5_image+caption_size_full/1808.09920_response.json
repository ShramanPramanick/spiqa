{"856": {"question": "What baseline did they compare Entity-GCN to?", "referred_figures_indices": [1], "response": "{'Answer': 'The provided context does not contain the information about the baseline models used to compare against Entity-GCN. Therefore, I cannot answer your question.'}", "all_figures_names": ["11-Table5-1.png", "6-Table2-1.png", "3-Figure2-1.png", "12-Table6-1.png", "8-Table4-1.png", "13-Figure3-1.png", "1-Figure1-1.png", "5-Table1-1.png"], "referred_figures_names": ["6-Table2-1.png"], "answer": "Human, FastQA, BiDAF, Coref-GRU, MHPGM, Weaver / Jenga, MHQA-GRN"}, "858": {"question": "Did they use a relation extraction method to construct the edges in the graph?", "referred_figures_indices": [2], "response": "{'Answer': 'Based on the captions and images provided, specifically Figure 2 and the description of solid edges representing co-occurrence in the same document, it can be concluded that they did not use a relation extraction method to construct the edges in the graph.'}", "all_figures_names": ["5-Table1-1.png", "13-Figure3-1.png", "3-Figure2-1.png", "1-Figure1-1.png", "6-Table2-1.png", "7-Table3-1.png", "8-Table4-1.png", "11-Table5-1.png"], "referred_figures_names": ["3-Figure2-1.png"], "answer": "No"}, "859": {"question": "How did they get relations between mentions?", "referred_figures_indices": [4], "response": "{'Answer': 'Relations between mentions were obtained by organizing supporting documents as a graph, where nodes are mentions of candidate or query entities, connected by edges indicating co-occurrence in the same document, exact matches, or coreference.'}", "all_figures_names": ["11-Table5-1.png", "12-Table6-1.png", "5-Table1-1.png", "6-Table2-1.png", "3-Figure2-1.png", "13-Figure3-1.png", "8-Table4-1.png", "1-Figure1-1.png"], "referred_figures_names": ["3-Figure2-1.png"], "answer": "Assign a value to the relation based on whether mentions occur in the same document, if mentions are identical, or if mentions are in the same coreference chain."}, "862": {"question": "What performance does the Entity-GCN get on WIKIHOP?", "referred_figures_indices": [1], "response": "{'Answer': 'The Entity-GCN with an ensemble of 5 models achieves an accuracy of 71.2 on the WIKIHOP dataset.'}", "all_figures_names": ["13-Figure3-1.png", "6-Table2-1.png", "7-Table3-1.png", "5-Table1-1.png", "1-Figure1-1.png", "3-Figure2-1.png", "8-Table4-1.png", "11-Table5-1.png"], "referred_figures_names": ["6-Table2-1.png"], "answer": "During testing: 67.6 for single model without coreference, 66.4 for single model with coreference, 71.2 for ensemble of 5 models"}}