{"1021": {"question": "Does the model evaluated on NLG datasets or dialog datasets?", "referred_figures_indices": [3], "response": "{'Answer': 'The model is evaluated on NLG datasets for the task of dialog act to natural language generation.'}", "all_figures_names": ["6-Table3-1.png", "3-Figure1-1.png", "7-Figure4-1.png", "5-Table1-1.png", "3-Figure2-1.png", "7-Figure3-1.png", "7-Figure5-1.png", "6-Table2-1.png"], "referred_figures_names": ["5-Table1-1.png"], "answer": "NLG datasets"}, "1022": {"question": "Does the model evaluated on NLG datasets or dialog datasets?", "referred_figures_indices": [1], "response": "{'Answer': 'The model was evaluated on dialog datasets, as indicated by captions such as  \"Table 4: Comparison of top responses generated for some input dialogue acts between different models\" and \"Figure 3: Performance comparison of the models trained on Laptop domain.\"'}", "all_figures_names": ["8-Table4-1.png", "5-Table1-1.png", "7-Figure3-1.png", "7-Figure5-1.png", "6-Table3-1.png", "6-Table2-1.png", "8-Figure6-1.png", "7-Figure4-1.png"], "referred_figures_names": ["5-Table1-1.png"], "answer": "NLG datasets"}}