{"654": {"question": "How they extract \"structured answer-relevant relation\"?", "referred_figures_indices": [7], "response": " {'Answer': 'The structured answer-relevant relation is a binary relation between the answer and the question, which indicates whether the answer is relevant to the question.'}", "all_figures_names": ["7-Table5-1.png", "7-Figure4-1.png", "4-Figure3-1.png", "6-Table4-1.png", "5-Table3-1.png", "3-Figure2-1.png", "8-Figure5-1.png", "1-Figure1-1.png"], "referred_figures_names": ["1-Figure1-1.png"], "answer": "Using the OpenIE toolbox and applying heuristic rules to select the most relevant relation."}, "656": {"question": "How big are significant improvements?", "referred_figures_indices": [7], "response": " {'Answer': 'In the paper, the authors conduct extensive experiments on two benchmark datasets. The results show that our model outperforms several baselines by a large margin. For example, on the Du Split dataset, our model achieves a BLEU-4 score of 45.66, which is 1.54 higher than the previous state-of-the-art model. On the Zhou Split dataset, our model achieves a BLEU-4 score of 44.40, which is 2.48 higher than the previous state-of-the-art model.'}", "all_figures_names": ["7-Table5-1.png", "3-Table2-1.png", "8-Figure5-1.png", "5-Table3-1.png", "2-Table1-1.png", "7-Figure4-1.png", "4-Figure3-1.png", "6-Table4-1.png"], "referred_figures_names": ["6-Table4-1.png"], "answer": "Metrics show better results on all metrics compared to baseline except Bleu1  on Zhou split (worse by 0.11 compared to baseline). Bleu1 score on DuSplit is 45.66 compared to best baseline 43.47, other metrics on average by 1"}}