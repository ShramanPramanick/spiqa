{"812": {"question": "By how much did they improve?", "referred_figures_indices": [2, 4], "response": " {'Answer': 'The F1 score improved from 0.445 (SVMovr) to 0.481 (biLSTM+Multitask).'}", "all_figures_names": ["3-Table2-1.png", "5-Figure2-1.png", "3-Figure1-1.png", "2-Table1-1.png", "5-Table3-1.png"], "referred_figures_names": ["3-Figure1-1.png", "5-Table3-1.png"], "answer": "They decrease MAE in 0.34"}, "813": {"question": "What dataset did they use?", "referred_figures_indices": [4], "response": " {'Answer': 'The dataset used is not explicitly stated in the captions or images.'}", "all_figures_names": ["5-Table3-1.png", "3-Figure1-1.png", "2-Table1-1.png", "5-Figure2-1.png", "3-Table2-1.png"], "referred_figures_names": ["3-Table2-1.png"], "answer": " high-quality datasets  from SemEval-2016 \u201cSentiment Analysis in Twitter\u201d task"}}