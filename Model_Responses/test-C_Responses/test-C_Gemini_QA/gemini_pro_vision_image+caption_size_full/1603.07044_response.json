{"193": {"question": "What supplemental tasks are used for multitask learning?", "referred_figures_indices": [1], "response": " {'Answer': 'In the paper, the authors use three supplemental tasks for multitask learning: answer ranking, question retrieval, and comment ranking.'}", "all_figures_names": ["5-Figure3-1.png", "3-Figure1-1.png", "7-Table4-1.png", "3-Figure2-1.png", "8-Figure5-1.png", "7-Table3-1.png", "5-Table2-1.png", "5-Figure4-1.png"], "referred_figures_names": ["3-Figure1-1.png"], "answer": "Multitask learning is used for the task of predicting relevance of a comment on a different question to a given question, where the supplemental tasks are predicting relevance between the questions, and between the comment and the corresponding question"}, "195": {"question": "How much performance gap between their approach and the strong handcrafted method?", "referred_figures_indices": [7], "response": " {'Answer': 'The performance gap between their approach and the strong handcrafted method is not large. For Task A, the handcrafted method achieves 0.632 in MAP and 0.623 in F1, while their approach with attention achieves 0.639 in MAP and 0.623 in F1. For Task B, the handcrafted method achieves 0.685 in MAP and 0.538 in F1, while their approach with attention achieves 0.695 in MAP and 0.434 in F1. For Task C, the handcrafted method achieves 0.339 in MAP and 0.193 in F1, while their approach with attention achieves 0.324 in MAP and 0.149 in F1.'}", "all_figures_names": ["5-Figure3-1.png", "8-Figure5-1.png", "5-Table2-1.png", "7-Table3-1.png", "3-Figure2-1.png", "5-Figure4-1.png", "3-Figure1-1.png", "7-Table4-1.png"], "referred_figures_names": ["7-Table4-1.png"], "answer": "0.007 MAP on Task A, 0.032 MAP on Task B, 0.055 MAP on Task C"}}