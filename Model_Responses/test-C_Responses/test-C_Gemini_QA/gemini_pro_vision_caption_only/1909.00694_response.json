{"2": {"question": "What are the results?", "referred_figures_indices": [0, 3], "response": "{'Answer': 'The provided captions do not contain the results requested in the question.'}", "all_figures_names": ["5-Table3-1.png", "5-Table5-1.png", "2-Figure1-1.png", "5-Table4-1.png", "4-Table2-1.png", "4-Table1-1.png"], "referred_figures_names": ["5-Table3-1.png", "5-Table4-1.png"], "answer": "Using all data to train: AL -- BiGRU achieved 0.843 accuracy, AL -- BERT achieved 0.863 accuracy, AL+CA+CO -- BiGRU achieved 0.866 accuracy, AL+CA+CO -- BERT achieved 0.835, accuracy, ACP -- BiGRU achieved 0.919 accuracy, ACP -- BERT achived 0.933, accuracy, ACP+AL+CA+CO -- BiGRU achieved 0.917 accuracy, ACP+AL+CA+CO -- BERT achieved 0.913 accuracy. \nUsing a subset to train: BERT achieved 0.876 accuracy using ACP (6K), BERT achieved 0.886 accuracy using ACP (6K) + AL, BiGRU achieved 0.830 accuracy using ACP (6K), BiGRU achieved 0.879 accuracy using ACP (6K) + AL + CA + CO."}, "3": {"question": "How are relations used to propagate polarity?", "referred_figures_indices": [0], "response": "{'Answer': 'The polarity of a following event is automatically recognized as either positive or negative according to the seed lexicon, and the same polarity is used for the relation CAUSE. In case of CONCESSION, the polarity is reversed.'}", "all_figures_names": ["2-Figure1-1.png", "5-Table4-1.png", "5-Table5-1.png", "5-Table3-1.png", "4-Table2-1.png", "4-Table1-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "based on the relation between events, the suggested polarity of one event can determine the possible polarity of the other event "}, "4": {"question": "How are relations used to propagate polarity?", "referred_figures_indices": [0], "response": "{'Answer': 'Relations are used to propagate polarity by assuming that the polarity of a latter event is the same as the polarity of the discourse relation CAUSE, and the reversed polarity for CONCESSION. Depending on the discourse relation, the two events\u2019 polarities are encouraged to be the same (CA) or reversed (CO).'}", "all_figures_names": ["2-Figure1-1.png", "5-Table5-1.png", "5-Table3-1.png", "5-Table4-1.png", "4-Table1-1.png", "4-Table2-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "cause relation: both events in the relation should have the same polarity; concession relation: events should have opposite polarity"}, "5": {"question": "How big is the Japanese data?", "referred_figures_indices": [3, 4], "response": "{'Answer': 'The text does not specify the size of the Japanese data, so I cannot answer this question from the provided context.'}", "all_figures_names": ["5-Table4-1.png", "5-Table5-1.png", "5-Table3-1.png", "4-Table2-1.png", "4-Table1-1.png", "2-Figure1-1.png"], "referred_figures_names": ["4-Table2-1.png", "4-Table1-1.png"], "answer": "7000000 pairs of events were extracted from the Japanese Web corpus, 529850 pairs of events were extracted from the ACP corpus"}, "6": {"question": "How big is the Japanese data?", "referred_figures_indices": [0], "response": "{'Answer': 'The provided context does not contain any information about the size of the Japanese data, so I cannot answer this question from the provided context.'}", "all_figures_names": ["4-Table2-1.png", "5-Table3-1.png", "4-Table1-1.png", "5-Table5-1.png", "5-Table4-1.png", "2-Figure1-1.png"], "referred_figures_names": ["4-Table2-1.png"], "answer": "The ACP corpus has around 700k events split into positive and negative polarity "}, "8": {"question": "How big are improvements of supervszed learning results trained on smalled labeled data enhanced with proposed approach copared to basic approach?", "referred_figures_indices": [4], "response": "{'Answer': 'I cannot find the answer to this question in the context provided.'}", "all_figures_names": ["5-Table3-1.png", "4-Table2-1.png", "4-Table1-1.png", "2-Figure1-1.png", "5-Table4-1.png", "5-Table5-1.png"], "referred_figures_names": ["5-Table4-1.png"], "answer": "3%"}, "9": {"question": "How does their model learn using mostly raw data?", "referred_figures_indices": [3], "response": "{'Answer': 'This question cannot be answered from the given context.'}", "all_figures_names": ["4-Table2-1.png", "5-Table4-1.png", "4-Table1-1.png", "2-Figure1-1.png", "5-Table3-1.png", "5-Table5-1.png"], "referred_figures_names": ["2-Figure1-1.png"], "answer": "by exploiting discourse relations to propagate polarity from seed predicates to final sentiment polarity"}, "10": {"question": "How big is seed lexicon used for training?", "referred_figures_indices": [1], "response": "{'Answer': 'The size of the seed lexicon used for training is not specified in the provided captions.'}", "all_figures_names": ["5-Table4-1.png", "4-Table1-1.png", "4-Table2-1.png", "2-Figure1-1.png", "5-Table3-1.png", "5-Table5-1.png"], "referred_figures_names": ["4-Table1-1.png"], "answer": "30 words"}}