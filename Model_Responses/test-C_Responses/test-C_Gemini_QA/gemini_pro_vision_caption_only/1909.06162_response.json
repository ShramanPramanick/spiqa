{"909": {"question": "What is best performing model among author's submissions, what performance it had?", "referred_figures_indices": [1], "response": "{'Answer': 'I am sorry, I cannot answer the question as no such information is present in the input captions provided.'}", "all_figures_names": ["4-Table3-1.png", "3-Table2-1.png", "4-Table4-1.png", "3-Figure1-1.png", "2-Table1-1.png"], "referred_figures_names": ["3-Table2-1.png"], "answer": "For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."}, "910": {"question": "What extracted features were most influencial on performance?", "referred_figures_indices": [3], "response": "{'Answer': 'I cannot answer the question, the given context does not mention which extracted features were most influential on performance.'}", "all_figures_names": ["3-Table2-1.png", "4-Table4-1.png", "3-Figure1-1.png", "4-Table3-1.png", "2-Table1-1.png"], "referred_figures_names": ["4-Table3-1.png"], "answer": "Linguistic"}, "912": {"question": "Did ensemble schemes help in boosting peformance, by how much?", "referred_figures_indices": [1], "response": "{'Answer': 'This question cannot be answered from the given context as the provided captions do not contain any information about the performance boost achieved by ensemble schemes.'}", "all_figures_names": ["3-Figure1-1.png", "4-Table3-1.png", "3-Table2-1.png", "2-Table1-1.png", "4-Table4-1.png"], "referred_figures_names": ["4-Table3-1.png"], "answer": "The best ensemble topped the best single model by 0.029 in F1 score on dev (external)."}, "913": {"question": "Did ensemble schemes help in boosting peformance, by how much?", "referred_figures_indices": [2, 0, 3], "response": "{'Answer': 'Answer not found in the given context.'}", "all_figures_names": ["4-Table4-1.png", "3-Figure1-1.png", "4-Table3-1.png", "3-Table2-1.png", "2-Table1-1.png"], "referred_figures_names": ["4-Table3-1.png", "4-Table4-1.png", "3-Table2-1.png"], "answer": "They increased F1 Score by 0.029 in Sentence Level Classification, and by 0.044 in Fragment-Level classification"}, "914": {"question": "Which basic neural architecture perform best by itself?", "referred_figures_indices": [3], "response": "{'Answer': 'The text lacks information on which basic neural architecture performs best by itself'}", "all_figures_names": ["3-Table2-1.png", "2-Table1-1.png", "3-Figure1-1.png", "4-Table3-1.png", "4-Table4-1.png"], "referred_figures_names": ["4-Table3-1.png"], "answer": "BERT"}, "915": {"question": "What participating systems had better results than ones authors submitted?", "referred_figures_indices": [2], "response": "{'Answer': 'The question is unanswerable from the given context because the caption does not have the information about the results of the participating systems.'}", "all_figures_names": ["4-Table3-1.png", "4-Table4-1.png", "3-Table2-1.png", "3-Figure1-1.png", "2-Table1-1.png"], "referred_figures_names": ["3-Table2-1.png"], "answer": "For SLC task : Ituorp, ProperGander and YMJA  teams had better results.\nFor FLC task: newspeak and Antiganda teams had better results."}, "916": {"question": "What is specific to multi-granularity and multi-tasking neural arhiteture design?", "referred_figures_indices": [4], "response": "{'Answer': 'The multi-granularity and multi-tasking neural architecture design is specific to the use of a multi-tasking LSTM-CRF architecture that consists of Propaganda Fragment Detection (PFD) and FLC layers, and a binary classification component at the last hidden layer in the recurrent architecture that jointly performs PFD, FLC, and SLC tasks (i.e., multi-grained propaganda detection).'}", "all_figures_names": ["4-Table3-1.png", "4-Table4-1.png", "2-Table1-1.png", "3-Table2-1.png", "3-Figure1-1.png"], "referred_figures_names": ["3-Figure1-1.png"], "answer": "An output layer for each task"}}